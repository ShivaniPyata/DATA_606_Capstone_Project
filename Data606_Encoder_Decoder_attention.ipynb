{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Data606_Encoder-Decoder_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTwP4QD5EgF3ru3GjTXFaW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxdJk93q3OQL"
      },
      "source": [
        "#**<center>Natural Language Text to SQL Query Conversion**\n",
        "##**<center>GRU based Encoder-Decoder model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxjRpT-l_ERw"
      },
      "source": [
        "###**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCTwwBebsBt",
        "outputId": "c22f3c7a-ab6e-4fab-ce4f-2cef4ca2512f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3REbOtKc3VHz",
        "outputId": "30c59e06-0eb1-41e3-cebb-5e7259d46951"
      },
      "source": [
        "pip install records"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: records in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: openpyxl<2.5.0 in /usr/local/lib/python3.7/dist-packages (from records) (2.4.11)\n",
            "Requirement already satisfied: SQLAlchemy; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from records) (1.4.7)\n",
            "Requirement already satisfied: tablib>=0.11.4 in /usr/local/lib/python3.7/dist-packages (from records) (3.0.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from records) (0.6.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.0.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy; python_version >= \"3.0\"->records) (3.10.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy; python_version >= \"3.0\"->records) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy; python_version >= \"3.0\"->records) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy; python_version >= \"3.0\"->records) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeVZdo0s3XPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d028fab-567f-4da2-a292-2f9ed3e6b0cc"
      },
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import records\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import json\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import open\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ImportWarning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwAD6WS3aFA",
        "outputId": "95e82276-9445-4c8e-b154-e344827d8a6b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import * \n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDU6X2K73cb4"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/lib/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-YsqTBi3izZ"
      },
      "source": [
        "from lib_db import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1fLEM3N-AVV"
      },
      "source": [
        "\"\"\"\n",
        "Device\n",
        "\"\"\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQpxR1D24c8_"
      },
      "source": [
        "###**Preparing training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FsZ9W6i3l1e"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Language:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = defaultdict(int)\n",
        "        self.word2count = defaultdict(int)\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence:\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GYXJfKQW9ff"
      },
      "source": [
        "\"\"\"\n",
        "To Load the train data from file into the memory  \n",
        "\"\"\"\n",
        "def readLangs(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = pd.read_json(\"/content/drive/MyDrive/Data606_finalproject/output/tokenized_train.jsonl\", lines=True)\n",
        "\n",
        "    # Split every line into pairs\n",
        "    pairs= []\n",
        "    for idx, row in lines.iterrows():\n",
        "        tokens_en = row[\"tokenized_question\"]\n",
        "        tokens_sql = row[\"tokenized_query\"]\n",
        "        pairs.append([tokens_en, tokens_sql])\n",
        "\n",
        "    input_lang = Language(lang1)\n",
        "    output_lang = Language(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\"\"\"To complete the mapping of all string data to numeric data and filter language pairs\n",
        "               The parameters lang1, lang2 represent the name of the source language and target language \"\"\"\n",
        "\n",
        "def prepareData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"\\nCounting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Number of words in\", input_lang.name, input_lang.n_words)\n",
        "    print(\"Number of words in\", output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMSFlGLW6XL1",
        "outputId": "bc59d62b-8f66-46ce-8268-2b98d6435055"
      },
      "source": [
        "global input_lang\n",
        "global output_lang\n",
        "global pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs= prepareData(\"en\", \"sql\")\n",
        "print(\"\\nRandom Question and query pair looks like:\\n\")\n",
        "print(random.choice(pairs))\n",
        "#output_lang.word2index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 56355 sentence pairs\n",
            "\n",
            "Counting words...\n",
            "Number of words in en 39685\n",
            "Number of words in sql 38066\n",
            "\n",
            "Random Question and query pair looks like:\n",
            "\n",
            "[['what', 'is', 'win-loss', ',', 'when', 'win', '%', 'is', '.456', '?'], ['SELECT', 'win-loss', 'FROM', 'table_', 'WHERE', 'win', '%', 'EQL', '.456']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K8tcITaX_3Q"
      },
      "source": [
        "\"\"\"\n",
        "To convert language pairs into tensors to input the model\n",
        "\"\"\"\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5buBZ7IpcLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008f0f37-4220-43bf-be42-3810906c3d2f"
      },
      "source": [
        "pair = pairs[0]\n",
        "print(pair)\n",
        "training_pairs = tensorsFromPair(pair)\n",
        "print(\"\\nTensor for Question and query pair looks like:\\n\")\n",
        "training_pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['tell', 'me', 'what', 'the', 'notes', 'are', 'for', 'south', 'australia'], ['SELECT', 'notes', 'FROM', 'table_', 'WHERE', 'current', 'slogan', 'EQL', 'south', 'australia']]\n",
            "\n",
            "Tensor for Question and query pair looks like:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2],\n",
              "         [ 3],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [ 6],\n",
              "         [ 7],\n",
              "         [ 8],\n",
              "         [ 9],\n",
              "         [10],\n",
              "         [ 1]], device='cuda:0'), tensor([[ 2],\n",
              "         [ 3],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [ 6],\n",
              "         [ 7],\n",
              "         [ 8],\n",
              "         [ 9],\n",
              "         [10],\n",
              "         [11],\n",
              "         [ 1]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxNkBGhVWhx8"
      },
      "source": [
        "\"\"\"\n",
        "To prepare validation data\n",
        "\"\"\"\n",
        "def readLangs_val(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = pd.read_json(\"/content/drive/MyDrive/Data606_finalproject/output/tokenized_test.jsonl\", lines=True)\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = []\n",
        "    for idx, row in lines.iterrows():\n",
        "        tokens_en = row[\"tokenized_question\"]\n",
        "        tokens_sql = row[\"tokenized_query\"]\n",
        "        pairs.append([tokens_en, tokens_sql])\n",
        "\n",
        "    input_lang = Language(lang1)\n",
        "    output_lang = Language(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "def prepareValData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs_val(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrlhQBvzgAYC",
        "outputId": "cc38c975-b528-4573-c02b-fcf1306a19f7"
      },
      "source": [
        "global pairs_test\n",
        "\n",
        "input_lang, output_lang, pairs_test= prepareValData(\"en\", \"sql\")\n",
        "print(\"\\nRandom Question and query pair looks like:\\n\")\n",
        "print(random.choice(pairs_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 15878 sentence pairs\n",
            "Trimmed to 15878 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "en 16358\n",
            "sql 15618\n",
            "\n",
            "Random Question and query pair looks like:\n",
            "\n",
            "[['who', 'directed', 'the', 'episode', 'that', 'aired', 'on', 'july15,2012', '?'], ['SELECT', 'directed', 'by', 'FROM', 'table_', 'WHERE', 'original', 'air', 'date', 'EQL', 'july15,2012']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg9XFtuyBH-C"
      },
      "source": [
        "###**Building GRU-based encoder and decoder model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9-GzzUt_4W8"
      },
      "source": [
        "###**Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzdXTwk_0uR"
      },
      "source": [
        "\"\"\"\n",
        "RNN Encoder\n",
        "\"\"\"\n",
        "class RNN_Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,dropout):\n",
        "        super(RNN_Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcTLxtc4BWng"
      },
      "source": [
        "###**Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoWoXR99rIZI"
      },
      "source": [
        "\"\"\"\n",
        "Decoder\n",
        "\"\"\"\n",
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QYMrxJPImoo"
      },
      "source": [
        "###**Attention Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p48-AWuo_Fsi"
      },
      "source": [
        "MAX_LENGTH = 50\n",
        "\"\"\"\n",
        "Attention Decoder\n",
        "\"\"\"\n",
        "\n",
        "class RNN_AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p, max_length=MAX_LENGTH):\n",
        "        super(RNN_AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcAcOZuRBgI0"
      },
      "source": [
        "###**Training function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlj9Nj4QI3-o"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "          criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length): \n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTHJCln5BpQI"
      },
      "source": [
        "###**Time Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb6APnew-FrE"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3QuP7lCDmN"
      },
      "source": [
        "###**Function to plot graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5crM3Ec-Lgt"
      },
      "source": [
        "def showPlot(points, plot_name):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.savefig(plot_name + \".png\")\n",
        "\n",
        "\n",
        "def plot_data(x, y, xlabel = \"x\", ylabel = \"y\", label = 'plot'):\n",
        "\tplt.figure()\n",
        "\tplt.plot(x, y)\n",
        "\tplt.xlabel(\"Epochs\")\n",
        "\tplt.ylabel(\"Loss\")\n",
        "\tprint(\"Generating plot for \", label)\n",
        "\tplt.savefig(\"./\" + label + \".png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H3FM37YBu_O"
      },
      "source": [
        "###**To call training function and print graphs and logs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGIaFv--Io3"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=1):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        # training_pair = tensorsFromPair(random.choice(pairs))\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                      iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses, \"Baseline loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1iWfeTbCPGp"
      },
      "source": [
        "###**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "D56R6h_DDIBQ",
        "outputId": "0967e19a-5ad4-4abd-c3bc-350bc510caf0"
      },
      "source": [
        "dropout = 0.5\n",
        "dropout_p = 0.5\n",
        "hidden_size = 256\n",
        "\n",
        "\n",
        "encoder1 = RNN_Encoder(input_lang.n_words, hidden_size,dropout).to(device)\n",
        "\n",
        "attn_decoder1 = RNN_AttnDecoder(hidden_size, output_lang.n_words, dropout_p).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, n_iters = 15000, print_every=1000, plot_every=1000,learning_rate= 0.001)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 31s (- 7m 15s) (1000 6%) 3.6885\n",
            "1m 1s (- 6m 39s) (2000 13%) 3.1792\n",
            "1m 32s (- 6m 8s) (3000 20%) 3.0379\n",
            "2m 2s (- 5m 36s) (4000 26%) 2.9508\n",
            "2m 33s (- 5m 7s) (5000 33%) 2.7966\n",
            "3m 4s (- 4m 36s) (6000 40%) 2.7779\n",
            "3m 35s (- 4m 6s) (7000 46%) 2.6418\n",
            "4m 6s (- 3m 35s) (8000 53%) 2.5140\n",
            "4m 36s (- 3m 4s) (9000 60%) 2.5354\n",
            "5m 7s (- 2m 33s) (10000 66%) 2.4404\n",
            "5m 37s (- 2m 2s) (11000 73%) 2.4100\n",
            "6m 8s (- 1m 32s) (12000 80%) 2.3467\n",
            "6m 39s (- 1m 1s) (13000 86%) 2.3515\n",
            "7m 10s (- 0m 30s) (14000 93%) 2.2535\n",
            "7m 41s (- 0m 0s) (15000 100%) 2.2615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csymIFaCi1A"
      },
      "source": [
        "###**Model evaluation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlmNUob3-OZM"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=50):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_cHrGS7-RHN"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=20):\n",
        "    correct = 0\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('\\nEnglish Question-', pair[0])\n",
        "        print('Ground truth Query-', pair[1])\n",
        "        generated_tokens, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        generated_query = ' '.join(generated_tokens)\n",
        "        if generated_query[:-6] == pair[1]:\n",
        "            correct += 1\n",
        "        print('Generated Query-', generated_query)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIuxVBPq-UCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9c2dcf-528a-45c9-8fab-811adc5d1158"
      },
      "source": [
        "\n",
        "evaluateRandomly(encoder1, attn_decoder1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "English Question- ['what', 'were', 'the', 'high', 'assist', 'on', 'january', '2', '?']\n",
            "Ground truth Query- ['SELECT', 'high', 'assists', 'FROM', 'table_', 'WHERE', 'date', 'EQL', 'january', '2']\n",
            "Generated Query- SELECT high 2 FROM table_ WHERE date EQL january 2 <EOS>\n",
            "\n",
            "English Question- ['who', 'is', 'the', 'republican', 'incumbent', 'for', 'pennsylvania', '9', '?']\n",
            "Ground truth Query- ['SELECT', 'incumbent', 'FROM', 'table_', 'WHERE', 'party', 'EQL', 'republican', 'AND', 'district', 'EQL', 'pennsylvania', '9']\n",
            "Generated Query- SELECT incumbent FROM table_ WHERE year EQL 9 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'average', '2006', 'value', 'with', 'a', '2010', 'value', 'of', '417.9', 'and', 'a', '2011', 'value', 'greater', 'than', '426.7', '?']\n",
            "Ground truth Query- ['SELECT', 'avg', '(', '2006', ')', 'FROM', 'table_', 'WHERE', '2010', 'EQL', '417.9', 'AND', '2011', 'GT', '426.7']\n",
            "Generated Query- SELECT avg ( table_ WHERE WHERE table_ WHERE SOS SOS SOS 2011 EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'round', 'for', 'zach', 'boychuk', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'round', ')', 'FROM', 'table_', 'WHERE', 'player', 'EQL', 'zach', 'boychuk']\n",
            "Generated Query- SELECT round FROM table_ WHERE round EQL SOS <EOS>\n",
            "\n",
            "English Question- ['when', 'has', 'a', 'record', 'of', '9–1', ',', 'and', 'a', 'tournament', 'champion', 'of', 'duke', '?']\n",
            "Ground truth Query- ['SELECT', 'year', 'FROM', 'table_', 'WHERE', 'record', 'EQL', '9–1', 'AND', 'tournament', 'champion', 'EQL', 'duke']\n",
            "Generated Query- SELECT FROM table_ WHERE opponent EQL 14 AND opponent EQL 14 AND opponent EQL 14 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'authority', 'status', 'of', 'the', 'school', 'in', 'ellerslie', 'with', 'a', 'decile', 'of', '7', '?']\n",
            "Ground truth Query- ['SELECT', 'authority', 'FROM', 'table_', 'WHERE', 'area', 'EQL', 'ellerslie', 'AND', 'decile', 'EQL', '7']\n",
            "Generated Query- SELECT status FROM table_ WHERE name EQL SOS SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'result', 'of', 'the', 'game', 'on', 'november', '6', ',', '1988', '?']\n",
            "Ground truth Query- ['SELECT', 'result', 'FROM', 'table_', 'WHERE', 'date', 'EQL', 'november', '6', ',', '1988']\n",
            "Generated Query- SELECT result FROM table_ WHERE date EQL january , , , , <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'result', 'of', 'the', 'game', 'played', 'in', 'texas', 'stadium', 'with', 'more', 'than', '46,267', 'in', 'the', 'crowd', 'and', 'against', 'the', 'pittsburgh', 'steelers', '?']\n",
            "Ground truth Query- ['SELECT', 'result', 'FROM', 'table_', 'WHERE', 'game', 'site', 'EQL', 'texas', 'stadium', 'AND', 'attendance', 'GT', '46,267', 'AND', 'opponent', 'EQL', 'pittsburgh', 'steelers']\n",
            "Generated Query- SELECT result FROM table_ WHERE score EQL l AND year GT GT <EOS>\n",
            "\n",
            "English Question- ['which', 'rank', 'has', 'a', 'bronze', 'of', '3', '?']\n",
            "Ground truth Query- ['SELECT', 'rank', 'FROM', 'table_', 'WHERE', 'bronze', 'EQL', '3']\n",
            "Generated Query- SELECT rank FROM table_ WHERE rank EQL 3 <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'states', 'is', 'grant', 'wharington', 'from', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'state/country', ')', 'FROM', 'table_', 'WHERE', 'skipper', 'EQL', 'grant', 'wharington']\n",
            "Generated Query- SELECT COUNT ( FROM ) FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'position', 'did', 'the', 'team', 'finish', 'in', 'with', 'a', 'difference', 'of', '-', '6', ',', '3', 'losses', ',', 'and', 'over', '4', 'draws', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'position', ')', 'FROM', 'table_', 'WHERE', 'difference', 'EQL', '-', '6', 'AND', 'lost', 'EQL', '3', 'AND', 'drawn', 'GT', '4']\n",
            "Generated Query- SELECT position FROM table_ WHERE round LT 6 AND lost EQL 6 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'place', ',', 'when', 'score', 'is', '72-72=144', ',', 'when', 'country', 'is', 'united', 'states', ',', 'and', 'when', 'player', 'is', 'scott', 'mccarron', '?']\n",
            "Ground truth Query- ['SELECT', 'place', 'FROM', 'table_', 'WHERE', 'score', 'EQL', '72-72=144', 'AND', 'country', 'EQL', 'united', 'states', 'AND', 'player', 'EQL', 'scott', 'mccarron']\n",
            "Generated Query- SELECT place FROM table_ WHERE score EQL SOS AND score EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'least', 'yards', 'when', 'the', 'average', 'is', '7', 'and', 'the', 'long', 'is', 'less', 'than', '7', '?']\n",
            "Ground truth Query- ['SELECT', 'min', '(', 'yards', ')', 'FROM', 'table_', 'WHERE', 'avg', '.', 'EQL', '7', 'AND', 'long', 'LT', '7']\n",
            "Generated Query- SELECT avg ( average ) FROM table_ WHERE start EQL 7 AND name EQL 7 <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'date', 'of', 'appointments', 'are', 'there', 'when', 'the', 'date', 'of', 'vacancy', 'was', '2', 'october', '2010', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'date', 'of', 'appointment', ')', 'FROM', 'table_', 'WHERE', 'date', 'of', 'vacancy', 'EQL', '2', 'october', '2010']\n",
            "Generated Query- SELECT date of vacancy FROM table_ WHERE date EQL SOS october 2 <EOS>\n",
            "\n",
            "English Question- ['what', 'player', 'has', 'a', 'to', 'par', 'of', '+1', 'with', 'a', 'score', 'of', '71-67-73=211', '?']\n",
            "Ground truth Query- ['SELECT', 'player', 'FROM', 'table_', 'WHERE', 'to', 'par', 'EQL', '+1', 'AND', 'score', 'EQL', '71-67-73=211']\n",
            "Generated Query- SELECT player FROM table_ WHERE score EQL SOS AND score EQL SOS <EOS>\n",
            "\n",
            "English Question- ['which', 'website', 'has', 'a', 'frequency', 'smaller', 'than', '760', 'and', 'a', 'callsign', 'of', 'kkyx', '?']\n",
            "Ground truth Query- ['SELECT', 'website', 'FROM', 'table_', 'WHERE', 'frequency', 'LT', '760', 'AND', 'callsign', 'EQL', 'kkyx']\n",
            "Generated Query- SELECT frequency FROM table_ WHERE frequency mhz EQL SOS AND frequency EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'average', 'rank', 'for', 'a', 'building', 'with', '24', 'floors', '?']\n",
            "Ground truth Query- ['SELECT', 'avg', '(', 'rank', ')', 'FROM', 'table_', 'WHERE', 'floors', 'EQL', '24']\n",
            "Generated Query- SELECT avg ( rank ) FROM table_ WHERE rank EQL 15 AND rank EQL 15 <EOS>\n",
            "\n",
            "English Question- ['which', 'title', 'has', 'a', 'songwriter', '(', 's', ')', 'of', 'hadise', 'açıkgöz', ',', 'stefaan', 'fernande', ',', 'elio', 'deepcore', '?']\n",
            "Ground truth Query- ['SELECT', 'title', 'FROM', 'table_', 'WHERE', 'songwriter', '(', 's', ')', 'EQL', 'hadise', 'açıkgöz', ',', 'stefaan', 'fernande', ',', 'elio', 'deepcore']\n",
            "Generated Query- SELECT title FROM table_ WHERE SOS ( SOS ) EQL SOS ( SOS ) SOS SOS SOS SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'average', 'year', 'having', 'a', 'rank', 'among', 'provinces', 'over', '5', 'and', 'ten-year', 'percentage', 'change', 'of', '67.3', '?']\n",
            "Ground truth Query- ['SELECT', 'avg', '(', 'year', ')', 'FROM', 'table_', 'WHERE', 'ten', 'year', '%', 'change', 'EQL', '67.3', 'AND', 'rank', 'among', 'provinces', 'GT', '5']\n",
            "Generated Query- SELECT avg ( rank ) FROM table_ WHERE AND EQL SOS AND SOS EQL SOS SOS <EOS>\n",
            "\n",
            "English Question- ['when', 'was', 'the', 'winning', 'score', '–12', '(', '69-66-72-65=272', ')', '?']\n",
            "Ground truth Query- ['SELECT', 'date', 'FROM', 'table_', 'WHERE', 'winning', 'score', 'EQL', '–12', '(', '69-66-72-65=272', ')']\n",
            "Generated Query- SELECT winning FROM table_ WHERE score EQL SOS ( SOS ) ) <EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftUkpFxjA5mf"
      },
      "source": [
        "References:\n",
        "1. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
      ]
    }
  ]
}