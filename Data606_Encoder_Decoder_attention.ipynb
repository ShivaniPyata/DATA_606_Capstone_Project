{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data606_Encoder-Decoder_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOizjfzcZs/TLoOrccv4zS3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxdJk93q3OQL"
      },
      "source": [
        "#**<center>Natural Language Text to SQL Query Conversion**\n",
        "##**<center>GRU based Encoder-Decoder model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxjRpT-l_ERw"
      },
      "source": [
        "###**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCTwwBebsBt",
        "outputId": "b9193f00-18f2-4bae-b4e0-f85703934e3e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3REbOtKc3VHz",
        "outputId": "df302bd6-23d9-4306-841a-350ea5a64edf"
      },
      "source": [
        "pip install records"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: records in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: SQLAlchemy; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from records) (1.4.7)\n",
            "Requirement already satisfied: openpyxl<2.5.0 in /usr/local/lib/python3.7/dist-packages (from records) (2.4.11)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from records) (0.6.2)\n",
            "Requirement already satisfied: tablib>=0.11.4 in /usr/local/lib/python3.7/dist-packages (from records) (3.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy; python_version >= \"3.0\"->records) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy; python_version >= \"3.0\"->records) (3.10.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy; python_version >= \"3.0\"->records) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy; python_version >= \"3.0\"->records) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeVZdo0s3XPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47c8b61-80ff-4551-d49d-2145c350427e"
      },
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import records\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import json\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import open\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ImportWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwAD6WS3aFA",
        "outputId": "90db17a6-ae8c-477e-baf1-95792c12d134"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import * \n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDU6X2K73cb4"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/lib/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-YsqTBi3izZ"
      },
      "source": [
        "from lib_db import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1fLEM3N-AVV"
      },
      "source": [
        "\"\"\"\n",
        "Device\n",
        "\"\"\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQpxR1D24c8_"
      },
      "source": [
        "###**Preparing training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmVXDnwNz8NW"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FsZ9W6i3l1e"
      },
      "source": [
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = defaultdict(int)\n",
        "        self.word2count = defaultdict(int)\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def add_sent(self, sentence):\n",
        "        for word in sentence:\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GYXJfKQW9ff"
      },
      "source": [
        "\"\"\"\n",
        "To Load the train data from file into the memory  \n",
        "\"\"\"\n",
        "def read_Lang(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = pd.read_json(\"/content/drive/MyDrive/Data606_finalproject/output/tokenized_train.jsonl\", lines=True)\n",
        "\n",
        "    # Split every line into pairs\n",
        "    pairs= []\n",
        "    for idx, row in lines.iterrows():\n",
        "        tokens_en = row[\"tokenized_question\"]\n",
        "        tokens_sql = row[\"tokenized_query\"]\n",
        "        pairs.append([tokens_en, tokens_sql])\n",
        "\n",
        "    in_lang = Lang(lang1)\n",
        "    out_lang = Lang(lang2)\n",
        "\n",
        "    return in_lang, out_lang, pairs\n",
        "\n",
        "\n",
        "def data_prepare(lang1, lang2):\n",
        "    in_lang, out_lang, pairs = read_Lang(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"\\nCounting words...\")\n",
        "    for pair in pairs:\n",
        "        in_lang.add_sent(pair[0])\n",
        "        out_lang.add_sent(pair[1])\n",
        "    print(\"Number of words in\", in_lang.name, in_lang.n_words)\n",
        "    print(\"Number of words in\", out_lang.name, out_lang.n_words)\n",
        "    return in_lang, out_lang, pairs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMSFlGLW6XL1",
        "outputId": "1684c266-ace5-48d7-8697-4c91ad105aa6"
      },
      "source": [
        "global in_lang\n",
        "global out_lang\n",
        "global pairs\n",
        "\n",
        "\n",
        "in_lang, out_lang, pairs= data_prepare(\"en\", \"sql\")\n",
        "print(\"\\nRandom Question and query pair looks like:\\n\")\n",
        "print(random.choice(pairs))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 56355 sentence pairs\n",
            "\n",
            "Counting words...\n",
            "Number of words in en 39685\n",
            "Number of words in sql 38066\n",
            "\n",
            "Random Question and query pair looks like:\n",
            "\n",
            "[['when', 'type', 'was', 'rowexit', 'what', 'was', 'the', 'category', '?'], ['SELECT', 'category', 'FROM', 'table_', 'WHERE', 'type', 'EQL', 'rowexit']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K8tcITaX_3Q"
      },
      "source": [
        "\"\"\"\n",
        "To convert language pairs into tensors to input the model\n",
        "\"\"\"\n",
        "def indexes_Sentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence]\n",
        "\n",
        "def tensor_Sentence(lang, sentence):\n",
        "    indexes = indexes_Sentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensors_Pair(pair):\n",
        "    input_tensor = tensor_Sentence(in_lang, pair[0])\n",
        "    target_tensor = tensor_Sentence(out_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5buBZ7IpcLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2b2e62-7efb-4f5f-9e38-40514b9f3c45"
      },
      "source": [
        "pair = pairs[0]\n",
        "print(pair)\n",
        "training_pairs = tensors_Pair(pair)\n",
        "print(\"\\nTensor for Question and query pair looks like:\\n\")\n",
        "training_pairs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['tell', 'me', 'what', 'the', 'notes', 'are', 'for', 'south', 'australia'], ['SELECT', 'notes', 'FROM', 'table_', 'WHERE', 'current', 'slogan', 'EQL', 'south', 'australia']]\n",
            "\n",
            "Tensor for Question and query pair looks like:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2],\n",
              "         [ 3],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [ 6],\n",
              "         [ 7],\n",
              "         [ 8],\n",
              "         [ 9],\n",
              "         [10],\n",
              "         [ 1]], device='cuda:0'), tensor([[ 2],\n",
              "         [ 3],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [ 6],\n",
              "         [ 7],\n",
              "         [ 8],\n",
              "         [ 9],\n",
              "         [10],\n",
              "         [11],\n",
              "         [ 1]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxNkBGhVWhx8"
      },
      "source": [
        "\"\"\"\n",
        "To prepare validation data\n",
        "\"\"\"\n",
        "def read_Lang_val(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = pd.read_json(\"/content/drive/MyDrive/Data606_finalproject/output/tokenized_test.jsonl\", lines=True)\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = []\n",
        "    for idx, row in lines.iterrows():\n",
        "        tokens_en = row[\"tokenized_question\"]\n",
        "        tokens_sql = row[\"tokenized_query\"]\n",
        "        pairs.append([tokens_en, tokens_sql])\n",
        "\n",
        "    in_lang = Lang(lang1)\n",
        "    out_lang = Lang(lang2)\n",
        "\n",
        "    return in_lang, out_lang, pairs\n",
        "\n",
        "\n",
        "def Val_Data(lang1, lang2):\n",
        "    in_lang, out_lang, pairs = read_Lang_val(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        in_lang.add_sent(pair[0])\n",
        "        out_lang.add_sent(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(in_lang.name, in_lang.n_words)\n",
        "    print(out_lang.name, out_lang.n_words)\n",
        "    return in_lang, out_lang, pairs\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrlhQBvzgAYC",
        "outputId": "b9961c90-956a-4972-9cb7-67f7e6b18f6d"
      },
      "source": [
        "global pairs_test\n",
        "\n",
        "in_lang, out_lang, pairs_test= Val_Data(\"en\", \"sql\")\n",
        "print(\"\\nRandom Question and query pair looks like:\\n\")\n",
        "print(random.choice(pairs_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 15878 sentence pairs\n",
            "Trimmed to 15878 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "en 16358\n",
            "sql 15618\n",
            "\n",
            "Random Question and query pair looks like:\n",
            "\n",
            "[['what', 'is', 'the', 'type', 'when', 'the', 'year', '(', 's', ')', 'is', '1982', '?'], ['SELECT', 'type', 'FROM', 'table_', 'WHERE', 'year', '(', 's', ')', 'EQL', '1982']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg9XFtuyBH-C"
      },
      "source": [
        "###**Building GRU-based encoder and decoder model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9-GzzUt_4W8"
      },
      "source": [
        "###**Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzdXTwk_0uR"
      },
      "source": [
        "\"\"\"\n",
        "RNN Encoder\n",
        "\"\"\"\n",
        "class RNN_Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,dropout):\n",
        "        super(RNN_Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcTLxtc4BWng"
      },
      "source": [
        "###**Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoWoXR99rIZI"
      },
      "source": [
        "\"\"\"\n",
        "Decoder\n",
        "\"\"\"\n",
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QYMrxJPImoo"
      },
      "source": [
        "###**Attention Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p48-AWuo_Fsi"
      },
      "source": [
        "MAX_LENGTH = 50\n",
        "\"\"\"\n",
        "Attention Decoder\n",
        "\"\"\"\n",
        "\n",
        "class RNN_AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p, max_length=MAX_LENGTH):\n",
        "        super(RNN_AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcAcOZuRBgI0"
      },
      "source": [
        "###**Training function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlj9Nj4QI3-o"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "          criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length): \n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTHJCln5BpQI"
      },
      "source": [
        "###**Time Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb6APnew-FrE"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3QuP7lCDmN"
      },
      "source": [
        "###**Function to plot graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5crM3Ec-Lgt"
      },
      "source": [
        "def showPlot(points, plot_name):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.savefig(plot_name + \".png\")\n",
        "\n",
        "\n",
        "def plot_data(x, y, xlabel = \"x\", ylabel = \"y\", label = 'plot'):\n",
        "\tplt.figure()\n",
        "\tplt.plot(x, y)\n",
        "\tplt.xlabel(\"Epochs\")\n",
        "\tplt.ylabel(\"Loss\")\n",
        "\tprint(\"Generating plot for \", label)\n",
        "\tplt.savefig(\"./\" + label + \".png\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H3FM37YBu_O"
      },
      "source": [
        "###**To call training function and print graphs and logs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGIaFv--Io3"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=1):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensors_Pair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        \n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                      iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses, \"Baseline loss\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1iWfeTbCPGp"
      },
      "source": [
        "###**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "D56R6h_DDIBQ",
        "outputId": "5c8f2efa-cbd1-4925-c43c-0cded625c2e4"
      },
      "source": [
        "dropout = 0.5\n",
        "dropout_p = 0.5\n",
        "hidden_size = 256\n",
        "\n",
        "\n",
        "encoder1 = RNN_Encoder(in_lang.n_words, hidden_size,dropout).to(device)\n",
        "\n",
        "attn_decoder1 = RNN_AttnDecoder(hidden_size, out_lang.n_words, dropout_p).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, n_iters = 15000, print_every=1000, plot_every=1000,learning_rate= 0.001)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 27s (- 6m 18s) (1000 6%) 3.6916\n",
            "0m 53s (- 5m 47s) (2000 13%) 3.1402\n",
            "1m 19s (- 5m 19s) (3000 20%) 2.9889\n",
            "1m 46s (- 4m 52s) (4000 26%) 2.7877\n",
            "2m 12s (- 4m 25s) (5000 33%) 2.8062\n",
            "2m 39s (- 3m 59s) (6000 40%) 2.6672\n",
            "3m 5s (- 3m 32s) (7000 46%) 2.6586\n",
            "3m 32s (- 3m 5s) (8000 53%) 2.6249\n",
            "3m 59s (- 2m 39s) (9000 60%) 2.5238\n",
            "4m 26s (- 2m 13s) (10000 66%) 2.5257\n",
            "4m 53s (- 1m 46s) (11000 73%) 2.4758\n",
            "5m 19s (- 1m 19s) (12000 80%) 2.3474\n",
            "5m 46s (- 0m 53s) (13000 86%) 2.3661\n",
            "6m 13s (- 0m 26s) (14000 93%) 2.3654\n",
            "6m 40s (- 0m 0s) (15000 100%) 2.3004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csymIFaCi1A"
      },
      "source": [
        "###**Model evaluation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlmNUob3-OZM"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=50):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensor_Sentence(in_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(out_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_cHrGS7-RHN"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=20):\n",
        "    correct = 0\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('\\nEnglish Question-', pair[0])\n",
        "        print('Ground truth Query-', pair[1])\n",
        "        generated_tokens, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        generated_query = ' '.join(generated_tokens)\n",
        "        if generated_query[:-6] == pair[1]:\n",
        "            correct += 1\n",
        "        print('Generated Query-', generated_query)\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIuxVBPq-UCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23b3940-ba3c-4a31-d53a-e4ef42f4bfd0"
      },
      "source": [
        "\n",
        "evaluateRandomly(encoder1, attn_decoder1)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "English Question- ['what', 'is', 'the', 'highest', 'amount', 'of', 'plays', 'for', 'fluminense', '?']\n",
            "Ground truth Query- ['SELECT', 'max', '(', 'played', ')', 'FROM', 'table_', 'WHERE', 'team', 'EQL', 'fluminense']\n",
            "Generated Query- SELECT max ( FROM ) WHERE WHERE EQL EQL <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'model', 'number', ',', 'when', 'voltage', 'is', '2.0v', ',', 'and', 'when', 'frequency', 'is', '350', 'mhz', '?']\n",
            "Ground truth Query- ['SELECT', 'model', 'number', 'FROM', 'table_', 'WHERE', 'voltage', 'EQL', '2.0v', 'AND', 'frequency', 'EQL', '350', 'mhz']\n",
            "Generated Query- SELECT model FROM table_ WHERE WHERE EQL SOS SOS SOS SOS SOS SOS AND <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'best', 'bowling', 'score', 'when', 'the', 'average', 'was', '23.33', '?']\n",
            "Ground truth Query- ['SELECT', 'best', 'bowling', 'FROM', 'table_', 'WHERE', 'average', 'EQL', '23.33']\n",
            "Generated Query- SELECT best FROM table_ WHERE average EQL SOS SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', '2fm', 'for', 'rnag', '94.4', '?']\n",
            "Ground truth Query- ['SELECT', '2fm', '(', 'mhz', ')', 'FROM', 'table_', 'WHERE', 'rnag', '(', 'mhz', ')', 'EQL', '94.4']\n",
            "Generated Query- SELECT SOS FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'happened', 'in', 'week', '12', 'when', 'week', '13', 'resulted', 'in', 'tennessee', '(', '9-1', ')', '?']\n",
            "Ground truth Query- ['SELECT', 'week', '12', 'nov', '19', 'FROM', 'table_', 'WHERE', 'week', '13', 'nov', '26', 'EQL', 'tennessee', '(', '9-1', ')']\n",
            "Generated Query- SELECT avg ( week ) FROM table_ WHERE week EQL 3 AND week EQL 3 <EOS>\n",
            "\n",
            "English Question- ['which', 'candidate', 'won', '61.47', '%', 'of', 'the', 'votes', '?']\n",
            "Ground truth Query- ['SELECT', 'candidate', 'FROM', 'table_', 'WHERE', 'share', 'of', 'votes', 'EQL', '61.47', '%']\n",
            "Generated Query- SELECT % FROM table_ WHERE % EQL % % <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'years', 'for', 'engin', '5.7l', 'hemi', 'v8', '?']\n",
            "Ground truth Query- ['SELECT', 'years', 'FROM', 'table_', 'WHERE', 'engine', 'EQL', '5.7l', 'hemi', 'v8']\n",
            "Generated Query- SELECT years FROM table_ WHERE SOS EQL SOS SOS <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'bronze', 'medals', 'were', 'received', 'by', 'the', 'nation', 'that', 'ranked', 'less', 'than', '5', 'and', 'received', 'more', 'than', '2', 'gold', 'medals', ',', 'less', 'than', '4', 'silver', 'medals', 'with', 'a', 'total', 'of', '9', 'medals', '?']\n",
            "Ground truth Query- ['SELECT', 'avg', '(', 'bronze', ')', 'FROM', 'table_', 'WHERE', 'rank', 'LT', '5', 'AND', 'gold', 'GT', '2', 'AND', 'total', 'EQL', '9', 'AND', 'silver', 'LT', '4']\n",
            "Generated Query- SELECT COUNT ( bronze ) FROM table_ WHERE rank EQL 5 AND silver GT 5 AND silver LT 5 <EOS>\n",
            "\n",
            "English Question- ['when', '3t7458', 'is', 'the', 'production', 'code', 'who', 'are', 'the', 'writers', '?']\n",
            "Ground truth Query- ['SELECT', 'written', 'by', 'FROM', 'table_', 'WHERE', 'production', 'code', 'EQL', '3t7458']\n",
            "Generated Query- SELECT COUNT ( original by ) FROM table_ WHERE production code EQL SOS <EOS>\n",
            "\n",
            "English Question- ['with', 'less', 'than', '7', 'silver', 'medals', ',', 'how', 'many', 'gold', 'medals', 'did', 'canada', 'receive', '?']\n",
            "Ground truth Query- ['SELECT', 'max', '(', 'gold', ')', 'FROM', 'table_', 'WHERE', 'nation', 'EQL', 'canada', 'AND', 'silver', 'LT', '7']\n",
            "Generated Query- SELECT avg ( total ) FROM table_ WHERE rank EQL 3 AND silver LT 3 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'hardness', 'for', 'the', 'alloy', 'that', 'is', 'liquid', 'at', '243', 'degrees', 'c', '?']\n",
            "Ground truth Query- ['SELECT', 'hardness', 'FROM', 'table_', 'WHERE', 'liquid', 'at', '(', 'c', ')', 'EQL', '243']\n",
            "Generated Query- SELECT site FROM table_ WHERE WHERE EQL EQL SOS SOS SOS SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'game', '9', \"'s\", 'record', '?']\n",
            "Ground truth Query- ['SELECT', 'record', 'FROM', 'table_', 'WHERE', 'game', 'EQL', '9']\n",
            "Generated Query- SELECT record FROM table_ WHERE record EQL 1-1 <EOS>\n",
            "\n",
            "English Question- ['name', 'the', 'sum', 'of', 'points', 'for', '1984']\n",
            "Ground truth Query- ['SELECT', 'sum', '(', 'points', ')', 'FROM', 'table_', 'WHERE', 'year', 'LT', '1984']\n",
            "Generated Query- SELECT points FROM table_ WHERE points EQL EQL <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'french', 'word', 'where', 'the', 'german', 'word', 'is', 'filtern', '?']\n",
            "Ground truth Query- ['SELECT', 'french', 'FROM', 'table_', 'WHERE', 'german', 'EQL', 'filtern']\n",
            "Generated Query- SELECT type FROM table_ WHERE country EQL SOS <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'games', 'were', 'played', 'against', 'the', 'chicago', 'bears', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'record', ')', 'FROM', 'table_', 'WHERE', 'opponent', 'EQL', 'chicago', 'bears']\n",
            "Generated Query- SELECT COUNT ( table_ ) FROM table_ WHERE team EQL EQL <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'sum', 'of', 'the', 'total', 'of', 'the', 'player', 'who', 'won', 'in', '1979', '?']\n",
            "Ground truth Query- ['SELECT', 'sum', '(', 'total', ')', 'FROM', 'table_', 'WHERE', 'year', '(', 's', ')', 'won', 'EQL', '1979']\n",
            "Generated Query- SELECT sum ( total ) FROM table_ WHERE player EQL north <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'segment', 'c', 'in', 's07e05']\n",
            "Ground truth Query- ['SELECT', 'segment', 'c', 'FROM', 'table_', 'WHERE', 'netflix', 'EQL', 's07e05']\n",
            "Generated Query- SELECT SOS FROM FROM table_ WHERE WHERE EQL SOS SOS SOS <EOS>\n",
            "\n",
            "English Question- ['on', 'october', '24', ',', 'who', 'played', 'at', 'home', 'when', 'there', 'was', 'a', 'decision', 'of', 'ward', '?']\n",
            "Ground truth Query- ['SELECT', 'home', 'FROM', 'table_', 'WHERE', 'decision', 'EQL', 'ward', 'AND', 'date', 'EQL', 'october', '24']\n",
            "Generated Query- SELECT visitor FROM table_ WHERE home EQL EQL AND AND EQL <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'episodes', 'originally', 'aired', 'on', 'august', '31', ',', '1995', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'title', ')', 'FROM', 'table_', 'WHERE', 'original', 'air', 'date', 'EQL', 'august', '31', ',', '1995']\n",
            "Generated Query- SELECT COUNT ( date table_ WHERE WHERE date EQL december 8 <EOS>\n",
            "\n",
            "English Question- ['when', 'the', 'new', 'orleans', 'saints', 'were', 'visiting', 'texas', 'stadium', ',', 'what', 'was', 'the', 'final', 'score', '?']\n",
            "Ground truth Query- ['SELECT', 'final', 'score', 'FROM', 'table_', 'WHERE', 'stadium', 'EQL', 'texas', 'stadium', 'AND', 'visiting', 'team', 'EQL', 'new', 'orleans', 'saints']\n",
            "Generated Query- SELECT final final FROM table_ WHERE opponent EQL EQL AND date EQL EQL 26 <EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xik2SBj48dlU"
      },
      "source": [
        "Reference:\n",
        "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
      ]
    }
  ]
}