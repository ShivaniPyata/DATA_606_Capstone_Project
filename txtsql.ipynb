{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "txtsql.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIvzlmLYl9aDi/FdogbtOc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3HSyUiuQA2m"
      },
      "source": [
        "#**<center>Natural Language Text to SQL Query Conversion**\n",
        "##**<center>Augmented Pointer Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfvNEvMOHnnE",
        "outputId": "d5d422d2-0c4c-49bf-f7be-6ae68a1c79c6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnfGqTHdOXgj",
        "outputId": "b3550a70-5e1d-4ba1-8098-13523df3a4a2"
      },
      "source": [
        "pip install 'sqlalchemy>=1.3.0,<1.4.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sqlalchemy<1.4.0,>=1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/44/a86070dda790ce94cd7d9fb9281cd614c7d30850ed774ace9a84d0d5d491/SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sqlalchemy\n",
            "  Found existing installation: SQLAlchemy 1.4.7\n",
            "    Uninstalling SQLAlchemy-1.4.7:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.7\n",
            "Successfully installed sqlalchemy-1.3.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzW27N7iOa0b",
        "outputId": "c5b2902a-f181-4a13-c764-f0f11e8e9a75"
      },
      "source": [
        "pip install records"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting records\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/93/2467c761ea3729713ab97842a46cc125ad09d14a0a174cb637bee4983911/records-0.5.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: SQLAlchemy; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from records) (1.3.24)\n",
            "Collecting openpyxl<2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/26/0bd1a39776f53b4f28e5bb1d26b3fcd99068584a7e1ddca4e09c0d5fd592/openpyxl-2.4.11.tar.gz (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from records) (0.6.2)\n",
            "Collecting tablib>=0.11.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/85/078fc037b15aa1120d6a0287ec9d092d93d632ab01a0e7a3e69b4733da5e/tablib-3.0.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.4.1)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.0.1)\n",
            "Building wheels for collected packages: openpyxl\n",
            "  Building wheel for openpyxl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openpyxl: filename=openpyxl-2.4.11-py2.py3-none-any.whl size=222821 sha256=99fa02b2a477dfab8fea48b201b18572d80abaa954bb44dff0fb227fadf0d58c\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/44/27/63b211425501ad51d197ff8ed00e9e469e38b9e516cb69b1c2\n",
            "Successfully built openpyxl\n",
            "Installing collected packages: openpyxl, tablib, records\n",
            "  Found existing installation: openpyxl 2.5.9\n",
            "    Uninstalling openpyxl-2.5.9:\n",
            "      Successfully uninstalled openpyxl-2.5.9\n",
            "Successfully installed openpyxl-2.4.11 records-0.5.3 tablib-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUCi_adoOdAI",
        "outputId": "a281994d-2bbf-47e8-cdbc-2ba8ddda9c38"
      },
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import records\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import json\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import open\n",
        "from __future__ import unicode_literals, print_function, division"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToI2KwTq43q"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyBiVR_aOddj",
        "outputId": "8dac4037-383b-4718-a946-20cf361c36f1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import * \n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoVmMU4gOfbb"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/lib/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MA8yLepOhhl"
      },
      "source": [
        "from lib_project import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8-CJeEg2WFc"
      },
      "source": [
        "#constants\n",
        "MAX_LENGTH = 50\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "teacher_forcing_ratio = 1\n",
        "GPU = True\n",
        "BATCH_SIZE = 64\n",
        "TRAINING_EPOCHS = 30\n",
        "LEARNING_RATE = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSgIHy3JQbwo"
      },
      "source": [
        "##**Function to load the datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YyL94ez9s5f"
      },
      "source": [
        "def load_dataset(dataset_to_load):\n",
        "    \"\"\"Load the given dataset into memory.\"\"\"\n",
        "    print(\"Loading dataset : \", dataset_to_load)\n",
        "    sql_data_path = '/content/drive/MyDrive/Data606_finalproject/output/tokenized_' + dataset_to_load + '.jsonl'\n",
        "    table_data_path = '/content/drive/MyDrive/Data606_finalproject/output/tokenized_' + dataset_to_load + '.tables.jsonl'\n",
        "    db_file = '/content/drive/MyDrive/Data606_finalproject/data/' + dataset_to_load + '.db'\n",
        "\n",
        "    sql_data = []\n",
        "    table_data = {}\n",
        "    with open(sql_data_path, encoding=\"utf-8\") as lines:\n",
        "        for line in lines:\n",
        "            sql = json.loads(line.strip())\n",
        "            \n",
        "\n",
        "    # Build a mapping of the tables with table_id as the key\n",
        "    with open(table_data_path, encoding=\"utf-8\") as lines:\n",
        "        for line in lines:\n",
        "            tab = json.loads(line.strip())\n",
        "            table_data[tab[u'id']] = tab\n",
        "\n",
        "    return sql_data, table_data, db_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVGyzn6-SUoq"
      },
      "source": [
        "##**Function to plot graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8m6orfWPEeH"
      },
      "source": [
        "\n",
        "def showPlot(points, plot_name):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.savefig(plot_name + \".png\")\n",
        "\n",
        "\n",
        "def plot_data(x, y, xlabel = \"x\", ylabel = \"y\", label = 'plot'):\n",
        "\tplt.figure()\n",
        "\tplt.plot(x, y)\n",
        "\tplt.xlabel(xlabel)\n",
        "\tplt.ylabel(ylabel)\n",
        "\tprint(\"\\nGenerating plot for \", label)\n",
        "\tplt.savefig(\"./\" + label + \".png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6CxbysGSdth"
      },
      "source": [
        "##**Function for word embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXmus4nYUUIh"
      },
      "source": [
        "class WordEmbedding(nn.Module):\n",
        "    def __init__(self, word_emb, N_word, gpu, SQL_SYNTAX_TOKENS, our_model):\n",
        "        super(WordEmbedding, self).__init__()\n",
        "        self.N_word = N_word\n",
        "        self.our_model = our_model\n",
        "        self.gpu = gpu\n",
        "        self.SQL_SYNTAX_TOKENS = SQL_SYNTAX_TOKENS\n",
        "        self.word_emb = word_emb\n",
        "\n",
        "\n",
        "    def gen_x_batch(self, q, col):\n",
        "        B = len(q)\n",
        "        val_embs = []\n",
        "        val_len = np.zeros(B, dtype=np.int64)\n",
        "        for i, (one_q, one_col) in enumerate(zip(q, col)):\n",
        "            q_val = list(map(lambda x: self.word_emb.get(x, np.zeros(self.N_word, dtype=np.float32)), one_q))\n",
        "            if self.our_model:\n",
        "                val_embs.append([np.zeros(self.N_word, dtype=np.float32)] + q_val + [\n",
        "                    np.zeros(self.N_word, dtype=np.float32)])  # <BEG> and <END>\n",
        "                val_len[i] = 1 + len(q_val) + 1\n",
        "            else:\n",
        "                one_col_all = [x for toks in one_col for x in toks + [',']]\n",
        "                col_val = list(\n",
        "                    map(lambda x: self.word_emb.get(x, np.zeros(self.N_word, dtype=np.float32)), one_col_all))\n",
        "                val_embs.append([np.zeros(self.N_word, dtype=np.float32) for _ in self.SQL_SYNTAX_TOKENS] + col_val + [\n",
        "                    np.zeros(self.N_word, dtype=np.float32)] + q_val + [np.zeros(self.N_word, dtype=np.float32)])\n",
        "                val_len[i] = len(self.SQL_SYNTAX_TOKENS) + len(col_val) + 1 + len(q_val) + 1\n",
        "        max_len = max(val_len)\n",
        "\n",
        "        val_emb_array = np.zeros((B, max_len, self.N_word), dtype=np.float32)\n",
        "        for i in range(B):\n",
        "            for t in range(len(val_embs[i])):\n",
        "                val_emb_array[i, t, :] = val_embs[i][t]\n",
        "        val_inp = torch.from_numpy(val_emb_array)\n",
        "        if self.gpu:\n",
        "            val_inp = val_inp.cuda()\n",
        "        val_inp_var = Variable(val_inp)\n",
        "        return val_inp_var, val_len\n",
        "\n",
        "\n",
        "    def gen_col_batch(self, cols):\n",
        "        ret = []\n",
        "        col_len = np.zeros(len(cols), dtype=np.int64)\n",
        "\n",
        "        names = []\n",
        "        for b, one_cols in enumerate(cols):\n",
        "            names = names + one_cols\n",
        "            col_len[b] = len(one_cols)\n",
        "\n",
        "        name_inp_var, name_len = self.str_list_to_batch(names)\n",
        "        return name_inp_var, name_len, col_len\n",
        "\n",
        "\n",
        "    def str_list_to_batch(self, str_list):\n",
        "        B = len(str_list)\n",
        "\n",
        "        val_embs = []\n",
        "        val_len = np.zeros(B, dtype=np.int64)\n",
        "        for i, one_str in enumerate(str_list):\n",
        "            val = [self.word_emb.get(x, np.zeros(self.N_word, dtype=np.float32)) for x in one_str]\n",
        "            val_embs.append(val)\n",
        "            val_len[i] = len(val)\n",
        "        max_len = max(val_len)\n",
        "\n",
        "        val_emb_array = np.zeros(\n",
        "            (B, max_len, self.N_word), dtype=np.float32)\n",
        "        for i in range(B):\n",
        "            for t in range(len(val_embs[i])):\n",
        "                val_emb_array[i, t, :] = val_embs[i][t]\n",
        "        val_inp = torch.from_numpy(val_emb_array)\n",
        "        if self.gpu:\n",
        "            val_inp = val_inp.cuda()\n",
        "        val_inp_var = Variable(val_inp)\n",
        "\n",
        "        return val_inp_var, val_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBdWn75Sxsy"
      },
      "source": [
        "##**Aggregation Predictor model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5cg3y2cVpOY"
      },
      "source": [
        "class AggregationPredictor(nn.Module):\n",
        "    def __init__(self, N_word, N_h, N_depth):\n",
        "        super(AggregationPredictor, self).__init__()\n",
        "\n",
        "        self.agg_lstm = nn.LSTM(input_size=N_word, hidden_size=N_h // 2,\n",
        "                                num_layers=N_depth, batch_first=True,\n",
        "                                dropout=0.3, bidirectional=True)\n",
        "\n",
        "        self.agg_att = nn.Linear(N_h, 1)\n",
        "        self.agg_out = nn.Sequential(nn.Linear(N_h, N_h), nn.Tanh(), nn.Linear(N_h, 6))\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x_emb_var, x_len, col_inp_var=None, col_name_len=None, col_len=None, col_num=None, ground_truth_sel=None):\n",
        "        B = len(x_emb_var)\n",
        "        max_x_len = max(x_len)\n",
        "\n",
        "        h_enc, _ = run_lstm(self.agg_lstm, x_emb_var, x_len)\n",
        "        att_val = self.agg_att(h_enc).squeeze()\n",
        "\n",
        "        for idx, num in enumerate(x_len):\n",
        "            if num < max_x_len:\n",
        "                att_val[idx, num:] = -100\n",
        "        att = self.softmax(att_val)\n",
        "\n",
        "        K_agg = (h_enc * att.unsqueeze(2).expand_as(h_enc)).sum(1)\n",
        "        agg_score = self.agg_out(K_agg)\n",
        "        return agg_score\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3IJvbsNS4Uf"
      },
      "source": [
        "##**Selection Predictor Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq9kxo_AV3O8"
      },
      "source": [
        "class SelectionClausePredictor(nn.Module):\n",
        "    def __init__(self, N_word, N_h, N_depth, max_tok_num):\n",
        "        super(SelectionClausePredictor, self).__init__()\n",
        "        self.max_tok_num = max_tok_num\n",
        "        self.sel_lstm = nn.LSTM(input_size=N_word, hidden_size=N_h // 2, num_layers=N_depth, batch_first=True,\n",
        "                                dropout=0.3, bidirectional=True)\n",
        "        self.sel_att = nn.Linear(N_h, 1)\n",
        "        self.sel_col_name_enc = nn.LSTM(input_size=N_word, hidden_size=N_h // 2,\n",
        "                                        num_layers=N_depth, batch_first=True,\n",
        "                                        dropout=0.3, bidirectional=True)\n",
        "        self.sel_out_K = nn.Linear(N_h, N_h)\n",
        "        self.sel_out_col = nn.Linear(N_h, N_h)\n",
        "        self.sel_out = nn.Sequential(nn.Tanh(), nn.Linear(N_h, 1))\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x_emb_var, x_len, col_inp_var,\n",
        "                col_name_len, col_len, col_num):\n",
        "        B = len(x_emb_var)\n",
        "        max_x_len = max(x_len)\n",
        "\n",
        "        e_col, _ = col_name_encode(col_inp_var, col_name_len,\n",
        "                                   col_len, self.sel_col_name_enc)\n",
        "\n",
        "        h_enc, _ = run_lstm(self.sel_lstm, x_emb_var, x_len)\n",
        "        att_val = self.sel_att(h_enc).squeeze()\n",
        "        for idx, num in enumerate(x_len):\n",
        "            if num < max_x_len:\n",
        "                att_val[idx, num:] = -100\n",
        "        att = self.softmax(att_val)\n",
        "        K_sel = (h_enc * att.unsqueeze(2).expand_as(h_enc)).sum(1)\n",
        "        K_sel_expand = K_sel.unsqueeze(1)\n",
        "\n",
        "        sel_score = self.sel_out(self.sel_out_K(K_sel_expand) + \\\n",
        "                                 self.sel_out_col(e_col)).squeeze()\n",
        "        max_col_num = max(col_num)\n",
        "        for idx, num in enumerate(col_num):\n",
        "            if num < max_col_num:\n",
        "                sel_score[idx, num:] = -100\n",
        "\n",
        "        return sel_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isWIWgxUS8Yw"
      },
      "source": [
        "##**Condition Predictor model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwRAUjLIVv4h"
      },
      "source": [
        "class ConditionPredictor(nn.Module):\n",
        "    def __init__(self, N_word, N_h, N_depth, max_col_num, max_tok_num, gpu):\n",
        "        super(ConditionPredictor, self).__init__()\n",
        "        print(\"txtsql where prediction\")\n",
        "        self.N_h = N_h\n",
        "        self.max_tok_num = max_tok_num\n",
        "        self.max_col_num = max_col_num\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.cond_lstm = nn.LSTM(input_size=N_word, hidden_size=N_h // 2,\n",
        "                                 num_layers=N_depth, batch_first=True,\n",
        "                                 dropout=0.3, bidirectional=True)\n",
        "        self.cond_decoder = nn.LSTM(input_size=self.max_tok_num,\n",
        "                                    hidden_size=N_h, num_layers=N_depth,\n",
        "                                    batch_first=True, dropout=0.3)\n",
        "\n",
        "        self.cond_out_g = nn.Linear(N_h, N_h)\n",
        "        self.cond_out_h = nn.Linear(N_h, N_h)\n",
        "        self.cond_out = nn.Sequential(nn.Tanh(), nn.Linear(N_h, 1))\n",
        "\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def gen_ground_truth_batch(self, tok_seq, gen_inp=True):\n",
        "        B = len(tok_seq)\n",
        "        ret_len = np.array([len(one_tok_seq) - 1 for one_tok_seq in tok_seq])\n",
        "        max_len = max(ret_len)\n",
        "        ret_array = np.zeros((B, max_len, self.max_tok_num), dtype=np.float32)\n",
        "        for b, one_tok_seq in enumerate(tok_seq):\n",
        "            out_one_tok_seq = one_tok_seq[:-1] if gen_inp else one_tok_seq[1:]\n",
        "            for t, tok_id in enumerate(out_one_tok_seq):\n",
        "                ret_array[b, t, tok_id] = 1\n",
        "\n",
        "        ret_inp = torch.from_numpy(ret_array)\n",
        "        if self.gpu:\n",
        "            ret_inp = ret_inp.cuda()\n",
        "        ret_inp_var = Variable(ret_inp)\n",
        "\n",
        "        return ret_inp_var, ret_len\n",
        "\n",
        "    def forward(self, x_emb_var, x_len, col_inp_var, col_name_len, col_len,\n",
        "                col_num, ground_truth_where, ground_truth_cond):\n",
        "        max_x_len = max(x_len)\n",
        "        B = len(x_len)\n",
        "\n",
        "        h_enc, hidden = run_lstm(self.cond_lstm, x_emb_var, x_len)\n",
        "        decoder_hidden = tuple(torch.cat((hid[:2], hid[2:]), dim=2)\n",
        "                               for hid in hidden)\n",
        "        if ground_truth_where is not None:\n",
        "            ground_truth_tok_seq, ground_truth_tok_len = self.gen_ground_truth_batch(ground_truth_where, gen_inp=True)\n",
        "            g_s, _ = run_lstm(self.cond_decoder,\n",
        "                              ground_truth_tok_seq, ground_truth_tok_len, decoder_hidden)\n",
        "\n",
        "            h_enc_expand = h_enc.unsqueeze(1)\n",
        "            g_s_expand = g_s.unsqueeze(2)\n",
        "            cond_score = self.cond_out(self.cond_out_h(h_enc_expand) +\n",
        "                                       self.cond_out_g(g_s_expand)).squeeze()\n",
        "            for idx, num in enumerate(x_len):\n",
        "                if num < max_x_len:\n",
        "                    cond_score[idx, :, num:] = -100\n",
        "        else:\n",
        "            h_enc_expand = h_enc.unsqueeze(1)\n",
        "            scores = []\n",
        "            done_set = set()\n",
        "\n",
        "            t = 0\n",
        "            init_inp = np.zeros((B, 1, self.max_tok_num), dtype=np.float32)\n",
        "            init_inp[:, 0, 7] = 1  # Set the <BEG> token\n",
        "            if self.gpu:\n",
        "                cur_inp = Variable(torch.from_numpy(init_inp).cuda())\n",
        "            else:\n",
        "                cur_inp = Variable(torch.from_numpy(init_inp))\n",
        "            cur_h = decoder_hidden\n",
        "            while len(done_set) < B and t < 100:\n",
        "                g_s, cur_h = self.cond_decoder(cur_inp, cur_h)\n",
        "                g_s_expand = g_s.unsqueeze(2)\n",
        "\n",
        "                cur_cond_score = self.cond_out(self.cond_out_h(h_enc_expand) +\n",
        "                                               self.cond_out_g(g_s_expand)).squeeze()\n",
        "                for b, num in enumerate(x_len):\n",
        "                    if num < max_x_len:\n",
        "                        cur_cond_score[b, num:] = -100\n",
        "                scores.append(cur_cond_score)\n",
        "\n",
        "                _, ans_tok_var = cur_cond_score.view(B, max_x_len).max(1)\n",
        "                ans_tok_var = ans_tok_var.unsqueeze(1)\n",
        "\n",
        "                ans_tok = ans_tok_var.data.cpu()\n",
        "                if self.gpu:  # To one-hot\n",
        "                    cur_inp = Variable(torch.zeros(\n",
        "                        B, self.max_tok_num).scatter_(1, ans_tok, 1).cuda())\n",
        "                else:\n",
        "                    cur_inp = Variable(torch.zeros(\n",
        "                        B, self.max_tok_num).scatter_(1, ans_tok, 1))\n",
        "                cur_inp = cur_inp.unsqueeze(1)\n",
        "\n",
        "                for idx, tok in enumerate(ans_tok.squeeze()):\n",
        "                    if tok == 1:  # Find the <END> token\n",
        "                        done_set.add(idx)\n",
        "                t += 1\n",
        "\n",
        "            cond_score = torch.stack(scores, 1)\n",
        "\n",
        "        return cond_score\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN1DO_xGTGfe"
      },
      "source": [
        "##**txtsql model comprising of three models** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNggx0s2Sqnb"
      },
      "source": [
        "class txtsql(nn.Module):\n",
        "    \"\"\"\n",
        "    txtsql Model which is internally comprised of three individual models\n",
        "    1. Aggregation predictor\n",
        "    2. Selection Predictor\n",
        "    3. Condition Predictor\n",
        "    \"\"\"\n",
        "    def __init__(self, word_emb, N_word, N_h=100, N_depth=2,\n",
        "                 gpu=False):\n",
        "        super(txtsql, self).__init__()\n",
        "\n",
        "        self.gpu = gpu\n",
        "        self.N_h = N_h\n",
        "        self.N_depth = N_depth\n",
        "\n",
        "        self.maximum_column_count = 45\n",
        "        self.maximum_token_count = 200\n",
        "        self.SQL_SYNTAX_TOKENS = [\n",
        "            '<UNK>', '<END>', 'WHERE', 'AND',\n",
        "            'EQL', 'GT', 'LT', '<BEG>'\n",
        "        ]\n",
        "\n",
        "        # Word embedding\n",
        "        self.embed_layer = WordEmbedding(word_emb, N_word, gpu, self.SQL_SYNTAX_TOKENS, our_model=False)\n",
        "\n",
        "        # Model for predicting aggregation clause\n",
        "        self.agg_pred = AggregationPredictor(N_word, N_h, N_depth)\n",
        "\n",
        "        # Model for predicting select columns\n",
        "        self.sel_pred = SelectionClausePredictor(N_word, N_h, N_depth, self.maximum_token_count)\n",
        "\n",
        "        # Model for predicting the conditions\n",
        "        self.cond_pred = ConditionPredictor(N_word, N_h, N_depth, self.maximum_column_count, self.maximum_token_count, gpu)\n",
        "\n",
        "        # Loss function\n",
        "        self.CE = nn.CrossEntropyLoss()\n",
        "        if gpu:\n",
        "            self.cuda()\n",
        "\n",
        "    def generate_ground_truth_where_seq(self, q, col, query):\n",
        "        ret_seq = []\n",
        "        for cur_q, cur_col, cur_query in zip(q, col, query):\n",
        "            connect_col = [tok for col_tok in cur_col for tok in col_tok + [',']]\n",
        "            all_toks = self.SQL_SYNTAX_TOKENS + connect_col + [None] + cur_q + [None]\n",
        "            cur_seq = [all_toks.index('<BEG>')]\n",
        "            if 'WHERE' in cur_query:\n",
        "                cur_where_query = cur_query[cur_query.index('WHERE'):]\n",
        "                cur_seq = cur_seq + list(map(lambda tok: all_toks.index(tok)\n",
        "                if tok in all_toks else 0, cur_where_query))\n",
        "            cur_seq.append(all_toks.index('<END>'))\n",
        "            ret_seq.append(cur_seq)\n",
        "        return ret_seq\n",
        "\n",
        "    def forward(self, q, col, col_num, ground_truth_where=None, ground_truth_cond=None, ground_truth_sel=None):\n",
        "        x_emb_var, x_len = self.embed_layer.gen_x_batch(q, col)\n",
        "        batch = self.embed_layer.gen_col_batch(col)\n",
        "        col_inp_var, col_name_len, col_len = batch\n",
        "\n",
        "        agg_score = self.agg_pred(x_emb_var, x_len)\n",
        "\n",
        "        sel_score = self.sel_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num)\n",
        "\n",
        "        cond_score = self.cond_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num, ground_truth_where, ground_truth_cond)\n",
        "\n",
        "        return (agg_score, sel_score, cond_score)\n",
        "\n",
        "    def loss(self, score, truth_num, ground_truth_where):\n",
        "        agg_score, sel_score, cond_score = score\n",
        "        loss = 0\n",
        "        agg_truth = list(map(lambda x: x[0], truth_num))\n",
        "        data = torch.from_numpy(np.array(agg_truth))\n",
        "        if self.gpu:\n",
        "            agg_truth_var = Variable(data.cuda())\n",
        "        else:\n",
        "            agg_truth_var = Variable(data)\n",
        "\n",
        "        loss += self.CE(agg_score, agg_truth_var.long())\n",
        "\n",
        "        sel_truth = list(map(lambda x: x[1], truth_num))\n",
        "        data = torch.from_numpy(np.array(sel_truth))\n",
        "        if self.gpu:\n",
        "            sel_truth_var = Variable(data).cuda()\n",
        "        else:\n",
        "            sel_truth_var = Variable(data)\n",
        "\n",
        "        loss += self.CE(sel_score, sel_truth_var.long())\n",
        "\n",
        "        for b in range(len(ground_truth_where)):\n",
        "            if self.gpu:\n",
        "                cond_truth_var = Variable(torch.from_numpy(np.array(ground_truth_where[b][1:])).cuda())\n",
        "            else:\n",
        "                cond_truth_var = Variable(torch.from_numpy(np.array(ground_truth_where[b][1:])))\n",
        "            cond_pred_score = cond_score[b, :len(ground_truth_where[b]) - 1]\n",
        "\n",
        "            loss += (self.CE(\n",
        "                cond_pred_score, cond_truth_var.long()) / len(ground_truth_where))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def check_accuracy(self, pred_queries, ground_truth_queries):\n",
        "        tot_err = agg_err = sel_err = cond_err = cond_num_err = \\\n",
        "            cond_col_err = cond_op_err = cond_val_err = 0.0\n",
        "        for b, (pred_qry, ground_truth_qry) in enumerate(zip(pred_queries, ground_truth_queries)):\n",
        "            good = True\n",
        "\n",
        "            agg_pred = pred_qry['agg']\n",
        "            agg_gt = ground_truth_qry['agg']\n",
        "            if agg_pred != agg_gt:\n",
        "                agg_err += 1\n",
        "                good = False\n",
        "\n",
        "            sel_pred = pred_qry['sel']\n",
        "            sel_gt = ground_truth_qry['sel']\n",
        "            if sel_pred != sel_gt:\n",
        "                sel_err += 1\n",
        "                good = False\n",
        "\n",
        "            cond_pred = pred_qry['conds']\n",
        "            cond_gt = ground_truth_qry['conds']\n",
        "            flag = True\n",
        "            if len(cond_pred) != len(cond_gt):\n",
        "                flag = False\n",
        "                cond_num_err += 1\n",
        "\n",
        "            if flag and set(\n",
        "                    x[0] for x in cond_pred) != set(x[0] for x in cond_gt):\n",
        "                flag = False\n",
        "                cond_col_err += 1\n",
        "\n",
        "            for idx in range(len(cond_pred)):\n",
        "                if not flag:\n",
        "                    break\n",
        "                ground_truth_idx = tuple(x[0] for x in cond_gt).index(cond_pred[idx][0])\n",
        "                if flag and cond_gt[ground_truth_idx][1] != cond_pred[idx][1]:\n",
        "                    flag = False\n",
        "                    cond_op_err += 1\n",
        "\n",
        "            for idx in range(len(cond_pred)):\n",
        "                if not flag:\n",
        "                    break\n",
        "                ground_truth_idx = tuple(x[0] for x in cond_gt).index(cond_pred[idx][0])\n",
        "                if flag and str(cond_gt[ground_truth_idx][2]).lower() != \\\n",
        "                        str(cond_pred[idx][2]).lower():\n",
        "                    flag = False\n",
        "                    cond_val_err += 1\n",
        "\n",
        "            if not flag:\n",
        "                cond_err += 1\n",
        "                good = False\n",
        "\n",
        "            if not good:\n",
        "                tot_err += 1\n",
        "\n",
        "        return np.array((agg_err, sel_err, cond_err)), tot_err\n",
        "\n",
        "    def gen_query(self, score, q, col, raw_q, raw_col, verbose=False):\n",
        "        def merge_tokens(tok_list, raw_tok_str):\n",
        "            tok_str = raw_tok_str.lower()\n",
        "            alphabet = 'abcdefghijklmnopqrstuvwxyz0123456789$('\n",
        "            special = {'-LRB-': '(', '-RRB-': ')', '-LSB-': '[', '-RSB-': ']',\n",
        "                       '``': '\"', '\\'\\'': '\"', '--': u'\\u2013'}\n",
        "            ret = ''\n",
        "            double_quote_appear = 0\n",
        "            for raw_tok in tok_list:\n",
        "                if not raw_tok:\n",
        "                    continue\n",
        "                tok = special.get(raw_tok, raw_tok)\n",
        "                if tok == '\"':\n",
        "                    double_quote_appear = 1 - double_quote_appear\n",
        "\n",
        "                if len(ret) == 0:\n",
        "                    pass\n",
        "                elif len(ret) > 0 and ret + ' ' + tok in tok_str:\n",
        "                    ret = ret + ' '\n",
        "                elif len(ret) > 0 and ret + tok in tok_str:\n",
        "                    pass\n",
        "                elif tok == '\"':\n",
        "                    if double_quote_appear:\n",
        "                        ret = ret + ' '\n",
        "                elif tok[0] not in alphabet:\n",
        "                    pass\n",
        "                elif (ret[-1] not in ['(', '/', u'\\u2013', '#', '$', '&']) and \\\n",
        "                        (ret[-1] != '\"' or not double_quote_appear):\n",
        "                    ret = ret + ' '\n",
        "                ret = ret + tok\n",
        "            return ret.strip()\n",
        "\n",
        "        agg_score, sel_score, cond_score = score\n",
        "\n",
        "        ret_queries = []\n",
        "        B = len(cond_score)\n",
        "        for b in range(B):\n",
        "            cur_query = {}\n",
        "            cur_query['agg'] = np.argmax(agg_score[b].data.cpu().numpy())\n",
        "            cur_query['sel'] = np.argmax(sel_score[b].data.cpu().numpy())\n",
        "            cur_query['conds'] = []\n",
        "            all_toks = self.SQL_SYNTAX_TOKENS + \\\n",
        "                       [x for toks in col[b] for x in\n",
        "                        toks + [',']] + [''] + q[b] + ['']\n",
        "            cond_toks = []\n",
        "            for where_score in cond_score[b].data.cpu().numpy():\n",
        "                cond_tok = np.argmax(where_score)\n",
        "                cond_val = all_toks[cond_tok]\n",
        "                if cond_val == '<END>':\n",
        "                    break\n",
        "                cond_toks.append(cond_val)\n",
        "\n",
        "            if verbose:\n",
        "                print(cond_toks)\n",
        "            if len(cond_toks) > 0:\n",
        "                cond_toks = cond_toks[1:]\n",
        "            st = 0\n",
        "            while st < len(cond_toks):\n",
        "                cur_cond = [None, None, None]\n",
        "                ed = len(cond_toks) if 'AND' not in cond_toks[st:] \\\n",
        "                    else cond_toks[st:].index('AND') + st\n",
        "                if 'EQL' in cond_toks[st:ed]:\n",
        "                    op = cond_toks[st:ed].index('EQL') + st\n",
        "                    cur_cond[1] = 0\n",
        "                elif 'GT' in cond_toks[st:ed]:\n",
        "                    op = cond_toks[st:ed].index('GT') + st\n",
        "                    cur_cond[1] = 1\n",
        "                elif 'LT' in cond_toks[st:ed]:\n",
        "                    op = cond_toks[st:ed].index('LT') + st\n",
        "                    cur_cond[1] = 2\n",
        "                else:\n",
        "                    op = st\n",
        "                    cur_cond[1] = 0\n",
        "                sel_col = cond_toks[st:op]\n",
        "                to_idx = [x.lower() for x in raw_col[b]]\n",
        "                pred_col = merge_tokens(sel_col, raw_q[b] + ' || ' + \\\n",
        "                                        ' || '.join(raw_col[b]))\n",
        "                if pred_col in to_idx:\n",
        "                    cur_cond[0] = to_idx.index(pred_col)\n",
        "                else:\n",
        "                    cur_cond[0] = 0\n",
        "                cur_cond[2] = merge_tokens(cond_toks[op + 1:ed], raw_q[b])\n",
        "                cur_query['conds'].append(cur_cond)\n",
        "                st = ed + 1\n",
        "            ret_queries.append(cur_query)\n",
        "\n",
        "        return ret_queries\n",
        "\n",
        "\n",
        "    def save_readable_results(self, predicted_query, ground_truth, table_ids, table_data):\n",
        "        file = open(\"./target_model_results.txt\", \"a+\", encoding=\"utf-8\")\n",
        "        for index in range(len(predicted_query)):\n",
        "            predicted_query_object = Query.from_dict(predicted_query[index])\n",
        "            ground_truth_query_object = Query.from_dict(ground_truth[index])\n",
        "            table_id = table_ids[index]\n",
        "            table_info = table_data[table_id]\n",
        "            table = Table(table_id, table_info[\"header\"], table_info[\"types\"], table_info[\"rows\"])\n",
        "            \n",
        "            file.write(table.query_str(ground_truth_query_object))\n",
        "            file.write(\"\\n\")\n",
        "            file.write(table.query_str(predicted_query_object))\n",
        "            file.write(\"\\n\\n\")\n",
        "        file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcy-TeZqT1vI"
      },
      "source": [
        "##**Function to train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-EE3KigEaZTw",
        "outputId": "f3464758-3732-4107-e7c8-3abc82fcea0f"
      },
      "source": [
        "def train_txtsql():\n",
        "    # Load training and validation (dev) dataset\n",
        "    sql_data, table_data, TRAIN_DB = load_dataset(\"train\")\n",
        "    validation_sql_data, validation_table_data, DEV_DB = load_dataset(\"dev\")\n",
        "\n",
        "    # Load the glove word embeddings\n",
        "    word_emb = load_word_embeddings('/content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt')\n",
        "\n",
        "    # Initialize the target model with the word embeddings\n",
        "    model = txtsql(word_emb, N_word=300, gpu=GPU)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Load the file names for the best models that we find during training\n",
        "    aggregator_model, selection_model, condition_model = best_model_name()\n",
        "\n",
        "    # Initialize the starting values of accuracy by running the model once without training\n",
        "    init_acc = epoch_acc(model, BATCH_SIZE, validation_sql_data, validation_table_data)\n",
        "    best_agg_acc = init_acc[1][0]\n",
        "    best_agg_idx = 0\n",
        "    best_sel_acc = init_acc[1][1]\n",
        "    best_sel_idx = 0\n",
        "    best_cond_acc = init_acc[1][2]\n",
        "    best_cond_idx = 0\n",
        "    print('Initial dev accuracy: %s\\n  breakdown on (agg, sel, where): %s' % init_acc)\n",
        "\n",
        "    # Save the untrained model as the initial best\n",
        "    torch.save(model.sel_pred.state_dict(), selection_model)\n",
        "    torch.save(model.agg_pred.state_dict(), aggregator_model)\n",
        "    torch.save(model.cond_pred.state_dict(), condition_model)\n",
        "    \n",
        "    # Store the losses per epoch for loss curve\n",
        "    epoch_losses = []\n",
        "\n",
        "    for i in range(TRAINING_EPOCHS):\n",
        "        print('Epoch :', i + 1)\n",
        "        \n",
        "        # Train the model on training dataset only\n",
        "        epoch_loss = epoch_train(model, optimizer, BATCH_SIZE, sql_data, table_data)\n",
        "        epoch_losses.append(epoch_loss)\n",
        "\n",
        "        print('Loss =', epoch_loss)\n",
        "\n",
        "        # Check model accuracy on training and validation set\n",
        "        training_accuracy = epoch_acc(model, BATCH_SIZE, sql_data, table_data)\n",
        "        print('Train accuracy: %s\\n   breakdown result: %s' % training_accuracy)\n",
        "        \n",
        "        validation_accuracy = epoch_acc(model, BATCH_SIZE, validation_sql_data, validation_table_data)\n",
        "        print('Dev accuracy: %s\\n   breakdown result: %s' % validation_accuracy)\n",
        "        \n",
        "        # If the accuracy is better than the previous best, update the best scores and models\n",
        "        if validation_accuracy[1][0] > best_agg_acc:\n",
        "            best_agg_acc = validation_accuracy[1][0]\n",
        "            best_agg_idx = i + 1\n",
        "            torch.save(model.agg_pred.state_dict(), aggregator_model)\n",
        "        if validation_accuracy[1][1] > best_sel_acc:\n",
        "            best_sel_acc = validation_accuracy[1][1]\n",
        "            best_sel_idx = i + 1\n",
        "            torch.save(model.sel_pred.state_dict(), selection_model)\n",
        "        if validation_accuracy[1][2] > best_cond_acc:\n",
        "            best_cond_acc = validation_accuracy[1][2]\n",
        "            best_cond_idx = i + 1\n",
        "            torch.save(model.cond_pred.state_dict(), condition_model)\n",
        "\n",
        "        print('Best val accuracy = %s, on epoch %s individually' % (\n",
        "            (best_agg_acc, best_sel_acc, best_cond_acc),\n",
        "            (best_agg_idx, best_sel_idx, best_cond_idx)))\n",
        "\n",
        "    # save epoch vs loss graph\n",
        "    plot_data(x = range(TRAINING_EPOCHS), y = epoch_losses, xlabel = \"Epochs\", ylabel = \"Loss\", label = \"Loss Graph for target txtsql model\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_txtsql()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset :  train\n",
            "Loading dataset :  dev\n",
            "Loading word embedding from /content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt\n",
            "txtsql where prediction\n",
            "Initial dev accuracy: 0.0\n",
            "  breakdown on (agg, sel, where): [0.71452322 0.15912599 0.        ]\n",
            "Epoch : 1\n",
            "Loss = 3.5819270220785215\n",
            "Train accuracy: 0.05138851920858841\n",
            "   breakdown result: [0.89935232 0.35013752 0.16328631]\n",
            "Dev accuracy: 0.05189407433796461\n",
            "   breakdown result: [0.89193682 0.35779599 0.16209476]\n",
            "Best val accuracy = (0.8919368246051538, 0.35779598622491393, 0.16209476309226933), on epoch (1, 1, 1) individually\n",
            "Epoch : 2\n",
            "Loss = 2.401202180249997\n",
            "Train accuracy: 0.15649010735515925\n",
            "   breakdown result: [0.90662763 0.62425694 0.25923166]\n",
            "Dev accuracy: 0.14190713691960574\n",
            "   breakdown result: [0.8963306  0.61275383 0.24747655]\n",
            "Best val accuracy = (0.8963306020662629, 0.6127538297114357, 0.24747654672841704), on epoch (2, 2, 2) individually\n",
            "Epoch : 3\n",
            "Loss = 1.8827262598348589\n",
            "Train accuracy: 0.2614674829207701\n",
            "   breakdown result: [0.9067341  0.7681306  0.34845178]\n",
            "Dev accuracy: 0.2334639591497447\n",
            "   breakdown result: [0.89074932 0.75026719 0.32122076]\n",
            "Best val accuracy = (0.8963306020662629, 0.7502671891699323, 0.3212207576297352), on epoch (2, 3, 3) individually\n",
            "Epoch : 4\n",
            "Loss = 1.573493859010838\n",
            "Train accuracy: 0.32905687161742525\n",
            "   breakdown result: [0.91326413 0.82560554 0.40908526]\n",
            "Dev accuracy: 0.29129557059731626\n",
            "   breakdown result: [0.88896806 0.80168626 0.38000238]\n",
            "Best val accuracy = (0.8963306020662629, 0.8016862605391284, 0.38000237501484385), on epoch (2, 4, 4) individually\n",
            "Epoch : 5\n",
            "Loss = 1.387785331234726\n",
            "Train accuracy: 0.3682548132375122\n",
            "   breakdown result: [0.9196522  0.85625055 0.44420193]\n",
            "Dev accuracy: 0.3218145113406959\n",
            "   breakdown result: [0.89395559 0.82056763 0.40565254]\n",
            "Best val accuracy = (0.8963306020662629, 0.8205676285476784, 0.4056525353283458), on epoch (2, 5, 5) individually\n",
            "Epoch : 6\n",
            "Loss = 1.2557089288384264\n",
            "Train accuracy: 0.4130423210007985\n",
            "   breakdown result: [0.92423033 0.87548576 0.49005412]\n",
            "Dev accuracy: 0.3555397221232633\n",
            "   breakdown result: [0.89324308 0.83885524 0.44234651]\n",
            "Best val accuracy = (0.8963306020662629, 0.8388552428452678, 0.4423465146657167), on epoch (2, 6, 6) individually\n",
            "Epoch : 7\n",
            "Loss = 1.1548074684362215\n",
            "Train accuracy: 0.44148700204063523\n",
            "   breakdown result: [0.93109751 0.8939402  0.51225268]\n",
            "Dev accuracy: 0.37109606935043343\n",
            "   breakdown result: [0.8883743  0.85144282 0.45683411]\n",
            "Best val accuracy = (0.8963306020662629, 0.8514428215176345, 0.4568341052131576), on epoch (2, 7, 7) individually\n",
            "Epoch : 8\n",
            "Loss = 1.0675133865438688\n",
            "Train accuracy: 0.46086416467039304\n",
            "   breakdown result: [0.93619022 0.90698252 0.5254902 ]\n",
            "Dev accuracy: 0.3804773779836124\n",
            "   breakdown result: [0.88528678 0.85844912 0.46799667]\n",
            "Best val accuracy = (0.8963306020662629, 0.8584491153069707, 0.4679966749792186), on epoch (2, 8, 8) individually\n",
            "Epoch : 9\n",
            "Loss = 0.9973589353230987\n",
            "Train accuracy: 0.4877650607754414\n",
            "   breakdown result: [0.94204596 0.91306894 0.55143288]\n",
            "Dev accuracy: 0.3942524640779005\n",
            "   breakdown result: [0.88588054 0.86058663 0.48212801]\n",
            "Best val accuracy = (0.8963306020662629, 0.8605866286664292, 0.48212801330008315), on epoch (2, 9, 9) individually\n",
            "Epoch : 10\n",
            "Loss = 0.9353098160974538\n",
            "Train accuracy: 0.505811374323485\n",
            "   breakdown result: [0.94772425 0.9203265  0.56477686]\n",
            "Dev accuracy: 0.40161501009381306\n",
            "   breakdown result: [0.88433678 0.86640542 0.48972806]\n",
            "Best val accuracy = (0.8963306020662629, 0.8664054150338439, 0.48972806080038), on epoch (2, 10, 10) individually\n",
            "Epoch : 11\n",
            "Loss = 0.8797022705100971\n",
            "Train accuracy: 0.5300150829562594\n",
            "   breakdown result: [0.95389939 0.92692751 0.585893  ]\n",
            "Dev accuracy: 0.4149150932193326\n",
            "   breakdown result: [0.88409928 0.86889918 0.50682817]\n",
            "Best val accuracy = (0.8963306020662629, 0.8688991806198789, 0.506828167676048), on epoch (2, 11, 11) individually\n",
            "Epoch : 12\n",
            "Loss = 0.8340265056920045\n",
            "Train accuracy: 0.5498536066010115\n",
            "   breakdown result: [0.96042942 0.93400763 0.60113566]\n",
            "Dev accuracy: 0.42025887661797884\n",
            "   breakdown result: [0.88267427 0.87281796 0.50849068]\n",
            "Best val accuracy = (0.8963306020662629, 0.8728179551122195, 0.5084906780667379), on epoch (2, 12, 12) individually\n",
            "Epoch : 13\n",
            "Loss = 0.7851261502054313\n",
            "Train accuracy: 0.5551592582734451\n",
            "   breakdown result: [0.96341052 0.93691775 0.60457812]\n",
            "Dev accuracy: 0.4201401258757867\n",
            "   breakdown result: [0.87436171 0.87341171 0.51395321]\n",
            "Best val accuracy = (0.8963306020662629, 0.8734117088231802, 0.5139532122075763), on epoch (2, 13, 13) individually\n",
            "Epoch : 14\n",
            "Loss = 0.7475095330627055\n",
            "Train accuracy: 0.5905598438470411\n",
            "   breakdown result: [0.96850324 0.94282672 0.63637654]\n",
            "Dev accuracy: 0.4373589834936468\n",
            "   breakdown result: [0.88267427 0.87388671 0.53378459]\n",
            "Best val accuracy = (0.8963306020662629, 0.8738867117919487, 0.5337845861536634), on epoch (2, 14, 14) individually\n",
            "Epoch : 15\n",
            "Loss = 0.7103557924720433\n",
            "Train accuracy: 0.5970011534025375\n",
            "   breakdown result: [0.96884039 0.94586106 0.64269364]\n",
            "Dev accuracy: 0.4394964968531053\n",
            "   breakdown result: [0.88124926 0.87519297 0.53651585]\n",
            "Best val accuracy = (0.8963306020662629, 0.8751929699560622, 0.5365158532240827), on epoch (2, 15, 15) individually\n",
            "Epoch : 16\n",
            "Loss = 0.6790126616059385\n",
            "Train accuracy: 0.6212226066897347\n",
            "   breakdown result: [0.97540591 0.95006654 0.66242569]\n",
            "Dev accuracy: 0.44816530103313146\n",
            "   breakdown result: [0.879943   0.87792424 0.54613466]\n",
            "Best val accuracy = (0.8963306020662629, 0.8779242370264814, 0.5461346633416458), on epoch (2, 16, 16) individually\n",
            "Epoch : 17\n",
            "Loss = 0.6477954916951502\n",
            "Train accuracy: 0.6308402093869222\n",
            "   breakdown result: [0.97254902 0.95196522 0.67211428]\n",
            "Dev accuracy: 0.45327158294739345\n",
            "   breakdown result: [0.88326802 0.87733048 0.55017219]\n",
            "Best val accuracy = (0.8963306020662629, 0.8779242370264814, 0.5501721885761786), on epoch (2, 16, 17) individually\n",
            "Epoch : 18\n",
            "Loss = 0.6236151192639039\n",
            "Train accuracy: 0.6419483630556295\n",
            "   breakdown result: [0.97638186 0.9555319  0.68093337]\n",
            "Dev accuracy: 0.45267782923643274\n",
            "   breakdown result: [0.8715117  0.87768674 0.56097851]\n",
            "Best val accuracy = (0.8963306020662629, 0.8779242370264814, 0.5609785061156632), on epoch (2, 16, 18) individually\n",
            "Epoch : 19\n",
            "Loss = 0.5978849349867197\n",
            "Train accuracy: 0.6509271581935941\n",
            "   breakdown result: [0.98078254 0.95711117 0.68659391]\n",
            "Dev accuracy: 0.4546965918536991\n",
            "   breakdown result: [0.87281796 0.88136801 0.559316  ]\n",
            "Best val accuracy = (0.8963306020662629, 0.8813680085500535, 0.5609785061156632), on epoch (2, 19, 18) individually\n",
            "Epoch : 20\n",
            "Loss = 0.5774282612845866\n",
            "Train accuracy: 0.6700381510070091\n",
            "   breakdown result: [0.98427824 0.96087304 0.70229793]\n",
            "Dev accuracy: 0.4596841230257689\n",
            "   breakdown result: [0.87602423 0.8792305  0.56549103]\n",
            "Best val accuracy = (0.8963306020662629, 0.8813680085500535, 0.5654910343189645), on epoch (2, 19, 20) individually\n",
            "Epoch : 21\n",
            "Loss = 0.55520165655757\n",
            "Train accuracy: 0.6753438026794428\n",
            "   breakdown result: [0.98603496 0.96401384 0.70499512]\n",
            "Dev accuracy: 0.45671535447096545\n",
            "   breakdown result: [0.87851799 0.88326802 0.56014725]\n",
            "Best val accuracy = (0.8963306020662629, 0.8832680204251276, 0.5654910343189645), on epoch (2, 21, 20) individually\n",
            "Epoch : 22\n",
            "Loss = 0.5393421703630453\n",
            "Train accuracy: 0.681944814124745\n",
            "   breakdown result: [0.9872061  0.96367669 0.71147192]\n",
            "Dev accuracy: 0.46930293314333216\n",
            "   breakdown result: [0.88421803 0.88231801 0.56905356]\n",
            "Best val accuracy = (0.8963306020662629, 0.8832680204251276, 0.5690535565847287), on epoch (2, 21, 22) individually\n",
            "Epoch : 23\n",
            "Loss = 0.5193907658692716\n",
            "Train accuracy: 0.6917930973294295\n",
            "   breakdown result: [0.98853695 0.96467039 0.72013131]\n",
            "Dev accuracy: 0.4630091438071488\n",
            "   breakdown result: [0.87899299 0.88314927 0.56525353]\n",
            "Best val accuracy = (0.8963306020662629, 0.8832680204251276, 0.5690535565847287), on epoch (2, 21, 22) individually\n",
            "Epoch : 24\n",
            "Loss = 0.5072051203840003\n",
            "Train accuracy: 0.7020140182769941\n",
            "   breakdown result: [0.98912253 0.9668175  0.72815189]\n",
            "Dev accuracy: 0.46870917943237145\n",
            "   breakdown result: [0.87602423 0.88279302 0.57700986]\n",
            "Best val accuracy = (0.8963306020662629, 0.8832680204251276, 0.577009856311602), on epoch (2, 21, 24) individually\n",
            "Epoch : 25\n",
            "Loss = 0.4893526914919103\n",
            "Train accuracy: 0.7081181793984562\n",
            "   breakdown result: [0.99045338 0.96841452 0.73299618]\n",
            "Dev accuracy: 0.473459209120057\n",
            "   breakdown result: [0.87839924 0.88635554 0.58140363]\n",
            "Best val accuracy = (0.8963306020662629, 0.8863555397221232, 0.5814036337727111), on epoch (2, 25, 25) individually\n",
            "Epoch : 26\n",
            "Loss = 0.48128615656568335\n",
            "Train accuracy: 0.7042321000798509\n",
            "   breakdown result: [0.98844823 0.9706326  0.72960696]\n",
            "Dev accuracy: 0.4658591616197601\n",
            "   breakdown result: [0.86913668 0.88754305 0.57475359]\n",
            "Best val accuracy = (0.8963306020662629, 0.8875430471440446, 0.5814036337727111), on epoch (2, 26, 25) individually\n",
            "Epoch : 27\n",
            "Loss = 0.4632896204842363\n",
            "Train accuracy: 0.7214444148700204\n",
            "   breakdown result: [0.98977908 0.97247804 0.74508029]\n",
            "Dev accuracy: 0.480346752167201\n",
            "   breakdown result: [0.87744923 0.88540553 0.58781617]\n",
            "Best val accuracy = (0.8963306020662629, 0.8875430471440446, 0.5878161738510865), on epoch (2, 26, 27) individually\n",
            "Epoch : 28\n",
            "Loss = 0.4554817839403265\n",
            "Train accuracy: 0.7309910389495164\n",
            "   breakdown result: [0.98972585 0.97258451 0.75514151]\n",
            "Dev accuracy: 0.4720342002137513\n",
            "   breakdown result: [0.87329296 0.88528678 0.58199739]\n",
            "Best val accuracy = (0.8963306020662629, 0.8875430471440446, 0.5878161738510865), on epoch (2, 26, 27) individually\n",
            "Epoch : 29\n",
            "Loss = 0.444511772266626\n",
            "Train accuracy: 0.7310797622216307\n",
            "   breakdown result: [0.99226333 0.97357821 0.7520362 ]\n",
            "Dev accuracy: 0.47915924474527966\n",
            "   breakdown result: [0.87816174 0.88611804 0.58555991]\n",
            "Best val accuracy = (0.8963306020662629, 0.8875430471440446, 0.5878161738510865), on epoch (2, 26, 27) individually\n",
            "Epoch : 30\n",
            "Loss = 0.4317046785257309\n",
            "Train accuracy: 0.7365983497471387\n",
            "   breakdown result: [0.99362967 0.97403957 0.75677402]\n",
            "Dev accuracy: 0.48212801330008315\n",
            "   breakdown result: [0.8797055  0.88683054 0.58876618]\n",
            "Best val accuracy = (0.8963306020662629, 0.8875430471440446, 0.5887661797886237), on epoch (2, 26, 30) individually\n",
            "Generating plot for  Loss Graph for target txtsql model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRc9X338fdXGm2j3VosWbYk25jFdgw2hkAhxJAQDMkDtJA0SUNJQkvIExKyPG1C25M2Oe05SdrShEKTOgkBUkJIw1KSsicOS1iM7djGC2DjVcKLZGvfl+/zx1wJISRLtjW6Gs3ndc6cmblzZ/S9Z2x99Fvu75q7IyIiyS0l7AJERCR8CgMREVEYiIiIwkBERFAYiIgIEAm7gGNVXFzs1dXVYZchIpJQ1q1bV+/uJaO9nnBhUF1dzdq1a8MuQ0QkoZjZnqO9rm4iERFRGIiIiMJARERQGIiICAoDERFBYSAiIigMRESEJAqDVw80861HX6W5syfsUkREppykCYN9Rzr4wdNvsLOuLexSRESmnKQJg+qiKAB7DisMRESGi1sYmFmmma0xs41mtsXMvjHCPp80szoz2xDc/iJe9cyZEcUMdte3x+tHiIgkrHiuTdQFXOTurWaWBjxnZo+6+4vD9rvP3W+MYx0AZKalMis/i91qGYiIvEPcwsBjF1duDZ6mBbdQL7hcVRRVGIiIjCCuYwZmlmpmG4BDwJPu/tIIu11lZpvM7JdmNmeUz7nezNaa2dq6urrjrqeqKJs9h9VNJCIyXFzDwN373P0MYDZwtpktHrbLr4Bqd18CPAncNcrnrHL35e6+vKRk1OW4x1RdFOVIWzdNHZpeKiIy1KTMJnL3RmA1sHLY9sPu3hU8/RFwZjzrqC7OBjSjSERkuHjOJioxs4LgcRZwMfDqsH3Khzy9HNgWr3oAqotiYbBbXUUiIm8Tz9lE5cBdZpZKLHR+4e6/NrNvAmvd/WHgC2Z2OdALHAE+Gcd6qJwRnGtQr5aBiMhQ8ZxNtAlYOsL2rw95fDNwc7xqGC4rPZWyvEy1DEREhkmaM5AHVBdreqmIyHDJFwZF2RpAFhEZJunCoKoom/rWblq0eqmIyKCkC4O5xQML1mncQERkQNKFQdXg9FJ1FYmIDEjCMFDLQERkuKQLg2h6hNLcDHbrXAMRkUFJFwYQW5ZC3UQiIm9JzjAoiurEMxGRIZIyDKqKsqlr6aKtqzfsUkREpoSkDIOBBes0iCwiEpOcYRCca6BxAxGRmKQMA51rICLydkkZBjkZEYpzMthTr24iERFI0jCA2LIUu9QyEBEBkjgMqrR6qYjIoKQNg+qiKAebu2jv1vRSEZGkDYOBQeS9RzRuICKStGEwtziYUaQ1ikREkjcMKosGzjVQy0BEJGnDIC8zjaLsdA0ii4iQxGEAsWsb7Na5BiIiyR0GWspaRCQmbmFgZplmtsbMNprZFjP7xgj7ZJjZfWa2w8xeMrPqeNUzkuqibPY3ddLZ0zeZP1ZEZMqJZ8ugC7jI3U8HzgBWmtk5w/a5Dmhw95OAfwO+Hcd63mHgEpiaXioiyS5uYeAxrcHTtODmw3a7ArgrePxL4H1mZvGqabiBpax3aXqpiCS5uI4ZmFmqmW0ADgFPuvtLw3apAPYBuHsv0AQUjfA515vZWjNbW1dXN2H1vXVdA4WBiCS3uIaBu/e5+xnAbOBsM1t8nJ+zyt2Xu/vykpKSCasvP5pGYTRN5xqISNKblNlE7t4IrAZWDnupFpgDYGYRIB84PBk1DdCCdSIi8Z1NVGJmBcHjLOBi4NVhuz0MXBs8vhr4rbsPH1eIq7nF2TrXQESSXjxbBuXAajPbBLxMbMzg12b2TTO7PNjnx0CRme0Avgx8LY71jKiqKMqbTR2aXioiSS0Srw92903A0hG2f33I407gw/GqYTyqi7Jxh5qGdk4qzQ2zFBGR0CT1Gcjw1rkG6ioSkWSW9GEwuJS1BpFFJIklfRgURNPJz0pTGIhIUkv6MIDYJTD36FwDEUliCgNi5xqoZSAiyUxhQGwp69qGDrp7+8MuRUQkFAoDYt1E/Q77GtRVJCLJSWFArJsItGCdiCQvhQGxlgHALp1rICJJSmEAzMhOJzczopaBiCQthQFgZlQXZWspaxFJWgqDQFVRVC0DEUlaCoPA3OJsaho66OnT9FIRST4Kg0BVUTZ9/U5NQ0fYpYiITDqFQWBgRpHORBaRZKQwCAyea1CvMBCR5KMwCBTnpJOTEdGMIhFJSgqDgJlRVRRVN5GIJCWFwRDVRdlaylpEkpLCYIiqoij7jrTTq+mlIpJkFAZDVBdn09vv1DZqeqmIJBeFwRDVRQPXQ1ZXkYgkl7iFgZnNMbPVZrbVzLaY2U0j7LPCzJrMbENw+3q86hmPgXMNtCyFiCSbSBw/uxf4iruvN7NcYJ2ZPenuW4ft96y7fyiOdYxbSW4G0fRUdulcAxFJMnFrGbj7fndfHzxuAbYBFfH6eRMhNr1UM4pEJPlMypiBmVUDS4GXRnj5XDPbaGaPmtmiUd5/vZmtNbO1dXV1caw01lWkcw1EJNnEPQzMLAe4H/iiuzcPe3k9UOXupwP/Djw00me4+yp3X+7uy0tKSuJab1VRNvuOtNPX73H9OSIiU0lcw8DM0ogFwT3u/sDw19292d1bg8ePAGlmVhzPmsYytzhKT5/zpqaXikgSiedsIgN+DGxz91tG2acs2A8zOzuo53C8ahqPqsHppeoqEpHkEc/ZROcB1wCvmNmGYNvfAJUA7v4D4Grgs2bWC3QAH3X3UPtnhp5r8J4FYVYiIjJ54hYG7v4cYGPscxtwW7xqOB6luRlkpqWwW9NLRSSJ6AzkYVJSjJNKc9hU0xh2KSIik0ZhMIL3nTqTtXsaqGvpCrsUEZFJoTAYwcrFZbjDE1sPhF2KiMikUBiM4NSyXKqLojy2WWEgIslBYTACM+OSxWW88MZhmtp7wi5HRCTuFAajuHRxOb39zlPbDoZdiohI3CkMRnH67HzK8zN5VF1FIpIEFAajMDMuWVTGM9vraO3qDbscEZG4UhgcxaWLy+ju7ed3rx0KuxQRkbhSGBzF8uoZFOekq6tIRKY9hcFRpKYYFy8sY/Wrh+js6Qu7HBGRuFEYjOHSxWW0d/fx7Pb6sEsREYkbhcEYzplXRF5mRCegici0pjAYQ3okhfcvnMlT2w7S09cfdjkiInGhMBiHlYvKaOro4YU3Qr3ujohI3CgMxuGCk0uIpqfy2BZ1FYnI9KQwGIfMtFQuPKWUJ7YcoK8/1AuxiYjExbjCwMyyzSwleHyymV0eXOw+aaxcXEZ9azfr9jSEXYqIyIQbb8vgGSDTzCqAJ4hd2/jOeBU1FV14ainpkRQe3bw/7FJERCbceMPA3L0d+BPgP9z9w8Ci+JU19eRkRLhgQTGPbz6Au7qKRGR6GXcYmNm5wJ8B/xtsS41PSVPXysXlvNnUyaaaprBLERGZUOMNgy8CNwMPuvsWM5sHrI5fWVPT+08rJZJiWqtIRKadcYWBuz/t7pe7+7eDgeR6d//C0d5jZnPMbLWZbTWzLWZ20wj7mJndamY7zGyTmS07zuOYFAXRdM6dX8Rjm/erq0hEppXxzib6mZnlmVk2sBnYamZ/NcbbeoGvuPtC4Bzgc2a2cNg+lwILgtv1wPePqfoQrFxcxu7D7bx2sCXsUkREJsx4u4kWunszcCXwKDCX2IyiUbn7fndfHzxuAbYBFcN2uwK422NeBArMrPxYDmCyXbxwJmZorSIRmVbGGwZpwXkFVwIPu3sPMO5+EjOrBpYCLw17qQLYN+R5De8MjCmlNDeTs6pmKAxEZFoZbxj8J7AbyAaeMbMqoHk8bzSzHOB+4ItB6+KYmdn1ZrbWzNbW1dUdz0dMqEsWl/HqgRZ21beFXYqIyIQY7wDyre5e4e6XBV06e4ALx3pf0Jq4H7jH3R8YYZdaYM6Q57ODbcN//ip3X+7uy0tKSsZTclytXFwGqKtIRKaP8Q4g55vZLQN/nZvZvxJrJRztPQb8GNjm7reMstvDwJ8Hs4rOAZrcfcqf4ltRkMWS2fk8prORRWSaGG830R1AC/CR4NYM/GSM95xHbJD5IjPbENwuM7MbzOyGYJ9HgJ3ADuCHwP891gMIy8rFZWysaaK2sSPsUkRETlhknPvNd/erhjz/hpltONob3P05wMbYx4HPjbOGKWXlojK+89hrPL75AJ8+f27Y5YiInJDxtgw6zOz8gSdmdh6Q1H8SzyvJ4ZSZubrGgYhMC+NtGdwA3G1m+cHzBuDa+JSUOFYuLuPW325nf1MH5flZYZcjInLcxjubaKO7nw4sAZa4+1LgorhWlgCuPnM2kRTj1t9sD7sUEZETckxXOnP35iHnCnw5DvUklDkzonzinCrue3kfOw5peQoRSVwnctnLow4OJ4vPX7SAaHqE7zz2WtiliIgctxMJAy3bCczITueG987jia0HWbv7SNjliIgcl6OGgZm1mFnzCLcWYNYk1Tjlffr8uZTmZvCtR1/V0tYikpCOGgbunuvueSPcct19vDORpr1oeoQvvv9k1u5p4MmtB8MuR0TkmJ1IN5EM8ZHls5lXks13Hn+N3r7+sMsRETkmCoMJEklN4a8vOZUdh1q5f31N2OWIiBwThcEEumTRTJZVFnDLk6/T0d0XdjkiIuOmMJhAZsbXLj2Ng81d/OT5XWGXIyIybgqDCXb23Bm8/7RSvv+7N2ho6w67HBGRcVEYxMFfrzyVtq5ebl+9I+xSRETGRWEQByfPzOXqM2dz9wt72HekPexyRETGpDCIky9dfDJm8G9Pvh52KSIiY1IYxEl5fhafOm8uD26oZeubzWO/QUQkRAqDOPrsivnkZabx7cdeDbsUEZGjUhjEUX5WGjdeeBJPv17H8zvqwy5HRGRUCoM4u+bcKioKsvjWY6/S369F7ERkalIYxFlmWipfvvhkNtU08etX9oddjojIiBQGk+DKpRUsrsjjbx94hW37NZgsIlOPwmASpKYYq65ZTnZGhGvvWKNzD0RkyolbGJjZHWZ2yMw2j/L6CjNrMrMNwe3r8aplKphVkMXd151NZ08f1/5kDUe0VIWITCHxbBncCawcY59n3f2M4PbNONYyJZw8M5cff/Isahs6+PSdL9Pe3Rt2SSIiQBzDwN2fAXRR4GHOqp7BrR9byqaaRj53z3p6dCEcEZkCwh4zONfMNprZo2a2aLSdzOx6M1trZmvr6uoms764uGRRGf945btY/Vodf/PAK7pusoiELszrGK8Hqty91cwuAx4CFoy0o7uvAlYBLF++fFr85vz4uys51NLJd5/aTkluBn+98tSwSxKRJBZay8Ddm929NXj8CJBmZsVh1ROGm963gI+dXcl//O4N7vy9LoYjIuEJrWVgZmXAQXd3MzubWDAdDqueMJgZ/3jlYg63dvGNX2+lODeDDy2ZFXZZIpKE4jm19F7gBeAUM6sxs+vM7AYzuyHY5Wpgs5ltBG4FPupJ2HmemmLc+rGlLK8q5Mv3beT5N7SGkYhMPku037/Lly/3tWvXhl3GhGtq7+HD//k8+xs7ue8z57JwVl7YJYnINGJm69x9+Wivhz2bSAL50TTu+vTZ5GRGuPYna3ilpinskkQkiSgMppDy/Cx+et3ZpKUYV/3geX65ribskkQkSSgMppiTSnP51efPZ3lVIf/vvzfydw+9QnevTkwTkfhSGExBRTkZ3P3ps/nMBfP4rxf38tFVL3CwuTPsskRkGlMYTFGR1BRuvuw0bv/4Ml490MIHb32ONbu0uoeIxIfCYIr74JJyHvrceeRmRvj4D1/kzt/v0vIVIjLhFAYJ4OSZufzPjeex4pRS/uFXW/nyLzbS0d0XdlkiMo0oDBJEXmYaq645k69cfDIPbajlT77/PHsP6yI5IjIxFAYJJCXF+Pz7FnDHtWdR29DO/7ntOR7fciDsskRkGlAYJKALTy3lV58/n1kFWXzmp+u47s6XdSlNETkhCoMEVVWUzcM3nsffXnYaL+48zPtveZrvPbWdzh6NJYjIsVMYJLC01BT+8oJ5/OYrK7h44Uz+7anXueS7z7D6tUNhlyYiCUZhMA2U5Wdy28eXcc9fvJtIivGpn7zM9XevpaZBXUciMj4Kg2nkvJOKefSmC/jqylN5dns977/laW5fvYOuXnUdicjRKQymmfRICp9dMZ+nvvJeLjyllH9+/DUu/e6zPPN64l87WkTiR2EwTVUUZPH9T5zJnZ86i353/vyONVzz45fYuK8x7NJEZApSGExzK04p5fEvXcDfffA0trzZzBW3/57r717Lawdawi5NRKYQXeksibR29XLHc7v44TM7ae3u5YrTZ/Gli0+mqig77NJEJM7GutKZwiAJNbR185/P7OTO53fR2+d85Kw5fOGiBZTlZ4ZdmojEicJARnWouZPbV+/gZ2v2Ymb8+TlVfHbFfIpyMsIuTUQmmMJAxrTvSDvf+812HlhfQ1ZaKp84p4pPnFPFnBnRsEsTkQmiMJBx23Gole8+9TqPbj5AvzsXnVLKNedWccGCElJSLOzyROQEhBYGZnYH8CHgkLsvHuF1A74HXAa0A5909/Vjfa7CIP72N3Xws5f2cu+avdS3dlNdFOUT51Tx4TPnkB9NC7s8ETkOYYbBBUArcPcoYXAZ8HliYfBu4Hvu/u6xPldhMHm6evt4bPMB7n5hD+v2NJCZlsIfL63gmnOqWTgrL+zyROQYjBUGkXj9YHd/xsyqj7LLFcSCwoEXzazAzMrdfX+8apJjkxFJ5YozKrjijAo21zbx0xf28OAfarl3zT6WVxVyzblVXLKojMy01LBLFZETFLcwGIcKYN+Q5zXBtneEgZldD1wPUFlZOSnFydstrsjn21cv4ebLTuW/19bw0xf3cNPPN5CbGeFDS2Zx9ZmzWVZZQKz3T0QSTZhhMG7uvgpYBbFuopDLSWoF0XT+8oJ5XHf+XH7/Rj33r6vhwT/UcO+avcwtzuaqZRX88bLZVBRkhV2qiByDMMOgFpgz5PnsYJskgJQU4z0LSnjPghJaOnt4dPMB7l9Xw7888Tr/+uTrnDuviKuWzWbl4jKyMxLibw6RpBbXqaXBmMGvRxlA/iBwI28NIN/q7meP9ZkaQJ7a9h1p54H1tdy/voa9R9qJpqdy6eJyrlw6i3PnFRFJ1XJYImEIczbRvcAKoBg4CPw9kAbg7j8IppbeBqwkNrX0U+4+5m95hUFicHfW7mng/nU1/O+m/bR09VIYTeOSRWVc9q5yzp1fRJqCQWTS6KQzCV1nTx9Pv17HI6/s56mtB2nr7qMwmsYHFpZx2ZJy/kjBIBJ3CgOZUkYKhoJoGh9YOJMPLpmlYBCJE4WBTFmdPX08MxAM2w7R2tVLXmaE8xcUB4PTxcwu1PpIIhMhtJPORMaSmZbKBxaV8YFFZXT29PHs9noe33KA57bX88grBwCYV5zNe4JwOGd+ETmamSQSF2oZyJTj7uw41Moz2+t5dnsdL+48TGdPP5EUY1lVIRcE4bC4Ip9ULaAnMi7qJpKE19Xbx7rdDTy7IxYOm2ubAZiRnc57Ty7hwlNLee+CEi2iJ3IUCgOZdupbu/j9jnpWv3qIp1+vo6G9h9QU48zKQlacWsJFp5ZyysxcLY0hMoTCQKa1vn5nw75GVr96iN++eoit+2OthoqCLFacEguGP5pfTFa6FtOT5KYwkKRyoKmT370WC4bndtTT3t1HemoKiyryOLOykGVVhZxZVcjMPF3vWZKLwkCSVldvHy/vauDZ7XWs39vAxpomunv7gVjLYVlVIWdWFrCsqpDTyvN0foNMa5paKkkrI5LK+QuKOX9BMQDdvf1s3d/Muj0NrN/TwMu7jvCrjW8CkJmWwpLZBSyrLGRZEBDFORlhli8yqdQykKT2ZmMH6/c2DAbEljeb6e2P/Z+onBEdDIZllYWcUpar1oMkLLUMRI5iVkEWswqy+NCSWUDsrOhXaptYv6eB9Xsb+P0bh3loQ6z1kJWWyrtm57OsspCllQUsmpVHRUGWZi3JtKAwEBkiMy2Vs6pncFb1DCB2AlxtYwfr9zayfk8Df9jbwI+e3TnYesjLjLBwVh4Ly/OD+zxOKs0hPaIWhCQWhYHIUZgZswujzC6Mcvnpb7UetrzZzNb9zWwN7u95aQ9dweB0WqqxoDR3MBwWzsrjtPI88rN0UpxMXQoDkWOUmZbKmcEU1QG9ff3sPtz2tpD43WuH+OW6msF9ZhdmsbA8FgwDQTG7UN1MMjUoDEQmQCQ1hZNKczmpNJcrzqgY3H6ouTMWDkNaEU9uO8jAvI3czMhgQJxWnsvc4hyqi6OU5GQoJGRSKQxE4qg0L5PSvExWnFI6uK29u5fXDrS8LSDue3kfHT19g/vkZESoKopSXZzN3KLs2H1xlOqibGZkpysoZMIpDEQmWTQ9wtLKQpZWvtXN1Nfv1DS0s6u+jd31bew+3M7O+jZeqWni0Vf20z9kBnheZoS5JTnML85mfmkO84qzmVeSQ1VRlMw0Lbshx0dhIDIFpKYYVUXZVBVlwylvf627t599De3srm+LhcXh2P3zbxzmgT/UDu6XYjC7MMr8klg4zCvJZm5xNnMKo5TlZ+ocCTkqhYHIFJceSWF+SQ7zS3Le8VpbVy+76tt4o66VN+ra2BncvxBcA2JAikFZXiYVhVnMLoxSUZBFRWEWFQVZzC6MnWuhVkVyUxiIJLDsjAiLK/JZXJH/tu39/c7+5k521bVR29hObUMHNY0d1DR0sGbXEQ40d9LX//bVB0pzM6icEaVyRpQ5wX1lUey+NFcD2tOdwkBkGkpJsdhf/wVZI77e29fPgeZOahs6qA1CYt+RdvYeaefFnYd5cEMtQ1eqyYikDAbF7MIsSvMyKcnJoCQ3divNzWBGdjoRdUUlrLiGgZmtBL4HpAI/cvdvDXv9k8A/AwMdn7e5+4/iWZOIxKbCDpxMN5Ku3j5qGzrYe6R9MCRitw7W7D5CS2fvO96TYjAj++0BUZ6fyawglAbudW2JqSluYWBmqcDtwMVADfCymT3s7luH7Xqfu98YrzpE5NhlRFKDQeh3jlNA7CzsupYuDrV0UdfSRV1rcD9462T7wRYOtXS9oztqRnZ6EA6ZVBREmVUQC4yCaBqF0fTBe41hTK54tgzOBna4+04AM/s5cAUwPAxEJMFkpqUyJxhbOJrevn4OtnTxZmPHYJdUbWMHbzZ2sLOujWe3xy5ANPLPSKEgK/1tIVEQTackN4OyvEzK8zOZmZdJWX4mhdE0jWmcoHiGQQWwb8jzGuDdI+x3lZldALwOfMnd942wj4gkoEhqyuDYxVnV73zd3Wnq6GF/UyeN7T00tnfT0N5DY0c3je09NLR109gR2779UCuN7d0cbutm+Mr76ZEUyvIyKcvLZGZ+LChKcjLIzoiQnZFKdnpk8HE0PUJORoRosD01RSEC4Q8g/wq41927zOwzwF3ARcN3MrPrgesBKisrJ7dCEYkbM6Mgmk5BNH3c7+np66eupYsDzZ0caIrdDjZ3sr+pkwPNnWyqaeTxLZ2DV7UbS2ZaCkXZGZTlx1oZ5UFroyw/Fi5l+ZmU5mZO+5Vo4xkGtcCcIc9n89ZAMQDufnjI0x8B3xnpg9x9FbAKYhe3mdgyRSSRpKWmDF6HYjTuTktXL+1dfbR29dLe3UtbVx9tXb20BY8HtrV29VDf2s2Bpk62vtnMb7YdfNs5GgOKg9lTOUHrYqCVkZ2eSjQjuB+yPSczQn5W2uAtLzNtSgdKPMPgZWCBmc0lFgIfBT4+dAczK3f3/cHTy4FtcaxHRJKEmZGXGfsFfKzcneaOXg40d7K/qWOw1XGwuZO6li7auvpo7OjhzcYO2rv7aOuOhU5339gtkay01LfCISsS3KcxI5pOYXY6hdF0ZmTHxkgGnhdE0ybl7PG4hYG795rZjcDjxKaW3uHuW8zsm8Bad38Y+IKZXQ70AkeAT8arHhGR8TAz8qNp5EfTOKUsd9zv6+7tpyMIh7auXlq6emnq6KG5o4emjh6a2nto7gweB7faxlhrpKG9520LFQ6XmxlhRnY615xTxV+8Z95EHOY7xHXMwN0fAR4Ztu3rQx7fDNwczxpERCZDeiSF9EgK+dHju4hRZ08fDe3dHGmLDZ4faeumob2bhraewe3FORkTXPVbwh5AFhERYtN1y/OzKM8ffSwknqbuaIaIiEwahYGIiCgMREREYSAiIigMREQEhYGIiKAwEBERFAYiIgKYD18Ldoozszpgz3G+vRion8BypoLpdkzT7Xhg+h3TdDsemH7HNNLxVLl7yWhvSLgwOBFmttbdl4ddx0Sabsc03Y4Hpt8xTbfjgel3TMdzPOomEhERhYGIiCRfGKwKu4A4mG7HNN2OB6bfMU2344Hpd0zHfDxJNWYgIiIjS7aWgYiIjEBhICIiyRMGZrbSzF4zsx1m9rWw65kIZrbbzF4xsw1mtjbseo6Vmd1hZofMbPOQbTPM7Ekz2x7cF4ZZ47Ea5Zj+wcxqg+9pg5ldFmaNx8LM5pjZajPbamZbzOymYHtCfk9HOZ5E/o4yzWyNmW0Mjukbwfa5ZvZS8DvvPjNLP+rnJMOYgZmlAq8DFwM1wMvAx9x9a6iFnSAz2w0sd/eEPFnGzC4AWoG73X1xsO07wBF3/1YQ2oXu/tUw6zwWoxzTPwCt7v4vYdZ2PMysHCh39/VmlgusA64kdr3yhPuejnI8HyFxvyMDst291czSgOeAm4AvAw+4+8/N7AfARnf//mifkywtg7OBHe6+0927gZ8DV4RcU9Jz92eAI8M2XwHcFTy+i9h/1IQxyjElLHff7+7rg8ctwDagggT9no5yPAnLY1qDp2nBzYGLgF8G28f8jpIlDCqAfUOe15Dg/wACDjxhZuvM7Pqwi5kgM919f/D4ADAzzGIm0I1mtinoRkqILpXhzKwaWAq8xDT4noYdDyTwd2RmqWa2ATgEPAm8ATS6e2+wy5i/85IlDKar8919GXAp8Lmgi2La8Fgf5nTox/w+MB84A9gP/Gu45Rw7M8sB7ge+6O7NQ19LxO9phONJ6O/I3fvc/QxgNrGekFOP9TOSJcHraWwAAAMfSURBVAxqgTlDns8OtiU0d68N7g8BDxL7R5DoDgb9ugP9u4dCrueEufvB4D9rP/BDEux7Cvqh7wfucfcHgs0J+z2NdDyJ/h0NcPdGYDVwLlBgZpHgpTF/5yVLGLwMLAhG19OBjwIPh1zTCTGz7GAADDPLBj4AbD76uxLCw8C1weNrgf8JsZYJMfBLM/DHJND3FAxO/hjY5u63DHkpIb+n0Y4nwb+jEjMrCB5nEZsos41YKFwd7Dbmd5QUs4kAgqli3wVSgTvc/Z9CLumEmNk8Yq0BgAjws0Q7JjO7F1hBbLndg8DfAw8BvwAqiS1V/hF3T5gB2VGOaQWx7gcHdgOfGdLfPqWZ2fnAs8ArQH+w+W+I9bMn3Pd0lOP5GIn7HS0hNkCcSuwP/F+4+zeD3xE/B2YAfwA+4e5do35OsoSBiIiMLlm6iURE5CgUBiIiojAQERGFgYiIoDAQEREUBiKDzKxvyKqVGyZydVszqx66kqnIVBMZexeRpNERnNIvknTUMhAZQ3DdiO8E145YY2YnBdurzey3weJmvzGzymD7TDN7MFhffqOZ/VHwUalm9sNgzfkngrNFMbMvBOvrbzKzn4d0mJLkFAYib8ka1k30p0Nea3L3dwG3ETuTHeDfgbvcfQlwD3BrsP1W4Gl3Px1YBmwJti8Abnf3RUAjcFWw/WvA0uBzbojXwYkcjc5AFgmYWau754ywfTdwkbvvDBY5O+DuRWZWT+xCKT3B9v3uXmxmdcDsoaf+B8slP+nuC4LnXwXS3P0fzewxYhfEeQh4aMja9CKTRi0DkfHxUR4fi6HrwvTx1pjdB4HbibUiXh6y0qTIpFEYiIzPnw65fyF4/DyxFXAB/ozYAmgAvwE+C4MXHckf7UPNLAWY4+6rga8C+cA7Wici8aa/QETekhVcLWrAY+4+ML200Mw2Efvr/mPBts8DPzGzvwLqgE8F228CVpnZdcRaAJ8ldsGUkaQC/xUEhgG3BmvSi0wqjRmIjCEYM1ju7vVh1yISL+omEhERtQxEREQtAxERQWEgIiIoDEREBIWBiIigMBAREeD/AxuE8KhUUveoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMFaMdCQT6td"
      },
      "source": [
        "##**Function to test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abdqlNLTPM2s",
        "outputId": "ca6fe566-afd1-402b-b37e-ea60b98f029b"
      },
      "source": [
        "\n",
        "def test_txtsql():\n",
        "    test_sql_data, test_table_data, TEST_DB = load_dataset(\"test\")\n",
        "\n",
        "    # load glove word embeddings and initialize the model\n",
        "    word_emb = load_word_embeddings('/content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt')\n",
        "    model = txtsql(word_emb, N_word=300, gpu=GPU)\n",
        "\n",
        "    # Load the best model state saved during training\n",
        "    agg_m, sel_m, cond_m = best_model_name()\n",
        "    model.agg_pred.load_state_dict(torch.load(agg_m))\n",
        "    model.sel_pred.load_state_dict(torch.load(sel_m))\n",
        "    model.cond_pred.load_state_dict(torch.load(cond_m))\n",
        "\n",
        "    # Run the model on the test data and get the logical accuracy\n",
        "    logical_accuracy_score =\\\n",
        "        epoch_acc(model, BATCH_SIZE, test_sql_data, test_table_data, save_results = True)\n",
        "\n",
        "    # Run the model on the test data and get the execution accuracy\n",
        "    execution_accuracy_score =\\\n",
        "        epoch_exec_acc(model, BATCH_SIZE, test_sql_data, test_table_data, TEST_DB)\n",
        "    \n",
        "    print(\"Test logical accuracy: %s;\\n  breakdown on (agg, sel, where): %s\" % logical_accuracy_score)\n",
        "    print(\"Test execution accuracy: %s\" % execution_accuracy_score)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test_txtsql()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset :  test\n",
            "Loading word embedding from /content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt\n",
            "txtsql where prediction\n",
            "Test logical accuracy: 0.48425494394760044;\n",
            "  breakdown on (agg, sel, where): [0.89772012 0.88304572 0.57500945]\n",
            "Test execution accuracy: 0.5655624134021917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMp_3Rc7AAE5"
      },
      "source": [
        "References:\n",
        "1. https://github.com/salesforce/WikiSQL\n",
        "2. https://github.com/tiwarikajal/Seq2SQL--Natural-Language-sentences-to-SQL-Queries"
      ]
    }
  ]
}