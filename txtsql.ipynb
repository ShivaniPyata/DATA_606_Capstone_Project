{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "txtsql.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdcYAQDRiLs7rURMcQGMQU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3HSyUiuQA2m"
      },
      "source": [
        "#**<center>Natural Language Text to SQL Query Conversion**\n",
        "##**<center>Augmented Pointer Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfvNEvMOHnnE",
        "outputId": "fe2ab193-8e60-4c56-a05c-d11c283127b6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnfGqTHdOXgj",
        "outputId": "afba35b4-f217-4bd7-8b53-00b44ada154f"
      },
      "source": [
        "pip install 'sqlalchemy>=1.3.0,<1.4.0' --force-reinstall"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sqlalchemy<1.4.0,>=1.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/31/44/a86070dda790ce94cd7d9fb9281cd614c7d30850ed774ace9a84d0d5d491/SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Installing collected packages: sqlalchemy\n",
            "  Found existing installation: SQLAlchemy 1.3.24\n",
            "    Uninstalling SQLAlchemy-1.3.24:\n",
            "      Successfully uninstalled SQLAlchemy-1.3.24\n",
            "Successfully installed sqlalchemy-1.3.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzW27N7iOa0b",
        "outputId": "bfce5717-2d3c-4a58-f476-a0b032b64444"
      },
      "source": [
        "pip install records"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: records in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: SQLAlchemy; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from records) (1.3.24)\n",
            "Requirement already satisfied: tablib>=0.11.4 in /usr/local/lib/python3.7/dist-packages (from records) (3.0.0)\n",
            "Requirement already satisfied: openpyxl<2.5.0 in /usr/local/lib/python3.7/dist-packages (from records) (2.4.11)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from records) (0.6.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.0.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUCi_adoOdAI",
        "outputId": "ab17636b-1462-43de-b407-32f87a749aa5"
      },
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import records\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import json\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import open\n",
        "from __future__ import unicode_literals, print_function, division"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToI2KwTq43q"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyBiVR_aOddj",
        "outputId": "b2fe3591-b0af-43b7-c437-faf0271c5f53"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import * \n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoVmMU4gOfbb"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/lib/')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MA8yLepOhhl"
      },
      "source": [
        "from lib_project import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8-CJeEg2WFc"
      },
      "source": [
        "#constants\n",
        "MAX_LENGTH = 50\n",
        "teacher_forcing_ratio = 1\n",
        "GPU = True\n",
        "BATCH_SIZE = 64\n",
        "TRAINING_EPOCHS = 30\n",
        "LEARNING_RATE = 1e-3"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9k304etAGWN"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVGyzn6-SUoq"
      },
      "source": [
        "##**Function to plot graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8m6orfWPEeH"
      },
      "source": [
        "\n",
        "\n",
        "def plot_data(x, y, xlabel = \"x\", ylabel = \"y\", label = 'plot'):\n",
        "\tplt.figure()\n",
        "\tplt.plot(x, y)\n",
        "\tplt.xlabel(xlabel)\n",
        "\tplt.ylabel(ylabel)\n",
        "\tprint(\"\\nGenerating plot for \", label)\n",
        "\tplt.savefig(\"./\" + label + \".png\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBdWn75Sxsy"
      },
      "source": [
        "##**Aggregation Predictor model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5cg3y2cVpOY"
      },
      "source": [
        "class AggregationPredictor(nn.Module):\n",
        "    def __init__(self, N_word, N_h, N_depth):\n",
        "        super(AggregationPredictor, self).__init__()\n",
        "\n",
        "        self.agg_lstm = nn.LSTM(input_size=N_word, hidden_size=N_h // 2,\n",
        "                                num_layers=N_depth, batch_first=True,\n",
        "                                dropout=0.3, bidirectional=True)\n",
        "\n",
        "        self.agg_att = nn.Linear(N_h, 1)\n",
        "        self.agg_out = nn.Sequential(nn.Linear(N_h, N_h), nn.Tanh(), nn.Linear(N_h, 6))\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x_emb_var, x_len, col_inp_var=None, col_name_len=None, col_len=None, col_num=None, ground_truth_sel=None):\n",
        "        B = len(x_emb_var)\n",
        "        max_x_len = max(x_len)\n",
        "\n",
        "        h_enc, _ = run_lstm(self.agg_lstm, x_emb_var, x_len)\n",
        "        att_val = self.agg_att(h_enc).squeeze()\n",
        "\n",
        "        for idx, num in enumerate(x_len):\n",
        "            if num < max_x_len:\n",
        "                att_val[idx, num:] = -100\n",
        "        att = self.softmax(att_val)\n",
        "\n",
        "        K_agg = (h_enc * att.unsqueeze(2).expand_as(h_enc)).sum(1)\n",
        "        agg_score = self.agg_out(K_agg)\n",
        "        return agg_score\n",
        "        "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3IJvbsNS4Uf"
      },
      "source": [
        "##**Selection Predictor Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq9kxo_AV3O8"
      },
      "source": [
        "class SelectionClausePredictor(nn.Module):\n",
        "    def __init__(self, N_word, N_h, N_depth, max_tok_num):\n",
        "        super(SelectionClausePredictor, self).__init__()\n",
        "        self.max_tok_num = max_tok_num\n",
        "        self.sel_lstm = nn.LSTM(input_size=N_word, hidden_size=N_h // 2, num_layers=N_depth, batch_first=True,\n",
        "                                dropout=0.3, bidirectional=True)\n",
        "        self.sel_att = nn.Linear(N_h, 1)\n",
        "        self.sel_col_name_enc = nn.LSTM(input_size=N_word, hidden_size=N_h // 2,\n",
        "                                        num_layers=N_depth, batch_first=True,\n",
        "                                        dropout=0.3, bidirectional=True)\n",
        "        self.sel_out_K = nn.Linear(N_h, N_h)\n",
        "        self.sel_out_col = nn.Linear(N_h, N_h)\n",
        "        self.sel_out = nn.Sequential(nn.Tanh(), nn.Linear(N_h, 1))\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x_emb_var, x_len, col_inp_var,\n",
        "                col_name_len, col_len, col_num):\n",
        "        B = len(x_emb_var)\n",
        "        max_x_len = max(x_len)\n",
        "\n",
        "        e_col, _ = col_name_encode(col_inp_var, col_name_len,\n",
        "                                   col_len, self.sel_col_name_enc)\n",
        "\n",
        "        h_enc, _ = run_lstm(self.sel_lstm, x_emb_var, x_len)\n",
        "        att_val = self.sel_att(h_enc).squeeze()\n",
        "        for idx, num in enumerate(x_len):\n",
        "            if num < max_x_len:\n",
        "                att_val[idx, num:] = -100\n",
        "        att = self.softmax(att_val)\n",
        "        K_sel = (h_enc * att.unsqueeze(2).expand_as(h_enc)).sum(1)\n",
        "        K_sel_expand = K_sel.unsqueeze(1)\n",
        "\n",
        "        sel_score = self.sel_out(self.sel_out_K(K_sel_expand) + \\\n",
        "                                 self.sel_out_col(e_col)).squeeze()\n",
        "        max_col_num = max(col_num)\n",
        "        for idx, num in enumerate(col_num):\n",
        "            if num < max_col_num:\n",
        "                sel_score[idx, num:] = -100\n",
        "\n",
        "        return sel_score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isWIWgxUS8Yw"
      },
      "source": [
        "##**Condition Predictor model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwRAUjLIVv4h"
      },
      "source": [
        "class ConditionPredictor(nn.Module):\n",
        "    def __init__(self, N_word, N_h, N_depth, max_col_num, max_tok_num, gpu):\n",
        "        super(ConditionPredictor, self).__init__()\n",
        "        print(\"txtsql where prediction\")\n",
        "        self.N_h = N_h\n",
        "        self.max_tok_num = max_tok_num\n",
        "        self.max_col_num = max_col_num\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.cond_lstm = nn.LSTM(input_size=N_word, hidden_size=N_h // 2,\n",
        "                                 num_layers=N_depth, batch_first=True,\n",
        "                                 dropout=0.3, bidirectional=True)\n",
        "        self.cond_decoder = nn.LSTM(input_size=self.max_tok_num,\n",
        "                                    hidden_size=N_h, num_layers=N_depth,\n",
        "                                    batch_first=True, dropout=0.3)\n",
        "\n",
        "        self.cond_out_g = nn.Linear(N_h, N_h)\n",
        "        self.cond_out_h = nn.Linear(N_h, N_h)\n",
        "        self.cond_out = nn.Sequential(nn.Tanh(), nn.Linear(N_h, 1))\n",
        "\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def gen_ground_truth_batch(self, tok_seq, gen_inp=True):\n",
        "        B = len(tok_seq)\n",
        "        ret_len = np.array([len(one_tok_seq) - 1 for one_tok_seq in tok_seq])\n",
        "        max_len = max(ret_len)\n",
        "        ret_array = np.zeros((B, max_len, self.max_tok_num), dtype=np.float32)\n",
        "        for b, one_tok_seq in enumerate(tok_seq):\n",
        "            out_one_tok_seq = one_tok_seq[:-1] if gen_inp else one_tok_seq[1:]\n",
        "            for t, tok_id in enumerate(out_one_tok_seq):\n",
        "                ret_array[b, t, tok_id] = 1\n",
        "\n",
        "        ret_inp = torch.from_numpy(ret_array)\n",
        "        if self.gpu:\n",
        "            ret_inp = ret_inp.cuda()\n",
        "        ret_inp_var = Variable(ret_inp)\n",
        "\n",
        "        return ret_inp_var, ret_len\n",
        "\n",
        "    def forward(self, x_emb_var, x_len, col_inp_var, col_name_len, col_len,\n",
        "                col_num, ground_truth_where, ground_truth_cond):\n",
        "        max_x_len = max(x_len)\n",
        "        B = len(x_len)\n",
        "\n",
        "        h_enc, hidden = run_lstm(self.cond_lstm, x_emb_var, x_len)\n",
        "        decoder_hidden = tuple(torch.cat((hid[:2], hid[2:]), dim=2)\n",
        "                               for hid in hidden)\n",
        "        if ground_truth_where is not None:\n",
        "            ground_truth_tok_seq, ground_truth_tok_len = self.gen_ground_truth_batch(ground_truth_where, gen_inp=True)\n",
        "            g_s, _ = run_lstm(self.cond_decoder,\n",
        "                              ground_truth_tok_seq, ground_truth_tok_len, decoder_hidden)\n",
        "\n",
        "            h_enc_expand = h_enc.unsqueeze(1)\n",
        "            g_s_expand = g_s.unsqueeze(2)\n",
        "            cond_score = self.cond_out(self.cond_out_h(h_enc_expand) +\n",
        "                                       self.cond_out_g(g_s_expand)).squeeze()\n",
        "            for idx, num in enumerate(x_len):\n",
        "                if num < max_x_len:\n",
        "                    cond_score[idx, :, num:] = -100\n",
        "        else:\n",
        "            h_enc_expand = h_enc.unsqueeze(1)\n",
        "            scores = []\n",
        "            done_set = set()\n",
        "\n",
        "            t = 0\n",
        "            init_inp = np.zeros((B, 1, self.max_tok_num), dtype=np.float32)\n",
        "            init_inp[:, 0, 7] = 1  # Set the <BEG> token\n",
        "            if self.gpu:\n",
        "                cur_inp = Variable(torch.from_numpy(init_inp).cuda())\n",
        "            else:\n",
        "                cur_inp = Variable(torch.from_numpy(init_inp))\n",
        "            cur_h = decoder_hidden\n",
        "            while len(done_set) < B and t < 100:\n",
        "                g_s, cur_h = self.cond_decoder(cur_inp, cur_h)\n",
        "                g_s_expand = g_s.unsqueeze(2)\n",
        "\n",
        "                cur_cond_score = self.cond_out(self.cond_out_h(h_enc_expand) +\n",
        "                                               self.cond_out_g(g_s_expand)).squeeze()\n",
        "                for b, num in enumerate(x_len):\n",
        "                    if num < max_x_len:\n",
        "                        cur_cond_score[b, num:] = -100\n",
        "                scores.append(cur_cond_score)\n",
        "\n",
        "                _, ans_tok_var = cur_cond_score.view(B, max_x_len).max(1)\n",
        "                ans_tok_var = ans_tok_var.unsqueeze(1)\n",
        "\n",
        "                ans_tok = ans_tok_var.data.cpu()\n",
        "                if self.gpu:  # To one-hot\n",
        "                    cur_inp = Variable(torch.zeros(\n",
        "                        B, self.max_tok_num).scatter_(1, ans_tok, 1).cuda())\n",
        "                else:\n",
        "                    cur_inp = Variable(torch.zeros(\n",
        "                        B, self.max_tok_num).scatter_(1, ans_tok, 1))\n",
        "                cur_inp = cur_inp.unsqueeze(1)\n",
        "\n",
        "                for idx, tok in enumerate(ans_tok.squeeze()):\n",
        "                    if tok == 1:  # Find the <END> token\n",
        "                        done_set.add(idx)\n",
        "                t += 1\n",
        "\n",
        "            cond_score = torch.stack(scores, 1)\n",
        "\n",
        "        return cond_score\n",
        "        \n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN1DO_xGTGfe"
      },
      "source": [
        "##**txtsql model comprising of three models** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNggx0s2Sqnb"
      },
      "source": [
        "class txtsql(nn.Module):\n",
        "    \"\"\"\n",
        "    txtsql Model which is internally comprised of three individual models\n",
        "    1. Aggregation predictor\n",
        "    2. Selection Predictor\n",
        "    3. Condition Predictor\n",
        "    \"\"\"\n",
        "    def __init__(self, emb, N_word, N_h=100, N_depth=2,\n",
        "                 gpu=False):\n",
        "        super(txtsql, self).__init__()\n",
        "\n",
        "        self.gpu = gpu\n",
        "        self.N_h = N_h\n",
        "        self.N_depth = N_depth\n",
        "\n",
        "        self.maximum_column_count = 45\n",
        "        self.maximum_token_count = 200\n",
        "        self.SQL_SYNTAX_TOKENS = [\n",
        "            '<UNK>', '<END>', 'WHERE', 'AND',\n",
        "            'EQL', 'GT', 'LT', '<BEG>'\n",
        "        ]\n",
        "\n",
        "        # Word embedding\n",
        "        self.embed_layer = Embedding(emb, N_word, gpu, self.SQL_SYNTAX_TOKENS, our_model=False)\n",
        "\n",
        "        # Model for predicting aggregation clause\n",
        "        self.agg_pred = AggregationPredictor(N_word, N_h, N_depth)\n",
        "\n",
        "        # Model for predicting select columns\n",
        "        self.sel_pred = SelectionClausePredictor(N_word, N_h, N_depth, self.maximum_token_count)\n",
        "\n",
        "        # Model for predicting the conditions\n",
        "        self.cond_pred = ConditionPredictor(N_word, N_h, N_depth, self.maximum_column_count, self.maximum_token_count, gpu)\n",
        "\n",
        "        # Loss function\n",
        "        self.CE = nn.CrossEntropyLoss()\n",
        "        if gpu:\n",
        "            self.cuda()\n",
        "\n",
        "    def generate_ground_truth_where_seq(self, q, col, query):\n",
        "        ret_seq = []\n",
        "        for cur_q, cur_col, cur_query in zip(q, col, query):\n",
        "            connect_col = [tok for col_tok in cur_col for tok in col_tok + [',']]\n",
        "            all_toks = self.SQL_SYNTAX_TOKENS + connect_col + [None] + cur_q + [None]\n",
        "            cur_seq = [all_toks.index('<BEG>')]\n",
        "            if 'WHERE' in cur_query:\n",
        "                cur_where_query = cur_query[cur_query.index('WHERE'):]\n",
        "                cur_seq = cur_seq + list(map(lambda tok: all_toks.index(tok)\n",
        "                if tok in all_toks else 0, cur_where_query))\n",
        "            cur_seq.append(all_toks.index('<END>'))\n",
        "            ret_seq.append(cur_seq)\n",
        "        return ret_seq\n",
        "\n",
        "    def forward(self, q, col, col_num, ground_truth_where=None, ground_truth_cond=None, ground_truth_sel=None):\n",
        "        x_emb_var, x_len = self.embed_layer.gen_x_batch(q, col)\n",
        "        batch = self.embed_layer.gen_col_batch(col)\n",
        "        col_inp_var, col_name_len, col_len = batch\n",
        "\n",
        "        agg_score = self.agg_pred(x_emb_var, x_len)\n",
        "\n",
        "        sel_score = self.sel_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num)\n",
        "\n",
        "        cond_score = self.cond_pred(x_emb_var, x_len, col_inp_var, col_name_len, col_len, col_num, ground_truth_where, ground_truth_cond)\n",
        "\n",
        "        return (agg_score, sel_score, cond_score)\n",
        "\n",
        "    def loss(self, score, truth_num, ground_truth_where):\n",
        "        agg_score, sel_score, cond_score = score\n",
        "        loss = 0\n",
        "        agg_truth = list(map(lambda x: x[0], truth_num))\n",
        "        data = torch.from_numpy(np.array(agg_truth))\n",
        "        if self.gpu:\n",
        "            agg_truth_var = Variable(data.cuda())\n",
        "        else:\n",
        "            agg_truth_var = Variable(data)\n",
        "\n",
        "        loss += self.CE(agg_score, agg_truth_var.long())\n",
        "\n",
        "        sel_truth = list(map(lambda x: x[1], truth_num))\n",
        "        data = torch.from_numpy(np.array(sel_truth))\n",
        "        if self.gpu:\n",
        "            sel_truth_var = Variable(data).cuda()\n",
        "        else:\n",
        "            sel_truth_var = Variable(data)\n",
        "\n",
        "        loss += self.CE(sel_score, sel_truth_var.long())\n",
        "\n",
        "        for b in range(len(ground_truth_where)):\n",
        "            if self.gpu:\n",
        "                cond_truth_var = Variable(torch.from_numpy(np.array(ground_truth_where[b][1:])).cuda())\n",
        "            else:\n",
        "                cond_truth_var = Variable(torch.from_numpy(np.array(ground_truth_where[b][1:])))\n",
        "            cond_pred_score = cond_score[b, :len(ground_truth_where[b]) - 1]\n",
        "\n",
        "            loss += (self.CE(\n",
        "                cond_pred_score, cond_truth_var.long()) / len(ground_truth_where))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def check_accuracy(self, pred_queries, ground_truth_queries):\n",
        "        tot_err = agg_err = sel_err = cond_err = cond_num_err = \\\n",
        "            cond_col_err = cond_op_err = cond_val_err = 0.0\n",
        "        for b, (pred_qry, ground_truth_qry) in enumerate(zip(pred_queries, ground_truth_queries)):\n",
        "            good = True\n",
        "\n",
        "            agg_pred = pred_qry['agg']\n",
        "            agg_gt = ground_truth_qry['agg']\n",
        "            if agg_pred != agg_gt:\n",
        "                agg_err += 1\n",
        "                good = False\n",
        "\n",
        "            sel_pred = pred_qry['sel']\n",
        "            sel_gt = ground_truth_qry['sel']\n",
        "            if sel_pred != sel_gt:\n",
        "                sel_err += 1\n",
        "                good = False\n",
        "\n",
        "            cond_pred = pred_qry['conds']\n",
        "            cond_gt = ground_truth_qry['conds']\n",
        "            flag = True\n",
        "            if len(cond_pred) != len(cond_gt):\n",
        "                flag = False\n",
        "                cond_num_err += 1\n",
        "\n",
        "            if flag and set(\n",
        "                    x[0] for x in cond_pred) != set(x[0] for x in cond_gt):\n",
        "                flag = False\n",
        "                cond_col_err += 1\n",
        "\n",
        "            for idx in range(len(cond_pred)):\n",
        "                if not flag:\n",
        "                    break\n",
        "                ground_truth_idx = tuple(x[0] for x in cond_gt).index(cond_pred[idx][0])\n",
        "                if flag and cond_gt[ground_truth_idx][1] != cond_pred[idx][1]:\n",
        "                    flag = False\n",
        "                    cond_op_err += 1\n",
        "\n",
        "            for idx in range(len(cond_pred)):\n",
        "                if not flag:\n",
        "                    break\n",
        "                ground_truth_idx = tuple(x[0] for x in cond_gt).index(cond_pred[idx][0])\n",
        "                if flag and str(cond_gt[ground_truth_idx][2]).lower() != \\\n",
        "                        str(cond_pred[idx][2]).lower():\n",
        "                    flag = False\n",
        "                    cond_val_err += 1\n",
        "\n",
        "            if not flag:\n",
        "                cond_err += 1\n",
        "                good = False\n",
        "\n",
        "            if not good:\n",
        "                tot_err += 1\n",
        "\n",
        "        return np.array((agg_err, sel_err, cond_err)), tot_err\n",
        "\n",
        "    def gen_query(self, score, q, col, raw_q, raw_col, verbose=False):\n",
        "        def merge_tokens(tok_list, raw_tok_str):\n",
        "            tok_str = raw_tok_str.lower()\n",
        "            alphabet = 'abcdefghijklmnopqrstuvwxyz0123456789$('\n",
        "            special = {'-LRB-': '(', '-RRB-': ')', '-LSB-': '[', '-RSB-': ']',\n",
        "                       '``': '\"', '\\'\\'': '\"', '--': u'\\u2013'}\n",
        "            ret = ''\n",
        "            double_quote_appear = 0\n",
        "            for raw_tok in tok_list:\n",
        "                if not raw_tok:\n",
        "                    continue\n",
        "                tok = special.get(raw_tok, raw_tok)\n",
        "                if tok == '\"':\n",
        "                    double_quote_appear = 1 - double_quote_appear\n",
        "\n",
        "                if len(ret) == 0:\n",
        "                    pass\n",
        "                elif len(ret) > 0 and ret + ' ' + tok in tok_str:\n",
        "                    ret = ret + ' '\n",
        "                elif len(ret) > 0 and ret + tok in tok_str:\n",
        "                    pass\n",
        "                elif tok == '\"':\n",
        "                    if double_quote_appear:\n",
        "                        ret = ret + ' '\n",
        "                elif tok[0] not in alphabet:\n",
        "                    pass\n",
        "                elif (ret[-1] not in ['(', '/', u'\\u2013', '#', '$', '&']) and \\\n",
        "                        (ret[-1] != '\"' or not double_quote_appear):\n",
        "                    ret = ret + ' '\n",
        "                ret = ret + tok\n",
        "            return ret.strip()\n",
        "\n",
        "        agg_score, sel_score, cond_score = score\n",
        "\n",
        "        ret_queries = []\n",
        "        B = len(cond_score)\n",
        "        for b in range(B):\n",
        "            cur_query = {}\n",
        "            cur_query['agg'] = np.argmax(agg_score[b].data.cpu().numpy())\n",
        "            cur_query['sel'] = np.argmax(sel_score[b].data.cpu().numpy())\n",
        "            cur_query['conds'] = []\n",
        "            all_toks = self.SQL_SYNTAX_TOKENS + \\\n",
        "                       [x for toks in col[b] for x in\n",
        "                        toks + [',']] + [''] + q[b] + ['']\n",
        "            cond_toks = []\n",
        "            for where_score in cond_score[b].data.cpu().numpy():\n",
        "                cond_tok = np.argmax(where_score)\n",
        "                cond_val = all_toks[cond_tok]\n",
        "                if cond_val == '<END>':\n",
        "                    break\n",
        "                cond_toks.append(cond_val)\n",
        "\n",
        "            if verbose:\n",
        "                print(cond_toks)\n",
        "            if len(cond_toks) > 0:\n",
        "                cond_toks = cond_toks[1:]\n",
        "            st = 0\n",
        "            while st < len(cond_toks):\n",
        "                cur_cond = [None, None, None]\n",
        "                ed = len(cond_toks) if 'AND' not in cond_toks[st:] \\\n",
        "                    else cond_toks[st:].index('AND') + st\n",
        "                if 'EQL' in cond_toks[st:ed]:\n",
        "                    op = cond_toks[st:ed].index('EQL') + st\n",
        "                    cur_cond[1] = 0\n",
        "                elif 'GT' in cond_toks[st:ed]:\n",
        "                    op = cond_toks[st:ed].index('GT') + st\n",
        "                    cur_cond[1] = 1\n",
        "                elif 'LT' in cond_toks[st:ed]:\n",
        "                    op = cond_toks[st:ed].index('LT') + st\n",
        "                    cur_cond[1] = 2\n",
        "                else:\n",
        "                    op = st\n",
        "                    cur_cond[1] = 0\n",
        "                sel_col = cond_toks[st:op]\n",
        "                to_idx = [x.lower() for x in raw_col[b]]\n",
        "                pred_col = merge_tokens(sel_col, raw_q[b] + ' || ' + \\\n",
        "                                        ' || '.join(raw_col[b]))\n",
        "                if pred_col in to_idx:\n",
        "                    cur_cond[0] = to_idx.index(pred_col)\n",
        "                else:\n",
        "                    cur_cond[0] = 0\n",
        "                cur_cond[2] = merge_tokens(cond_toks[op + 1:ed], raw_q[b])\n",
        "                cur_query['conds'].append(cur_cond)\n",
        "                st = ed + 1\n",
        "            ret_queries.append(cur_query)\n",
        "\n",
        "        return ret_queries\n",
        "\n",
        "\n",
        "    def save_readable_results(self, predicted_query, ground_truth, table_ids, table_data):\n",
        "        file = open(\"./target_model_results.txt\", \"a+\", encoding=\"utf-8\")\n",
        "        for index in range(len(predicted_query)):\n",
        "            predicted_query_object = Query.from_dict(predicted_query[index])\n",
        "            ground_truth_query_object = Query.from_dict(ground_truth[index])\n",
        "            table_id = table_ids[index]\n",
        "            table_info = table_data[table_id]\n",
        "            table = Table(table_id, table_info[\"header\"], table_info[\"types\"], table_info[\"rows\"])\n",
        "            \n",
        "            file.write(table.query_str(ground_truth_query_object))\n",
        "            file.write(\"\\n\")\n",
        "            file.write(table.query_str(predicted_query_object))\n",
        "            file.write(\"\\n\\n\")\n",
        "        file.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcy-TeZqT1vI"
      },
      "source": [
        "##**Function to train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-EE3KigEaZTw",
        "outputId": "57435f3c-676a-4fc9-c6da-e800b541f86c"
      },
      "source": [
        "def train_txtsql():\n",
        "    # Load training and validation (dev) dataset\n",
        "    sql_data, table_data, TRAIN_DB = load_dataset(\"train\")\n",
        "    validation_sql_data, validation_table_data, DEV_DB = load_dataset(\"dev\")\n",
        "\n",
        "    # Load the glove word embeddings\n",
        "    emb = load_word_embeddings('/content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt')\n",
        "\n",
        "    # Initialize the target model with the word embeddings\n",
        "    model = txtsql(emb, N_word=300, gpu=GPU)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Load the file names for the best models that we find during training\n",
        "    aggregator_model, selection_model, condition_model = best_model_name()\n",
        "\n",
        "    # Initialize the starting values of accuracy by running the model once without training\n",
        "    init_acc = epoch_acc(model, BATCH_SIZE, validation_sql_data, validation_table_data)\n",
        "    best_agg_acc = init_acc[1][0]\n",
        "    best_agg_idx = 0\n",
        "    best_sel_acc = init_acc[1][1]\n",
        "    best_sel_idx = 0\n",
        "    best_cond_acc = init_acc[1][2]\n",
        "    best_cond_idx = 0\n",
        "    print('Initial dev accuracy: %s\\n  breakdown on (agg, sel, where): %s' % init_acc)\n",
        "\n",
        "    # Save the untrained model as the initial best\n",
        "    torch.save(model.sel_pred.state_dict(), selection_model)\n",
        "    torch.save(model.agg_pred.state_dict(), aggregator_model)\n",
        "    torch.save(model.cond_pred.state_dict(), condition_model)\n",
        "    \n",
        "    # Store the losses per epoch for loss curve\n",
        "    epoch_losses = []\n",
        "\n",
        "    for i in range(TRAINING_EPOCHS):\n",
        "        print('Epoch :', i + 1)\n",
        "        \n",
        "        # Train the model on training dataset only\n",
        "        epoch_loss = epoch_train(model, optimizer, BATCH_SIZE, sql_data, table_data)\n",
        "        epoch_losses.append(epoch_loss)\n",
        "\n",
        "        print('Loss =', epoch_loss)\n",
        "\n",
        "        # Check model accuracy on training and validation set\n",
        "        training_accuracy = epoch_acc(model, BATCH_SIZE, sql_data, table_data)\n",
        "        print('Train accuracy: %s\\n   breakdown result: %s' % training_accuracy)\n",
        "        \n",
        "        validation_accuracy = epoch_acc(model, BATCH_SIZE, validation_sql_data, validation_table_data)\n",
        "        print('Dev accuracy: %s\\n   breakdown result: %s' % validation_accuracy)\n",
        "        \n",
        "        # If the accuracy is better than the previous best, update the best scores and models\n",
        "        if validation_accuracy[1][0] > best_agg_acc:\n",
        "            best_agg_acc = validation_accuracy[1][0]\n",
        "            best_agg_idx = i + 1\n",
        "            torch.save(model.agg_pred.state_dict(), aggregator_model)\n",
        "        if validation_accuracy[1][1] > best_sel_acc:\n",
        "            best_sel_acc = validation_accuracy[1][1]\n",
        "            best_sel_idx = i + 1\n",
        "            torch.save(model.sel_pred.state_dict(), selection_model)\n",
        "        if validation_accuracy[1][2] > best_cond_acc:\n",
        "            best_cond_acc = validation_accuracy[1][2]\n",
        "            best_cond_idx = i + 1\n",
        "            torch.save(model.cond_pred.state_dict(), condition_model)\n",
        "\n",
        "        print('Best val accuracy = %s, on epoch %s individually' % (\n",
        "            (best_agg_acc, best_sel_acc, best_cond_acc),\n",
        "            (best_agg_idx, best_sel_idx, best_cond_idx)))\n",
        "\n",
        "    # save epoch vs loss graph\n",
        "    plot_data(x = range(TRAINING_EPOCHS), y = epoch_losses, xlabel = \"Epochs\", ylabel = \"Loss\", label = \"Loss Graph for target txtsql model\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_txtsql()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset :  train\n",
            "Loading dataset :  dev\n",
            "Loading word embedding from /content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt\n",
            "txtsql where prediction\n",
            "Initial dev accuracy: 0.0\n",
            "  breakdown on (agg, sel, where): [0.71452322 0.16553853 0.        ]\n",
            "Epoch : 1\n",
            "Loss = 3.5831952608337145\n",
            "Train accuracy: 0.051193328009937006\n",
            "   breakdown result: [0.89976045 0.3087215  0.18598172]\n",
            "Dev accuracy: 0.048687804298776866\n",
            "   breakdown result: [0.89110557 0.31088944 0.18299489]\n",
            "Best val accuracy = (0.8911055694098088, 0.3108894430590191, 0.18299489371808575), on epoch (1, 1, 1) individually\n",
            "Epoch : 2\n",
            "Loss = 2.611871799687804\n",
            "Train accuracy: 0.11869399343447787\n",
            "   breakdown result: [0.90726644 0.41623636 0.29844734]\n",
            "Dev accuracy: 0.10913193207457547\n",
            "   breakdown result: [0.89644935 0.41218383 0.28132051]\n",
            "Best val accuracy = (0.8964493528084551, 0.4121838261489134, 0.28132050825317656), on epoch (2, 2, 2) individually\n",
            "Epoch : 3\n",
            "Loss = 2.240994863516055\n",
            "Train accuracy: 0.21185342915446723\n",
            "   breakdown result: [0.91177358 0.59449916 0.36115695]\n",
            "Dev accuracy: 0.19190119938249614\n",
            "   breakdown result: [0.89894312 0.58318489 0.33843962]\n",
            "Best val accuracy = (0.8989431183944899, 0.5831848949055931, 0.3384396152475953), on epoch (3, 3, 3) individually\n",
            "Epoch : 4\n",
            "Loss = 1.8713658727079474\n",
            "Train accuracy: 0.30027504214355427\n",
            "   breakdown result: [0.91344158 0.726963   0.41455062]\n",
            "Dev accuracy: 0.2706329414558841\n",
            "   breakdown result: [0.89811186 0.71107944 0.38522741]\n",
            "Best val accuracy = (0.8989431183944899, 0.7110794442465266, 0.38522740767129793), on epoch (3, 4, 4) individually\n",
            "Epoch : 5\n",
            "Loss = 1.598644944215009\n",
            "Train accuracy: 0.3498890959098572\n",
            "   breakdown result: [0.92029101 0.78889185 0.44862035]\n",
            "Dev accuracy: 0.30518940743379647\n",
            "   breakdown result: [0.89894312 0.76617979 0.40375252]\n",
            "Best val accuracy = (0.8989431183944899, 0.7661797886236789, 0.40375252345327156), on epoch (3, 5, 5) individually\n",
            "Epoch : 6\n",
            "Loss = 1.4155722576431073\n",
            "Train accuracy: 0.39190843758317806\n",
            "   breakdown result: [0.92245586 0.83266791 0.48206903]\n",
            "Dev accuracy: 0.34010212563828524\n",
            "   breakdown result: [0.89134307 0.80429878 0.43379646]\n",
            "Best val accuracy = (0.8989431183944899, 0.8042987768673554, 0.4337964612278827), on epoch (3, 6, 6) individually\n",
            "Epoch : 7\n",
            "Loss = 1.2777365040032402\n",
            "Train accuracy: 0.4268121728329341\n",
            "   breakdown result: [0.92909236 0.84977376 0.5140094 ]\n",
            "Dev accuracy: 0.3600522503265645\n",
            "   breakdown result: [0.89359933 0.81415509 0.45909037]\n",
            "Best val accuracy = (0.8989431183944899, 0.814155088469303, 0.45909036931480823), on epoch (3, 7, 7) individually\n",
            "Epoch : 8\n",
            "Loss = 1.1710452702292722\n",
            "Train accuracy: 0.4516546890249312\n",
            "   breakdown result: [0.93439801 0.86260314 0.53649188]\n",
            "Dev accuracy: 0.3734710841942762\n",
            "   breakdown result: [0.8876618  0.81748011 0.4713217 ]\n",
            "Best val accuracy = (0.8989431183944899, 0.8174801092506828, 0.4713216957605985), on epoch (3, 8, 8) individually\n",
            "Epoch : 9\n",
            "Loss = 1.089270220406994\n",
            "Train accuracy: 0.4833466418241505\n",
            "   breakdown result: [0.94131843 0.88487268 0.56037619]\n",
            "Dev accuracy: 0.39353995962474764\n",
            "   breakdown result: [0.89312433 0.839449   0.48925306]\n",
            "Best val accuracy = (0.8989431183944899, 0.8394489965562285, 0.48925305783161144), on epoch (3, 9, 9) individually\n",
            "Epoch : 10\n",
            "Loss = 1.0199064826406885\n",
            "Train accuracy: 0.5045515038594623\n",
            "   breakdown result: [0.94637565 0.89404667 0.57904356]\n",
            "Dev accuracy: 0.39757748485928035\n",
            "   breakdown result: [0.87875549 0.84348652 0.49756561]\n",
            "Best val accuracy = (0.8989431183944899, 0.8434865217907612, 0.49756560978506115), on epoch (3, 10, 10) individually\n",
            "Epoch : 11\n",
            "Loss = 0.9500521052159748\n",
            "Train accuracy: 0.5233608375476888\n",
            "   breakdown result: [0.95150386 0.90504835 0.59029367]\n",
            "Dev accuracy: 0.41372758579741126\n",
            "   breakdown result: [0.88659304 0.84989906 0.5125282 ]\n",
            "Best val accuracy = (0.8989431183944899, 0.8498990618691367, 0.5125282033012706), on epoch (3, 11, 11) individually\n",
            "Epoch : 12\n",
            "Loss = 0.8993675945486492\n",
            "Train accuracy: 0.5409280454263153\n",
            "   breakdown result: [0.95636589 0.91271404 0.60399255]\n",
            "Dev accuracy: 0.41099631872699205\n",
            "   breakdown result: [0.87507422 0.85429284 0.5127657 ]\n",
            "Best val accuracy = (0.8989431183944899, 0.8542928393302458, 0.5127657047856549), on epoch (3, 12, 12) individually\n",
            "Epoch : 13\n",
            "Loss = 0.8474307505528745\n",
            "Train accuracy: 0.5514328808446456\n",
            "   breakdown result: [0.95874368 0.91805519 0.61052258]\n",
            "Dev accuracy: 0.416933855836599\n",
            "   breakdown result: [0.88279302 0.85524285 0.51490322]\n",
            "Best val accuracy = (0.8989431183944899, 0.8552428452677829, 0.5149032181451134), on epoch (3, 13, 13) individually\n",
            "Epoch : 14\n",
            "Loss = 0.8032996055661241\n",
            "Train accuracy: 0.5831248336438648\n",
            "   breakdown result: [0.96774022 0.92689202 0.6373525 ]\n",
            "Dev accuracy: 0.42726517040731504\n",
            "   breakdown result: [0.87875549 0.85880537 0.53235958]\n",
            "Best val accuracy = (0.8989431183944899, 0.8588053675335471, 0.5323595772473578), on epoch (3, 14, 14) individually\n",
            "Epoch : 15\n",
            "Loss = 0.7666459502191046\n",
            "Train accuracy: 0.5782805429864254\n",
            "   breakdown result: [0.97065034 0.93196699 0.62842694]\n",
            "Dev accuracy: 0.42299014368839805\n",
            "   breakdown result: [0.87804299 0.86438665 0.52131576]\n",
            "Best val accuracy = (0.8989431183944899, 0.8643866524165776, 0.5323595772473578), on epoch (3, 15, 14) individually\n",
            "Epoch : 16\n",
            "Loss = 0.7250777400002146\n",
            "Train accuracy: 0.6068494366072221\n",
            "   breakdown result: [0.97350723 0.93223316 0.65731523]\n",
            "Dev accuracy: 0.4373589834936468\n",
            "   breakdown result: [0.87258045 0.86034913 0.54316589]\n",
            "Best val accuracy = (0.8989431183944899, 0.8643866524165776, 0.5431658947868424), on epoch (3, 15, 16) individually\n",
            "Epoch : 17\n",
            "Loss = 0.697474215168378\n",
            "Train accuracy: 0.6224647324993345\n",
            "   breakdown result: [0.97719812 0.9390826  0.66895573]\n",
            "Dev accuracy: 0.44662154138463367\n",
            "   breakdown result: [0.87733048 0.8637929  0.54969719]\n",
            "Best val accuracy = (0.8989431183944899, 0.8643866524165776, 0.5496971856074101), on epoch (3, 15, 17) individually\n",
            "Epoch : 18\n",
            "Loss = 0.6643922258958072\n",
            "Train accuracy: 0.6338213113299619\n",
            "   breakdown result: [0.98028569 0.94314613 0.6770118 ]\n",
            "Dev accuracy: 0.44282151763448524\n",
            "   breakdown result: [0.87507422 0.86557416 0.54791592]\n",
            "Best val accuracy = (0.8989431183944899, 0.865574159838499, 0.5496971856074101), on epoch (3, 18, 17) individually\n",
            "Epoch : 19\n",
            "Loss = 0.6367964033595672\n",
            "Train accuracy: 0.6421435542542809\n",
            "   breakdown result: [0.982557   0.94554166 0.68311596]\n",
            "Dev accuracy: 0.44947155919724496\n",
            "   breakdown result: [0.8712742  0.86806793 0.55551597]\n",
            "Best val accuracy = (0.8989431183944899, 0.8680679254245339, 0.5555159719748248), on epoch (3, 19, 19) individually\n",
            "Epoch : 20\n",
            "Loss = 0.6139299537261687\n",
            "Train accuracy: 0.6466506964776861\n",
            "   breakdown result: [0.98085352 0.9508828  0.6851566 ]\n",
            "Dev accuracy: 0.4523215770098563\n",
            "   breakdown result: [0.879943   0.87091794 0.55029094]\n",
            "Best val accuracy = (0.8989431183944899, 0.8709179432371452, 0.5555159719748248), on epoch (3, 20, 19) individually\n",
            "Epoch : 21\n",
            "Loss = 0.591201037026247\n",
            "Train accuracy: 0.6569071067340964\n",
            "   breakdown result: [0.98502351 0.95308313 0.69188182]\n",
            "Dev accuracy: 0.45588409927562046\n",
            "   breakdown result: [0.87780549 0.87163045 0.55836599]\n",
            "Best val accuracy = (0.8989431183944899, 0.8716304476902981, 0.5583659897874361), on epoch (3, 21, 21) individually\n",
            "Epoch : 22\n",
            "Loss = 0.5723271406920586\n",
            "Train accuracy: 0.6783249046224825\n",
            "   breakdown result: [0.98635436 0.95581581 0.71228817]\n",
            "Dev accuracy: 0.45885286783042395\n",
            "   breakdown result: [0.87816174 0.86961169 0.56418478]\n",
            "Best val accuracy = (0.8989431183944899, 0.8716304476902981, 0.564184776154851), on epoch (3, 21, 22) individually\n",
            "Epoch : 23\n",
            "Loss = 0.5536867622178001\n",
            "Train accuracy: 0.6746872504657971\n",
            "   breakdown result: [0.98633662 0.95810487 0.70797622]\n",
            "Dev accuracy: 0.45113406958793495\n",
            "   breakdown result: [0.86961169 0.87448047 0.55860349]\n",
            "Best val accuracy = (0.8989431183944899, 0.8744804655029094, 0.564184776154851), on epoch (3, 23, 22) individually\n",
            "Epoch : 24\n",
            "Loss = 0.5346986949264014\n",
            "Train accuracy: 0.6909058646082867\n",
            "   breakdown result: [0.98802236 0.95893887 0.72238488]\n",
            "Dev accuracy: 0.4645529034556466\n",
            "   breakdown result: [0.86889918 0.86996794 0.57439734]\n",
            "Best val accuracy = (0.8989431183944899, 0.8744804655029094, 0.5743973399833749), on epoch (3, 23, 24) individually\n",
            "Epoch : 25\n",
            "Loss = 0.5173519740435936\n",
            "Train accuracy: 0.6877650607754414\n",
            "   breakdown result: [0.99167776 0.96282495 0.7143643 ]\n",
            "Dev accuracy: 0.4570716066975419\n",
            "   breakdown result: [0.87471797 0.87388671 0.56133476]\n",
            "Best val accuracy = (0.8989431183944899, 0.8744804655029094, 0.5743973399833749), on epoch (3, 23, 24) individually\n",
            "Epoch : 26\n",
            "Loss = 0.5018119168486742\n",
            "Train accuracy: 0.6996894685476001\n",
            "   breakdown result: [0.98328454 0.96365895 0.73154112]\n",
            "Dev accuracy: 0.4568341052131576\n",
            "   breakdown result: [0.86141788 0.87578672 0.56988481]\n",
            "Best val accuracy = (0.8989431183944899, 0.8757867236670229, 0.5743973399833749), on epoch (3, 26, 24) individually\n",
            "Epoch : 27\n",
            "Loss = 0.4935433283608191\n",
            "Train accuracy: 0.7089699228107532\n",
            "   breakdown result: [0.99210363 0.96552214 0.73480614]\n",
            "Dev accuracy: 0.46419665122907017\n",
            "   breakdown result: [0.87697423 0.87709298 0.56905356]\n",
            "Best val accuracy = (0.8989431183944899, 0.8770929818311365, 0.5743973399833749), on epoch (3, 27, 24) individually\n",
            "Epoch : 28\n",
            "Loss = 0.4774107324094487\n",
            "Train accuracy: 0.7167598261023866\n",
            "   breakdown result: [0.99235205 0.96578831 0.7420637 ]\n",
            "Dev accuracy: 0.46680916755729723\n",
            "   breakdown result: [0.87792424 0.8722242  0.57404109]\n",
            "Best val accuracy = (0.8989431183944899, 0.8770929818311365, 0.5743973399833749), on epoch (3, 27, 24) individually\n",
            "Epoch : 29\n",
            "Loss = 0.46179940371068723\n",
            "Train accuracy: 0.7239286664892202\n",
            "   breakdown result: [0.99114542 0.96857422 0.74901961]\n",
            "Dev accuracy: 0.46597791236195224\n",
            "   breakdown result: [0.86794917 0.87863674 0.57510984]\n",
            "Best val accuracy = (0.8989431183944899, 0.8786367414796342, 0.5751098444365277), on epoch (3, 29, 29) individually\n",
            "Epoch : 30\n",
            "Loss = 0.4591360958283991\n",
            "Train accuracy: 0.7229881998048088\n",
            "   breakdown result: [0.99027593 0.96910656 0.74786621]\n",
            "Dev accuracy: 0.4670466690416815\n",
            "   breakdown result: [0.87661798 0.87804299 0.57309108]\n",
            "Best val accuracy = (0.8989431183944899, 0.8786367414796342, 0.5751098444365277), on epoch (3, 29, 29) individually\n",
            "\n",
            "Generating plot for  Loss Graph for target txtsql model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMFaMdCQT6td"
      },
      "source": [
        "##**Function to test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abdqlNLTPM2s",
        "outputId": "aac2b9d5-632c-42a9-91a6-5850dd0d74f3"
      },
      "source": [
        "\n",
        "def test_txtsql():\n",
        "    test_sql_data, test_table_data, TEST_DB = load_dataset(\"test\")\n",
        "\n",
        "    # load glove word embeddings and initialize the model\n",
        "    emb = load_word_embeddings('/content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt')\n",
        "    model = txtsql(emb, N_word=300, gpu=GPU)\n",
        "\n",
        "    # Load the best model state saved during training\n",
        "    agg_m, sel_m, cond_m = best_model_name()\n",
        "    model.agg_pred.load_state_dict(torch.load(agg_m))\n",
        "    model.sel_pred.load_state_dict(torch.load(sel_m))\n",
        "    model.cond_pred.load_state_dict(torch.load(cond_m))\n",
        "\n",
        "    # Run the model on the test data and get the logical accuracy\n",
        "    logical_accuracy_score =\\\n",
        "        epoch_acc(model, BATCH_SIZE, test_sql_data, test_table_data, save_results = True)\n",
        "\n",
        "    # Run the model on the test data and get the execution accuracy\n",
        "    execution_accuracy_score =\\\n",
        "        epoch_exec_acc(model, BATCH_SIZE, test_sql_data, test_table_data, TEST_DB)\n",
        "    \n",
        "    print(\"Test logical accuracy: %s;\\n  breakdown on (agg, sel, where): %s\" % logical_accuracy_score)\n",
        "    print(\"Test execution accuracy: %s\" % execution_accuracy_score)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test_txtsql()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset :  test\n",
            "Loading word embedding from /content/drive/MyDrive/Data606_finalproject/data/glove.6B.300d.txt\n",
            "txtsql where prediction\n",
            "Test logical accuracy: 0.47128101776042325;\n",
            "  breakdown on (agg, sel, where): [0.90074317 0.87044968 0.56090188]\n",
            "Test execution accuracy: 0.5537221312507873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMp_3Rc7AAE5"
      },
      "source": [
        "References:\n",
        "1. https://github.com/salesforce/WikiSQL\n",
        "2. https://github.com/tiwarikajal/Seq2SQL--Natural-Language-sentences-to-SQL-Queries"
      ]
    }
  ]
}