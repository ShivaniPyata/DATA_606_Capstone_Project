{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder_Decoder_attention (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxdJk93q3OQL"
      },
      "source": [
        "#**<center>Natural Language Text to SQL Query Conversion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxjRpT-l_ERw"
      },
      "source": [
        "###**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCTwwBebsBt",
        "outputId": "9a8e47b6-7dc2-40af-acff-ef9e8596dcfd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3REbOtKc3VHz",
        "outputId": "a61c7685-a0f9-40c2-b8f4-95fce9a5ab5f"
      },
      "source": [
        "pip install records"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting records\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/93/2467c761ea3729713ab97842a46cc125ad09d14a0a174cb637bee4983911/records-0.5.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: SQLAlchemy; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from records) (1.4.7)\n",
            "Collecting openpyxl<2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/26/0bd1a39776f53b4f28e5bb1d26b3fcd99068584a7e1ddca4e09c0d5fd592/openpyxl-2.4.11.tar.gz (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from records) (0.6.2)\n",
            "Collecting tablib>=0.11.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/85/078fc037b15aa1120d6a0287ec9d092d93d632ab01a0e7a3e69b4733da5e/tablib-3.0.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy; python_version >= \"3.0\"->records) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy; python_version >= \"3.0\"->records) (3.10.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.4.1)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl<2.5.0->records) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy; python_version >= \"3.0\"->records) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->SQLAlchemy; python_version >= \"3.0\"->records) (3.7.4.3)\n",
            "Building wheels for collected packages: openpyxl\n",
            "  Building wheel for openpyxl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openpyxl: filename=openpyxl-2.4.11-py2.py3-none-any.whl size=222821 sha256=596bf034607942b5616b464de86627f01178e2149dfc7fde18314b91b1ccbec4\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/44/27/63b211425501ad51d197ff8ed00e9e469e38b9e516cb69b1c2\n",
            "Successfully built openpyxl\n",
            "Installing collected packages: openpyxl, tablib, records\n",
            "  Found existing installation: openpyxl 2.5.9\n",
            "    Uninstalling openpyxl-2.5.9:\n",
            "      Successfully uninstalled openpyxl-2.5.9\n",
            "Successfully installed openpyxl-2.4.11 records-0.5.3 tablib-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeVZdo0s3XPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2309e145-939d-4d6d-a15a-a4bc8d0e1989"
      },
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import records\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import json\n",
        "import time\n",
        "import unicodedata\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import open\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ImportWarning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwAD6WS3aFA",
        "outputId": "f61ef4c7-dc46-4d6f-bc22-b05aca3971a3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import * \n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDU6X2K73cb4"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/lib/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-YsqTBi3izZ"
      },
      "source": [
        "from lib_db import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1fLEM3N-AVV"
      },
      "source": [
        "\"\"\"\n",
        "Device\n",
        "\"\"\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Xp2Qfu5Dsd"
      },
      "source": [
        "# #constants\n",
        "# \"\"\"\n",
        "# Batch Size, Embedding Size, Hidden Size\n",
        "# \"\"\"\n",
        "# BATCH_SIZE, EMBEDDING_SIZE, MAX_LENGTH, EPOCHS = 32, 64, 50, 10\n",
        "# LEARNING_RATE = 1\n",
        "# GPU = True\n",
        "MAX_LENGTH = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQpxR1D24c8_"
      },
      "source": [
        "###**Preparing training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FsZ9W6i3l1e"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\"\"\"\n",
        "To map words in the specified language to numbers\n",
        "\"\"\"\n",
        "class Language:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = defaultdict(int)\n",
        "        self.word2count = defaultdict(int)\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence:\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GYXJfKQW9ff"
      },
      "source": [
        "\"\"\"\n",
        "To Load the train data from file into the memory  \n",
        "\"\"\"\n",
        "def readLangs(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = pd.read_json(\"/content/drive/MyDrive/Data606_finalproject/output/tokenized_train.jsonl\", lines=True)\n",
        "\n",
        "    # Split every line into pairs\n",
        "    pairs= []\n",
        "    for idx, row in lines.iterrows():\n",
        "        tokens_en = row[\"tokenized_question\"]\n",
        "        tokens_sql = row[\"tokenized_query\"]\n",
        "        pairs.append([tokens_en, tokens_sql])\n",
        "\n",
        "    input_lang = Language(lang1)\n",
        "    output_lang = Language(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\"\"\"To complete the mapping of all string data to numeric data and filter language pairs\n",
        "               The parameters lang1, lang2 represent the name of the source language and target language \"\"\"\n",
        "\n",
        "def prepareData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"\\nCounting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Number of words in\", input_lang.name, input_lang.n_words)\n",
        "    print(\"Number of words in\", output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMSFlGLW6XL1",
        "outputId": "e7c7daf6-39b8-411d-bf91-542d8341bbee"
      },
      "source": [
        "global input_lang\n",
        "global output_lang\n",
        "global pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs= prepareData(\"en\", \"sql\")\n",
        "print(\"\\nRandom Question and query pair looks like:\\n\")\n",
        "print(random.choice(pairs))\n",
        "#output_lang.word2index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 56355 sentence pairs\n",
            "\n",
            "Counting words...\n",
            "Number of words in en 39685\n",
            "Number of words in sql 38066\n",
            "\n",
            "Random Question and query pair looks like:\n",
            "\n",
            "[['who', 'was', 'the', 'runner-up', 'after', 'season', '2', 'when', 'the', 'total', 'prize', 'money', 'was', '$', '108,000', '?'], ['SELECT', 'runner-up', 'FROM', 'table_', 'WHERE', 'season', 'GT', '2', 'AND', 'total', 'prize', 'money', 'EQL', '$', '108,000']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K8tcITaX_3Q"
      },
      "source": [
        "\"\"\"\n",
        "To convert language pairs into tensors to input the model\n",
        "\"\"\"\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5buBZ7IpcLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94892516-7a0d-4ad4-8111-1a250da18265"
      },
      "source": [
        "pair = pairs[0]\n",
        "print(pair)\n",
        "training_pairs = tensorsFromPair(pair)\n",
        "print(\"\\nTensor for Question and query pair looks like:\\n\")\n",
        "training_pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['tell', 'me', 'what', 'the', 'notes', 'are', 'for', 'south', 'australia'], ['SELECT', 'notes', 'FROM', 'table_', 'WHERE', 'current', 'slogan', 'EQL', 'south', 'australia']]\n",
            "\n",
            "Tensor for Question and query pair looks like:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2],\n",
              "         [ 3],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [ 6],\n",
              "         [ 7],\n",
              "         [ 8],\n",
              "         [ 9],\n",
              "         [10],\n",
              "         [ 1]], device='cuda:0'), tensor([[ 2],\n",
              "         [ 3],\n",
              "         [ 4],\n",
              "         [ 5],\n",
              "         [ 6],\n",
              "         [ 7],\n",
              "         [ 8],\n",
              "         [ 9],\n",
              "         [10],\n",
              "         [11],\n",
              "         [ 1]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxNkBGhVWhx8"
      },
      "source": [
        "\"\"\"\n",
        "To prepare validation data\n",
        "\"\"\"\n",
        "def readLangs_val(lang1, lang2):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = pd.read_json(\"/content/drive/MyDrive/Data606_finalproject/output/tokenized_test.jsonl\", lines=True)\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = []\n",
        "    for idx, row in lines.iterrows():\n",
        "        tokens_en = row[\"tokenized_question\"]\n",
        "        tokens_sql = row[\"tokenized_query\"]\n",
        "        pairs.append([tokens_en, tokens_sql])\n",
        "\n",
        "    input_lang = Language(lang1)\n",
        "    output_lang = Language(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "def prepareValData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs_val(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrlhQBvzgAYC",
        "outputId": "c8b3c036-b925-4ee9-b06d-9693ff9a003f"
      },
      "source": [
        "global pairs_test\n",
        "\n",
        "input_lang, output_lang, pairs_test= prepareValData(\"en\", \"sql\")\n",
        "print(\"\\nRandom Question and query pair looks like:\\n\")\n",
        "print(random.choice(pairs_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 15878 sentence pairs\n",
            "Trimmed to 15878 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "en 16358\n",
            "sql 15618\n",
            "\n",
            "Random Question and query pair looks like:\n",
            "\n",
            "[['how', 'many', 'defending', 'points', 'did', 'radek', 'štěpánek', 'have', '?'], ['SELECT', 'max', '(', 'points', 'defending', ')', 'FROM', 'table_', 'WHERE', 'player', 'EQL', 'radek', 'štěpánek']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg9XFtuyBH-C"
      },
      "source": [
        "###**Building GRU-based encoder and decoder model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9-GzzUt_4W8"
      },
      "source": [
        "###**Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzdXTwk_0uR"
      },
      "source": [
        "\"\"\"\n",
        "RNN Encoder\n",
        "\"\"\"\n",
        "class RNN_Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size,dropout):\n",
        "        super(RNN_Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcTLxtc4BWng"
      },
      "source": [
        "###**Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoWoXR99rIZI"
      },
      "source": [
        "\"\"\"\n",
        "Decoder\n",
        "\"\"\"\n",
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QYMrxJPImoo"
      },
      "source": [
        "###**Attention Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p48-AWuo_Fsi"
      },
      "source": [
        "\"\"\"\n",
        "Attention Decoder\n",
        "\"\"\"\n",
        "\n",
        "class RNN_AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p, max_length=MAX_LENGTH):\n",
        "        super(RNN_AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcAcOZuRBgI0"
      },
      "source": [
        "###**Training function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlj9Nj4QI3-o"
      },
      "source": [
        "teacher_forcing_ratio = 1\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "          criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length): \n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTHJCln5BpQI"
      },
      "source": [
        "###**Time Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb6APnew-FrE"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3QuP7lCDmN"
      },
      "source": [
        "###**Function to plot graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5crM3Ec-Lgt"
      },
      "source": [
        "def showPlot(points, plot_name):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.savefig(plot_name + \".png\")\n",
        "\n",
        "\n",
        "def plot_data(x, y, xlabel = \"x\", ylabel = \"y\", label = 'plot'):\n",
        "\tplt.figure()\n",
        "\tplt.plot(x, y)\n",
        "\tplt.xlabel(xlabel)\n",
        "\tplt.ylabel(ylabel)\n",
        "\tprint(\"Generating plot for \", label)\n",
        "\tplt.savefig(\"./\" + label + \".png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H3FM37YBu_O"
      },
      "source": [
        "###**To call training function and print graphs and logs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGIaFv--Io3"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=1):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        # training_pair = tensorsFromPair(random.choice(pairs))\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                      iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses, \"Baseline loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1iWfeTbCPGp"
      },
      "source": [
        "###**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "D56R6h_DDIBQ",
        "outputId": "c9ffc70f-00a1-4c21-bdc1-b3c5b40549f9"
      },
      "source": [
        "dropout = 0.5\n",
        "dropout_p = 0.5\n",
        "hidden_size = 256\n",
        "\n",
        "encoder1 = RNN_Encoder(input_lang.n_words, hidden_size,dropout).to(device)\n",
        "\n",
        "attn_decoder1 = RNN_AttnDecoder(hidden_size, output_lang.n_words, dropout_p).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, n_iters = 15000, print_every=1000, plot_every=1000,learning_rate= 0.001)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 36s (- 8m 24s) (1000 6%) 3.4367\n",
            "1m 11s (- 7m 43s) (2000 13%) 2.9114\n",
            "1m 46s (- 7m 6s) (3000 20%) 2.7104\n",
            "2m 21s (- 6m 29s) (4000 26%) 2.6327\n",
            "2m 56s (- 5m 53s) (5000 33%) 2.4106\n",
            "3m 32s (- 5m 18s) (6000 40%) 2.3611\n",
            "4m 7s (- 4m 43s) (7000 46%) 2.2733\n",
            "4m 43s (- 4m 7s) (8000 53%) 2.1843\n",
            "5m 18s (- 3m 32s) (9000 60%) 2.1240\n",
            "5m 53s (- 2m 56s) (10000 66%) 2.0779\n",
            "6m 29s (- 2m 21s) (11000 73%) 2.1333\n",
            "7m 3s (- 1m 45s) (12000 80%) 1.9925\n",
            "7m 38s (- 1m 10s) (13000 86%) 1.9701\n",
            "8m 13s (- 0m 35s) (14000 93%) 1.9985\n",
            "8m 49s (- 0m 0s) (15000 100%) 2.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csymIFaCi1A"
      },
      "source": [
        "###**Model evaluation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlmNUob3-OZM"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=50):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_cHrGS7-RHN"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=50):\n",
        "    correct = 0\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('\\nEnglish Question-', pair[0])\n",
        "        print('Ground truth Query-', pair[1])\n",
        "        generated_tokens, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        generated_query = ' '.join(generated_tokens)\n",
        "        if generated_query[:-6] == pair[1]:\n",
        "            correct += 1\n",
        "        print('Generated Query-', generated_query)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIuxVBPq-UCo",
        "outputId": "a3211089-2cf8-462a-8160-698522462b41"
      },
      "source": [
        "\n",
        "evaluateRandomly(encoder1, attn_decoder1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "English Question- ['how', 'many', 'times', 'was', 'the', 'rank', '(', 'night', ')', '11', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'viewers', '(', 'millions', ')', ')', 'FROM', 'table_', 'WHERE', 'rank', '(', 'night', ')', 'EQL', '11']\n",
            "Generated Query- SELECT COUNT ( rank ) FROM table_ WHERE rank EQL 14 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'surface', 'when', 'the', 'partner', 'was', 'robert', 'haybittel', '?']\n",
            "Ground truth Query- ['SELECT', 'surface', 'FROM', 'table_', 'WHERE', 'partner', 'EQL', 'robert', 'haybittel']\n",
            "Generated Query- SELECT surface FROM table_ WHERE tournament EQL SOS <EOS>\n",
            "\n",
            "English Question- ['can', 'you', 'tell', 'me', 'the', 'losing', 'bp', 'that', 'has', 'played', 'of', '22', ',', 'and', 'the', 'lost', 'of', '5', '?']\n",
            "Ground truth Query- ['SELECT', 'losing', 'bp', 'FROM', 'table_', 'WHERE', 'played', 'EQL', '22', 'AND', 'lost', 'EQL', '5']\n",
            "Generated Query- SELECT max ( SOS ) FROM table_ WHERE team EQL SOS AND competition EQL SOS <EOS>\n",
            "\n",
            "English Question- ['which', 'round', 'has', 'a', 'method', 'of', 'ko', ',', 'and', 'an', 'opponent', 'of', 'alfonse', \"d'amore\", '?']\n",
            "Ground truth Query- ['SELECT', 'round', 'FROM', 'table_', 'WHERE', 'method', 'EQL', 'ko', 'AND', 'opponent', 'EQL', 'alfonse', \"d'amore\"]\n",
            "Generated Query- SELECT round FROM table_ WHERE round EQL SOS AND round EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'total', 'number', 'of', 'ties', 'a', 'team', 'with', 'less', 'than', '3', 'losses', 'have', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'ties', ')', 'FROM', 'table_', 'WHERE', 'losses', 'LT', '3']\n",
            "Generated Query- SELECT COUNT ( wins ) FROM table_ WHERE wins LT 3 <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'attendance', 'on', 'week', '8', '?']\n",
            "Ground truth Query- ['SELECT', 'avg', '(', 'attendance', ')', 'FROM', 'table_', 'WHERE', 'week', 'EQL', '8']\n",
            "Generated Query- SELECT attendance FROM table_ WHERE week EQL 15 <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'score', 'in', 'the', 'game', 'on', 'may', '11', '?']\n",
            "Ground truth Query- ['SELECT', 'score', 'FROM', 'table_', 'WHERE', 'date', 'EQL', 'may', '11']\n",
            "Generated Query- SELECT score FROM table_ WHERE date EQL may 11 <EOS>\n",
            "\n",
            "English Question- ['what', \"'s\", 'the', 'longitude', 'named', 'zipaltonal', 'fluctus', 'in', '1997', 'with', 'a', 'diameter', 'smaller', 'than', '490', '?']\n",
            "Ground truth Query- ['SELECT', 'longitude', 'FROM', 'table_', 'WHERE', 'year', 'named', 'EQL', '1997', 'AND', 'diameter', '(', 'km', ')', 'LT', '490', 'AND', 'name', 'EQL', 'zipaltonal', 'fluctus']\n",
            "Generated Query- SELECT SOS FROM table_ WHERE SOS EQL SOS AND SOS EQL SOS AND SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'assists', 'did', 'delisha', 'milton-jones', 'make', '?']\n",
            "Ground truth Query- ['SELECT', 'assists', 'FROM', 'table_', 'WHERE', 'player', 'EQL', 'delisha', 'milton-jones']\n",
            "Generated Query- SELECT COUNT ( SOS ) FROM table_ WHERE SOS SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'total', 'number', 'of', 'poles', ',', 'when', 'position', 'is', '6th', ',', 'and', 'when', 'points', 'is', 'less', 'than', '164', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'poles', ')', 'FROM', 'table_', 'WHERE', 'position', 'EQL', '6th', 'AND', 'points', 'LT', '164']\n",
            "Generated Query- SELECT COUNT ( position ) FROM table_ WHERE position EQL 5 AND position EQL defensive <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'ethernet', 'ports', 'of', 'the', 'u10', 'appliance', '?']\n",
            "Ground truth Query- ['SELECT', 'ethernet', 'ports', 'FROM', 'table_', 'WHERE', 'name', 'EQL', 'u10']\n",
            "Generated Query- SELECT SOS FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['which', 'host', 'city', 'has', 'more', 'than', '6', 'silver', 'and', 'a', 'total', 'of', '22', '?']\n",
            "Ground truth Query- ['SELECT', 'host', 'city', 'FROM', 'table_', 'WHERE', 'silver', 'GT', '6', 'AND', 'total', 'EQL', '22']\n",
            "Generated Query- SELECT status FROM table_ WHERE silver EQL 6 AND total LT 6 <EOS>\n",
            "\n",
            "English Question- ['what', 'award', 'did', 'charlie', 'productions', 'ltd', 'receive', '?']\n",
            "Ground truth Query- ['SELECT', 'award', 'FROM', 'table_', 'WHERE', 'recipient', 'EQL', 'charlie', 'productions', 'ltd']\n",
            "Generated Query- SELECT year FROM table_ WHERE player EQL SOS <EOS>\n",
            "\n",
            "English Question- ['reported', 'offenses', 'larger', 'than', '216', ',', 'and', 'a', 'u.s.', 'rate', 'smaller', 'than', '3274', ',', 'and', 'a', 'texas', 'rate', 'smaller', 'than', '2688.9', ',', 'and', 'a', 'crime', 'of', 'violent', 'crime', 'has', 'what', 'killeen', 'rate', '?']\n",
            "Ground truth Query- ['SELECT', 'sum', '(', 'killeen', 'rate', ')', 'FROM', 'table_', 'WHERE', 'reported', 'offenses', 'GT', '216', 'AND', 'u.s.', 'rate', 'LT', '3274', 'AND', 'texas', 'rate', 'LT', '2688.9', 'AND', 'crime', 'EQL', 'violent', 'crime']\n",
            "Generated Query- SELECT max ( SOS force ) FROM table_ WHERE SOS SOS EQL SOS AND year GT SOS <EOS>\n",
            "\n",
            "English Question- ['who', 'was', 'the', 'opponent', 'of', 'the', 'game', 'before', 'week', '11', 'on', 'october', '31', ',', '1976', '?']\n",
            "Ground truth Query- ['SELECT', 'opponent', 'FROM', 'table_', 'WHERE', 'week', 'LT', '11', 'AND', 'date', 'EQL', 'october', '31', ',', '1976']\n",
            "Generated Query- SELECT opponent FROM table_ WHERE week EQL 11 AND week GT 15 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'density', '(', 'hab/km²', ')', 'with', 'a', 'population', 'censo', '2007', '(', 'hab', ')', 'of', '336.293*', '?']\n",
            "Ground truth Query- ['SELECT', 'density', '(', 'hab/', 'km²', ')', 'FROM', 'table_', 'WHERE', 'population', 'censo', '2007', '(', 'hab', ')', 'EQL', '336.293*']\n",
            "Generated Query- SELECT COUNT ( SOS population ( 2009 ) ) FROM table_ WHERE SOS ( SOS $ ) EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'position', 'did', 'jimmy', 'oliver', 'of', 'the', 'united', 'states', 'play', '?']\n",
            "Ground truth Query- ['SELECT', 'position', 'FROM', 'table_', 'WHERE', 'nationality', 'EQL', 'united', 'states', 'AND', 'player', 'EQL', 'jimmy', 'oliver']\n",
            "Generated Query- SELECT position FROM table_ WHERE position EQL linebacker AND position EQL 14 <EOS>\n",
            "\n",
            "English Question- ['what', '1997', ',', 'has', 'qf', 'as', 'a', '1994', ',', 'and', '1r', 'as', 'a', '1999', '?']\n",
            "Ground truth Query- ['SELECT', '1997', 'FROM', 'table_', 'WHERE', '1994', 'EQL', 'qf', 'AND', '1999', 'EQL', '1r']\n",
            "Generated Query- SELECT icao FROM table_ WHERE 1999 EQL 1r AND year EQL 1999 <EOS>\n",
            "\n",
            "English Question- ['what', 'player', 'was', 'from', 'the', 'british', 'columbia', 'college', '?']\n",
            "Ground truth Query- ['SELECT', 'player', 'FROM', 'table_', 'WHERE', 'college', 'EQL', 'british', 'columbia']\n",
            "Generated Query- SELECT player FROM table_ WHERE position EQL guard <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'greatest', 'wins', 'with', 'losses', 'larger', 'than', '1', '?']\n",
            "Ground truth Query- ['SELECT', 'max', '(', 'wins', ')', 'FROM', 'table_', 'WHERE', 'losses', 'GT', '1']\n",
            "Generated Query- SELECT max ( wins ) FROM table_ WHERE wins EQL 1 <EOS>\n",
            "\n",
            "English Question- ['when', 'the', 'occupation', 'was', 'utility', 'worker', 'on-air', 'talent', ',', 'what', 'was', 'the', 'game', 'status', '?']\n",
            "Ground truth Query- ['SELECT', 'game', 'status', 'FROM', 'table_', 'WHERE', 'occupation', 'EQL', 'utility', 'worker', 'on-air', 'talent']\n",
            "Generated Query- SELECT date FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', \"'s\", 'the', 'name', 'of', 'the', 'tournament', 'that', 'gianni', 'ocleppo', 'was', 'the', 'runner-up', '?']\n",
            "Ground truth Query- ['SELECT', 'tournament', 'name', 'FROM', 'table_', 'WHERE', 'runners-up', 'EQL', 'gianni', 'ocleppo']\n",
            "Generated Query- SELECT name FROM table_ WHERE tournament EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'score', 'in', 'the', 'final', 'when', 'mats', 'wilander', 'was', 'the', 'opponent', 'in', 'the', 'australian', 'open', '?']\n",
            "Ground truth Query- ['SELECT', 'score', 'in', 'the', 'final', 'FROM', 'table_', 'WHERE', 'championship', 'EQL', 'australian', 'open', 'AND', 'opponent', 'in', 'the', 'final', 'EQL', 'mats', 'wilander']\n",
            "Generated Query- SELECT score FROM table_ WHERE opponent EQL SOS SOS AND date EQL SOS <EOS>\n",
            "\n",
            "English Question- ['when', 'the', 'away', 'team', 'is', 'essendon', ',', 'what', \"'s\", 'the', 'home', 'team', 'score', '?']\n",
            "Ground truth Query- ['SELECT', 'home', 'team', 'score', 'FROM', 'table_', 'WHERE', 'away', 'team', 'EQL', 'essendon']\n",
            "Generated Query- SELECT away team score FROM table_ WHERE away team score EQL 13.12 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'total', 'when', 'matches', 'is', 'less', 'than', '3', ',', 'and', 'rank', 'is', 'smaller', 'than', '2', '?']\n",
            "Ground truth Query- ['SELECT', 'min', '(', 'total', ')', 'FROM', 'table_', 'WHERE', 'matches', 'LT', '3', 'AND', 'rank', 'LT', '2']\n",
            "Generated Query- SELECT COUNT ( rank ) FROM table_ WHERE rank GT 3 AND rank EQL 3 <EOS>\n",
            "\n",
            "English Question- ['what', \"'s\", 'the', 'name', 'that', 'has', 'the', 'characters', '廣亨', '?']\n",
            "Ground truth Query- ['SELECT', 'name', '(', 'wade', 'giles', ')', 'FROM', 'table_', 'WHERE', 'characters', 'EQL', '廣亨']\n",
            "Generated Query- SELECT name FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['when', 'kansas', 'state', 'had', 'a', 'pick', 'of', 'over', '35', ',', 'what', \"'s\", 'the', 'highest', 'overall', 'pick', 'found', '?']\n",
            "Ground truth Query- ['SELECT', 'max', '(', 'overall', ')', 'FROM', 'table_', 'WHERE', 'college', 'EQL', 'kansas', 'state', 'AND', 'pick', 'GT', '35']\n",
            "Generated Query- SELECT max ( pick # ) FROM table_ WHERE position EQL defensive AND years EQL guard <EOS>\n",
            "\n",
            "English Question- ['what', 'date', 'was', 'the', 'cross', 'code', 'debut', 'of', 'rl', '1st', 'test', 'great', 'britain', 'v', 'australia', ',', 'and', 'the', \"int'l\", 'debut', 'was', 'ru', 'five', 'nations', 'v', 'ireland', '?']\n",
            "Ground truth Query- ['SELECT', 'date', 'FROM', 'table_', 'WHERE', 'cross', 'code', 'debut', 'EQL', 'rl', '1st', 'test', 'great', 'britain', 'v', 'australia', 'AND', \"int'l\", 'debut', 'EQL', 'ru', 'five', 'nations', 'v', 'ireland']\n",
            "Generated Query- SELECT date FROM table_ WHERE SOS SOS EQL SOS AND manufacturer EQL SOS SOS AND year EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'country', 'of', 'the', 'player', 'with', 'playoff', 'money', 'and', 'a', 'score', 'of', '66-67-70-67=270', '?']\n",
            "Ground truth Query- ['SELECT', 'country', 'FROM', 'table_', 'WHERE', 'money', '(', '$', ')', 'EQL', 'playoff', 'AND', 'score', 'EQL', '66-67-70-67=270']\n",
            "Generated Query- SELECT country FROM table_ WHERE country EQL united states AND player EQL SOS <EOS>\n",
            "\n",
            "English Question- ['who', 'is', 'the', 'music-director', 'for', 'the', 'song', 'from', 'the', 'film', 'khaleja', 'who', 'had', 'a', 'co-singer', 'of', 'hemachandra', '?']\n",
            "Ground truth Query- ['SELECT', 'music', '-', 'director', 'FROM', 'table_', 'WHERE', 'co', '-', 'singer', 'EQL', 'hemachandra', 'AND', 'film', 'EQL', 'khaleja']\n",
            "Generated Query- SELECT SOS FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['name', 'the', 'content', 'for', 'sky', 'famiglia', 'for', 'italian', 'and', 'dar', '16:9', 'for', 'mtv', 'hits']\n",
            "Ground truth Query- ['SELECT', 'content', 'FROM', 'table_', 'WHERE', 'package/option', 'EQL', 'sky', 'famiglia', 'AND', 'language', 'EQL', 'italian', 'AND', 'dar', 'EQL', '16:9', 'AND', 'television', 'service', 'EQL', 'mtv', 'hits']\n",
            "Generated Query- SELECT part 4 FROM table_ WHERE title EQL `` SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'camera', 'used', 'when', 'the', 'wavelength', 'is', '814nm', '(', 'i-band', ')', '?']\n",
            "Ground truth Query- ['SELECT', 'camera', 'FROM', 'table_', 'WHERE', 'wavelength', 'EQL', '814nm', '(', 'i-band', ')']\n",
            "Generated Query- SELECT SOS ( SOS ) FROM table_ WHERE SOS ( SOS ) EQL SOS <EOS>\n",
            "\n",
            "English Question- ['which', 'species', 'specific', 'has', 'a', 'link', 'of', 'server/sourcecode', '?']\n",
            "Ground truth Query- ['SELECT', 'species', 'specific', 'FROM', 'table_', 'WHERE', 'link', 'EQL', 'server/sourcecode']\n",
            "Generated Query- SELECT SOS FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'tournament', 'with', 'a', 'date', 'that', 'is', 'apr', '16', ',', '1967', '?']\n",
            "Ground truth Query- ['SELECT', 'tournament', 'FROM', 'table_', 'WHERE', 'date', 'EQL', 'apr', '16', ',', '1967']\n",
            "Generated Query- SELECT tournament FROM table_ WHERE date EQL june 15 <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'overall', 'values', 'have', 'a', 'college', 'of', 'notre', 'dame', 'and', 'rounds', 'over', '2', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'overall', ')', 'FROM', 'table_', 'WHERE', 'college', 'EQL', 'notre', 'dame', 'AND', 'round', 'GT', '2']\n",
            "Generated Query- SELECT COUNT ( position ) FROM table_ WHERE position EQL 2 AND player EQL billy <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'location', 'of', 'the', '1999', 'tournament', '?']\n",
            "Ground truth Query- ['SELECT', 'location', 'FROM', 'table_', 'WHERE', 'tournament', 'EQL', '1999']\n",
            "Generated Query- SELECT location FROM table_ WHERE tournament EQL french open <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'the', 'spa', 'fea', 'when', 'the', 'lms', 'fea', 'was', '5', '?']\n",
            "Ground truth Query- ['SELECT', 'spa', 'fea', 'FROM', 'table_', 'WHERE', 'lms', 'fea', 'EQL', '5']\n",
            "Generated Query- SELECT COUNT ( SOS 5 ) FROM table_ WHERE SOS SOS EQL 5 <EOS>\n",
            "\n",
            "English Question- ['what', 'year', 'was', 'the', 'bridge', 'in', 'kent', 'built', '?']\n",
            "Ground truth Query- ['SELECT', 'built', 'FROM', 'table_', 'WHERE', 'county', 'EQL', 'kent']\n",
            "Generated Query- SELECT year FROM table_ WHERE year EQL 2012 <EOS>\n",
            "\n",
            "English Question- ['what', \"'s\", 'the', 'sum', 'of', 'the', 'pick', 'that', 'has', 'the', 'player', 'of', 'robert', 'ingalls', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'pick', ')', 'FROM', 'table_', 'WHERE', 'player', 'EQL', 'robert', 'ingalls']\n",
            "Generated Query- SELECT sum ( pick ) FROM table_ WHERE player EQL SOS SOS <EOS>\n",
            "\n",
            "English Question- ['with', 'games', 'started', 'smaller', 'than', '16', 'plus', 'receptions', 'of', '51', ',', 'what', 'is', 'the', 'smallest', 'amount', 'of', 'touchdowns', 'listed', '?']\n",
            "Ground truth Query- ['SELECT', 'min', '(', 'touchdowns', ')', 'FROM', 'table_', 'WHERE', 'receptions', 'EQL', '51', 'AND', 'games', 'started', 'LT', '16']\n",
            "Generated Query- SELECT max ( SOS ) FROM table_ WHERE SOS EQL 0 AND total GT 3 <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'venue', 'when', 'the', 'score', 'was', '8-2', '?']\n",
            "Ground truth Query- ['SELECT', 'venue', 'FROM', 'table_', 'WHERE', 'score', 'EQL', '8-2']\n",
            "Generated Query- SELECT venue FROM table_ WHERE score EQL 3–6 <EOS>\n",
            "\n",
            "English Question- ['i', 'want', 'the', 'sum', 'of', 'drawn', 'for', 'lost', 'less', 'than', '0']\n",
            "Ground truth Query- ['SELECT', 'sum', '(', 'drawn', ')', 'FROM', 'table_', 'WHERE', 'lost', 'LT', '0']\n",
            "Generated Query- SELECT sum ( drawn ) FROM table_ WHERE wins GT 0 <EOS>\n",
            "\n",
            "English Question- ['which', 'outcome', 'has', 'a', 'score', 'of', '6–4', ',', '2–6', ',', '6–3', '?']\n",
            "Ground truth Query- ['SELECT', 'outcome', 'FROM', 'table_', 'WHERE', 'score', 'EQL', '6–4', ',', '2–6', ',', '6–3']\n",
            "Generated Query- SELECT outcome FROM table_ WHERE score EQL 5–7 , 5–7 , 5–7 , 6–3 , 6–3 , 6–3 , 6–3 <EOS>\n",
            "\n",
            "English Question- ['when', 'was', 'southend', 'united', 'the', 'home', 'team', '?']\n",
            "Ground truth Query- ['SELECT', 'date', 'FROM', 'table_', 'WHERE', 'home', 'team', 'EQL', 'southend', 'united']\n",
            "Generated Query- SELECT date FROM table_ WHERE home team EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'highest', 'number', 'of', 'laps', 'that', 'have', 'a', 'time', 'of', '+18.366', ',', 'and', 'a', 'grid', 'lower', 'than', '13', '?']\n",
            "Ground truth Query- ['SELECT', 'max', '(', 'laps', ')', 'FROM', 'table_', 'WHERE', 'grid', 'LT', '13', 'AND', 'time', 'EQL', '+18.366']\n",
            "Generated Query- SELECT max ( laps ) FROM table_ WHERE driver EQL SOS AND grid GT 13 <EOS>\n",
            "\n",
            "English Question- ['who', 'is', 'the', 'winner', 'when', 'bigten', '(', '2-1', ')', 'is', 'the', 'challenge', 'leader', '?']\n",
            "Ground truth Query- ['SELECT', 'winner', 'FROM', 'table_', 'WHERE', 'challenge', 'leader', 'EQL', 'bigten', '(', '2-1', ')']\n",
            "Generated Query- SELECT winner FROM table_ WHERE SOS EQL SOS ( SOS ) <EOS>\n",
            "\n",
            "English Question- ['what', 'was', 'matthew', 'warchus', \"'\", 'award', '?']\n",
            "Ground truth Query- ['SELECT', 'award', 'FROM', 'table_', 'WHERE', 'nominee', 'EQL', 'matthew', 'warchus']\n",
            "Generated Query- SELECT COUNT ( SOS ) FROM table_ WHERE SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['what', 'is', 'the', 'rank', 'of', 'the', 'cinema', 'when', 'the', 'number', 'of', 'sites', 'is', 'more', 'than', '62', 'and', 'the', 'circuit', 'is', 'cineplex', 'entertainment', '?']\n",
            "Ground truth Query- ['SELECT', 'sum', '(', 'rank', ')', 'FROM', 'table_', 'WHERE', 'sites', 'GT', '62', 'AND', 'circuit', 'EQL', 'cineplex', 'entertainment']\n",
            "Generated Query- SELECT sum ( rank ) FROM table_ WHERE rank EQL SOS AND year GT SOS <EOS>\n",
            "\n",
            "English Question- ['how', 'many', 'managers', 'left', 'sunshine', 'stars', '?']\n",
            "Ground truth Query- ['SELECT', 'COUNT', '(', 'outgoing', 'manager', ')', 'FROM', 'table_', 'WHERE', 'team', 'EQL', 'sunshine', 'stars']\n",
            "Generated Query- SELECT COUNT ( SOS SOS ) FROM table_ WHERE SOS SOS EQL SOS <EOS>\n",
            "\n",
            "English Question- ['in', 'which', 'tournament', 'did', 'al', 'geiberger', 'finish', 'runner-up', '?']\n",
            "Ground truth Query- ['SELECT', 'tournament', 'FROM', 'table_', 'WHERE', 'runner', '(', 's', ')', '-up', 'EQL', 'al', 'geiberger']\n",
            "Generated Query- SELECT tournament FROM table_ WHERE tournament EQL texas open <EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}